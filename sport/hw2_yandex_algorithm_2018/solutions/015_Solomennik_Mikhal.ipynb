{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yandex Algorithm 2018 ML track\n",
    "https://contest.yandex.ru/algorithm2018/contest/7914/standings/\n",
    "    \n",
    "15 место (85881) private LB (mi-sol@tut.by)\n",
    "\n",
    "Результат на public LB для одной модели без усреднения 86615\n",
    "\n",
    "Регрессия с помощью Catboost, фичи на основе грамматических признаков из pymorphy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "  Содержание<span class=\"tocSkip\"></span>\n",
    "</h1>\n",
    "<div class=\"toc\">\n",
    "  <ul class=\"toc-item\">\n",
    "    <li>\n",
    "      <span>\n",
    "        <a href=\"#Чтение-и-подготовка-данных\" data-toc-modified-id=\"Чтение-и-подготовка-данных-1\">\n",
    "          <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Чтение и подготовка данных\n",
    "        </a>\n",
    "      </span>\n",
    "      <ul class=\"toc-item\">\n",
    "        <li>\n",
    "          <span>\n",
    "            <a href=\"#Подготовка-целевой-переменной-для-регрессии\" data-toc-modified-id=\"Подготовка-целевой-переменной-для-регрессии-1.1\">\n",
    "              <span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Подготовка целевой переменной для регрессии\n",
    "            </a>\n",
    "          </span>\n",
    "        </li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "      <span>\n",
    "        <a href=\"#Чистка-данных-(ошибки-перекодировки)\" data-toc-modified-id=\"Чистка-данных-(ошибки-перекодировки)-2\">\n",
    "          <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Чистка данных (ошибки перекодировки)\n",
    "        </a>\n",
    "      </span>\n",
    "    <li>\n",
    "      <span>\n",
    "        <a href=\"#Вычисление-признаков\" data-toc-modified-id=\"Вычисление-признаков-3\">\n",
    "          <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Вычисление признаков\n",
    "        </a>\n",
    "      </span>\n",
    "      <ul class=\"toc-item\">\n",
    "        <li>\n",
    "          <span>\n",
    "            <a href=\"#Вычисление-грамматических-признаков\" data-toc-modified-id=\"Вычисление-грамматических-признаков-3.1\">\n",
    "              <span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Вычисление грамматических признаков\n",
    "            </a>\n",
    "          </span>\n",
    "        </li>\n",
    "        <li>\n",
    "          <span>\n",
    "            <a href=\"#Проверяем-одинаковы-ли-род,-время,-число-для-слов-контекста-и-ответа\" data-toc-modified-id=\"Проверяем-одинаковы-ли-род,-время,-число-для-слов-контекста-и-ответа-3.2\">\n",
    "              <span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Проверяем одинаковы ли род, время, число для слов контекста и ответа\n",
    "            </a>\n",
    "          </span>\n",
    "        </li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "      <span>\n",
    "        <a href=\"#Исследования\" data-toc-modified-id=\"Исследования-4\">\n",
    "          <span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Исследования\n",
    "        </a>\n",
    "      </span>\n",
    "    </li>\n",
    "    <li>\n",
    "      <span>\n",
    "        <a href=\"#Обучаемся-и-делаем-предсказание\" data-toc-modified-id=\"Обучаемся-и-делаем-предсказание-5\">\n",
    "          <span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Обучаемся и делаем предсказание\n",
    "        </a>\n",
    "      </span>\n",
    "      <ul class=\"toc-item\">\n",
    "        <li>\n",
    "          <span>\n",
    "            <a href=\"#Среднее-по-разным-сидам\" data-toc-modified-id=\"Среднее-по-разным-сидам-5.1\">\n",
    "              <span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Среднее по разным сидам\n",
    "            </a>\n",
    "          </span>\n",
    "        </li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv \n",
    "import re\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем данные\n",
    "train = pd.read_csv('train.tsv', sep='\\t', quoting=csv.QUOTE_NONE, header=None, names=[ 'context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply', 'label', 'confidence'])\n",
    "test = pd.read_csv('final.tsv', sep='\\t', quoting=csv.QUOTE_NONE, header=None, names=[ 'context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка целевой переменной для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение confidence всегда меняется от 1/3 (мнения экспертов разделились поровну) до 1 (все эксперты дали одинаковую оценку), эта величина определяет максимальную долю для одной из трёх оценок.\n",
    "\n",
    "Мы хотим, чтобы значения целивой переменной лежали в следующих диапазонах:\n",
    "\n",
    "$$good = [\\frac{2}{3}, 1]$$ \n",
    "$$neutral = [\\frac{1}{3}, \\frac{2}{3}]$$\n",
    "$$bad = [0, \\frac{2}{3}]$$\n",
    "\n",
    "при этом 1 - значение целевой переменной для good, когда все эксперты выставили это значение, при расхождении мнения экспертов оно уменьшается до 2/3, 0 - значение целевой переменной для bad, когда все эксперты выставили это значение, при расхождении мнения экспертов оно растёт до 1/3.\n",
    "\n",
    "Для neutral всё сложнее, т.к. организатры дали confidence только для решения экспертов с максимальным скором, то непонятно в какую сторону смещать neutral, значения confidence могли быть разные. Например:\n",
    "\n",
    "| good | neutral | bad | |\n",
    "| --- | --- | --- | --- |\n",
    "| 0,33 | 0,34 | 0,33 | мнения разделились (неопределённое значение) |\n",
    "| 0 | 1 | 0 | точно neutral |\n",
    "| 0,34 | 0,66 | 0 | ближе к good |\n",
    "| 0 | 0,66 | 0,34 | ближе к bad |\n",
    "\n",
    "Я решил, что neutral это всё же скорее хорошее значение, поэтому в случаях, когда confidence ближе к 1, то целевая переменная будет ближе к 2/3, а в случае, когда confidence ближе к  0,33 его значение будет 1/3.\n",
    "Но теперь думаю можно было и вообще всегда ставить для neutral значение 0,5, возможно это улучшило бы результат, хотя и не сильно, т.к. самих значений neutral достаточно мало.\n",
    "\n",
    "$$y = \\begin{cases}\n",
    "1 - \\Delta & \\text{good}\\\\\n",
    "2/3 - \\Delta  & \\text{neutral}\\\\\n",
    "0 + \\Delta  & \\text{bad}\\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "где $$\\Delta = (1 - confidence)/2$$\n",
    "\n",
    "_Замечу, что тот же принцип давал существенный прирост скора при сортировке результатов в виде вероятностей, \n",
    "полученных при применении логистической регрессии для 3-х классов._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем преобразование в соответствии с условиями задачи\n",
    "# good -> 2, neutral -> 1,  bad -> 0\n",
    "dict_g_n_b = { 'good': 2, 'neutral': 1, 'bad': 0 }\n",
    "train['label_num'] = [dict_g_n_b[label] for label in train['label']]\n",
    "\n",
    "# выставляем начальные значения в крайние точки диапазона (для good и neutral - верхнюю, для bad - нижнюю)\n",
    "dict_2_1_0 = { 2 : 1, 1 : 2/3, 0: -0.0000001 } # знак \"-\" для bad, чтобы упростить вычисления\n",
    "train['y'] = [dict_2_1_0[label] for label in train['label_num']]\n",
    "\n",
    "# вычисляем смещение по confidence\n",
    "train['confidence_delta'] = (1.-train['confidence'])/2.\n",
    "train['y'] = train['y'] - train['confidence_delta']\n",
    "# меняем обратно знак для bad на +\n",
    "train.loc[train['y']<0, 'y'] = -train.loc[train['y']<0, 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>confidence</th>\n",
       "      <th>confidence_delta</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875352</td>\n",
       "      <td>0.062324</td>\n",
       "      <td>0.937676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900968</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.617151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884320</td>\n",
       "      <td>0.057840</td>\n",
       "      <td>0.057840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>0.982530</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.991265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>0.838054</td>\n",
       "      <td>0.080973</td>\n",
       "      <td>0.919027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  label_num  confidence  confidence_delta         y\n",
       "0     good          2    0.875352          0.062324  0.937676\n",
       "1  neutral          1    0.900968          0.049516  0.617151\n",
       "2      bad          0    0.884320          0.057840  0.057840\n",
       "3     good          2    0.982530          0.008735  0.991265\n",
       "4     good          2    0.838054          0.080973  0.919027"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['label', 'label_num', 'confidence', 'confidence_delta', 'y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сливаем train и test вместе\n",
    "train['is_train'] = True\n",
    "test['is_train'] = False\n",
    "all_data = pd.concat([train , test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чистка данных (ошибки перекодировки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка данных давала прирост на валиации и LB.\n",
    "\n",
    "Ошибки получены, вероятно, в результате неправильной перекодировки из Win-1251 в macCyrillic и последующем приведении к нижнему регистру и отделении знаков препинания от слов (что также добавило ошибок в слова с апострофами), в результате разные буквы могли получить один и тот же код, что мешало сделать автоматическое восстановление.\n",
    "\n",
    "Например:\n",
    "<br>_Боже Пожалуйста -> Ѕоже ѕожалуйста -> sоже ѕожалуйста\n",
    "<br>Да -> ƒа\n",
    "<br>Он -> ќн\n",
    "<br>Такой -> “акой -> \" акой_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# исправление ошибок перекодировки\n",
    "def correct_encoding(field_name):\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ьi', 'ы')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ќа', 'на')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ќе', 'не')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ќу', 'ну')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ќи', 'ни')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ќо', 'но')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ќ', 'о')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('\\' орош', 'хорош')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ѕоже', 'боже')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ѕорис', 'борис')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('sольш', 'больш')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ѕи', ' би')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ѕе', 'бе')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ѕо', 'по')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ѕр', 'пр')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ћа', 'ла')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ћю', 'лю')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('ћ', 'м')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('єм', 'ём')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('єл', 'ял')\n",
    "    all_data[field_name] = all_data[field_name].str.replace(' є', ' я')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('\" є', 'чё')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('є', 'ё')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('¬', 'в')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('\" ы', 'ты')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('\" й', 'уй')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('\" олько', 'только')\n",
    "correct_encoding('reply')\n",
    "correct_encoding('context_0')\n",
    "correct_encoding('context_1')\n",
    "correct_encoding('context_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# зачистка текста от знаков препинания\n",
    "def replace_punctuation(field_name):\n",
    "    all_data[field_name] = all_data[field_name].str.replace('-', '')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('!', '')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('.', '')\n",
    "    all_data[field_name] = all_data[field_name].str.replace(',', '')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('\"', '')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('\\'', '')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('  ', ' ')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('  ', ' ')\n",
    "replace_punctuation('reply')\n",
    "replace_punctuation('context_0')\n",
    "replace_punctuation('context_1')\n",
    "replace_punctuation('context_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "при более тщательной очистке данных скор упал, поэтому от неё в таком виде отказался"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# читаем данные в файл, исправляем и сохраняем файл\n",
    "def correct_encoding(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text = text.replace('ьi', 'ы')\n",
    "        text = text.replace('ьı', 'ы')\n",
    "        text = text.replace('ќа', 'на')\n",
    "        text = text.replace('ќе', 'не')\n",
    "        text = text.replace('ќу', 'ну')\n",
    "        text = text.replace('ќи', 'ни')\n",
    "        text = text.replace('ќо', 'но')\n",
    "        text = text.replace('ќ', 'о')\n",
    "        text = text.replace('\\tч ', '\\t')\n",
    "        text = text.replace('\\tц ', '\\t')\n",
    "        text = text.replace('\\' орош', 'хорош')\n",
    "        text = text.replace('ѕоже', 'боже')\n",
    "        text = text.replace('ѕорис', 'борис')\n",
    "        text = text.replace('sольш', 'больш')\n",
    "        text = text.replace('ѕоюсь', 'боюсь')\n",
    "        text = text.replace('ѕоб ', 'боб ')\n",
    "        text = text.replace('ѕо', 'по')\n",
    "        text = text.replace('ѕи', ' би')\n",
    "        text = text.replace('ѕе', 'бе')\n",
    "        text = text.replace('ѕросай', 'бросай')\n",
    "        text = text.replace('ѕа', 'па')\n",
    "        text = text.replace('ѕр', 'пр')\n",
    "        text = text.replace('ѕе', 'бе')\n",
    "        text = text.replace('ѕл', 'бл')\n",
    "        text = text.replace('ѕэ', 'пэ')\n",
    "        text = text.replace('ë', 'ё')\n",
    "        \n",
    "        \n",
    "        text = text.replace('• ', '')\n",
    "        text = text.replace('{ c : $00ffff } ', '')\n",
    "        \n",
    "        text = text.replace('\\t≈сли', '\\tесли')\n",
    "        \n",
    "        text = text.replace('\\tако', '\\tкако')\n",
    "        text = text.replace('\\t\" ак', '\\tтак')\n",
    "        text = text.replace('\\t\" меня нет ключа', '\\tу меня нет ключа')\n",
    "\n",
    "        text = text.replace('\\ttр', '\\tтр')\n",
    "        text = text.replace('\\ttе', '\\tте')\n",
    "        text = text.replace('\\ttо', '\\tто')\n",
    "        text = text.replace('\\ttа', '\\tта')\n",
    "        text = text.replace('\\ttы', '\\tты')\n",
    "\n",
    "        text = text.replace('\\tbи', '\\tви')\n",
    "        \n",
    "        text = text.replace('\\tmи', '\\tми')\n",
    "        text = text.replace('\\tmн', '\\tмн')\n",
    "        text = text.replace('\\tmы', '\\tмы')\n",
    "        text = text.replace('\\tmе', '\\tме')\n",
    "        text = text.replace('\\tmэ', '\\tмэ')\n",
    "        text = text.replace('\\tmо', '\\tмо')\n",
    "        text = text.replace('\\tmа', '\\tма')\n",
    "        text = text.replace('\\tmм', '\\tмм')\n",
    "\n",
    "        text = text.replace('\\ttoг', '\\tтог')\n",
    "        text = text.replace('\\ttoн', '\\tтон')\n",
    "        text = text.replace('\\ttoм', '\\tтом')\n",
    "        \n",
    "        text = text.replace('\" звини', 'извини')\n",
    "        text = text.replace('ј', 'а')\n",
    "        text = text.replace('¬', 'в')\n",
    "        text = text.replace('√', 'г')\n",
    "        text = text.replace('ƒ', 'д')\n",
    "        text = text.replace('∆', 'ж')\n",
    "\n",
    "        text = text.replace('ёто', 'это')\n",
    "\n",
    "        text = text.replace('ћаркони', 'маркони')\n",
    "        text = text.replace('ћама', 'мама')\n",
    "        text = text.replace('ћадно', 'ладно')\n",
    "        text = text.replace('ћа', 'ла')\n",
    "        text = text.replace('ћю', 'лю')\n",
    "        text = text.replace('ћ', 'м')\n",
    "        text = text.replace('єм', 'ём')\n",
    "        text = text.replace('єл', 'ял')\n",
    "        text = text.replace('\" є', 'чё') # \" єрт\n",
    "        text = text.replace(' є', ' я')\n",
    "        text = text.replace('є', 'ё')\n",
    "        text = text.replace('€', 'я')\n",
    "        text = text.replace('\\t\" ы', '\\tты')\n",
    "        text = text.replace('\\t\" й', '\\tуй')\n",
    "        text = text.replace('\\t\" олько', '\\tтолько')\n",
    "        text = text.replace('\\t\" о есть', '\\tто есть')\n",
    "    with open(file_name[:-4] + '_' + file_name[-4:], 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "correct_encoding('train.tsv')\n",
    "correct_encoding('final.tsv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "# зачистка текста от знаков препинания\n",
    "import re\n",
    "def replace_punctuation(field_name):\n",
    "    all_data[field_name] = [re.sub('[\\♪\\?\\.\\!\\/\\;\\:\\`\\'\\\"\\:\\(\\)\\<\\>\\—\\–\\-\\$\\/\\\\\\*\\%\\~\\#\\=\\_\\¶\\d\\№\\{\\}\\[\\]]', '', row) for row in all_data[field_name]]\n",
    "    all_data[field_name] = all_data[field_name].str.replace('  ', ' ')\n",
    "    all_data[field_name] = all_data[field_name].str.replace('  ', ' ')\n",
    "replace_punctuation('reply')\n",
    "replace_punctuation('context_0')\n",
    "replace_punctuation('context_1')\n",
    "replace_punctuation('context_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вычисление признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# длина ответа в символах\n",
    "all_data['reply_char_len'] = train['reply'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# делим на слова, помещаем их в списки\n",
    "field_name = 'reply'\n",
    "all_data[field_name+'_words'] = [re.sub(\"[^a-zа-яё]\",\" \", field).lower().split() for field in all_data[field_name]]\n",
    "field_name = 'context_0'\n",
    "all_data[field_name+'_words'] = [re.sub(\"[^a-zа-яё]\",\" \", field).lower().split() for field in all_data[field_name]]\n",
    "field_name = 'context_1'\n",
    "all_data[field_name+'_words'] = [re.sub(\"[^a-zа-яё]\",\" \", field).lower().split() for field in all_data[field_name]]\n",
    "field_name = 'context_2'\n",
    "all_data[field_name+'_words'] = [re.sub(\"[^a-zа-яё]\",\" \", field).lower().split() for field in all_data[field_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# длина ближайшего контекста и ответа в словах\n",
    "field_name = 'reply'\n",
    "all_data[field_name+'_word_len'] = all_data[field_name+'_words'].apply(lambda x: len(x))\n",
    "field_name = 'context_0'\n",
    "all_data[field_name+'_word_len'] = all_data[field_name+'_words'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Количество и доля одинаковых слов в вопросе и в отвее\n",
    "all_data['reply_context_0_intersection_count'] = [len(set(row.loc['reply_words']).intersection(row.loc['context_0_words'])) for index, row in all_data.iterrows()]\n",
    "all_data['reply_context_0_intersection_part'] = [len(set(row.loc['reply_words']).intersection(row.loc['context_0_words']))/(len(set(row.loc['reply_words']))+1) for index, row in all_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фразы полностью совпадает\n",
    "all_data['reply_equel_context_0'] = False\n",
    "all_data.loc[all_data['context_0'] == all_data['reply'], 'reply_equel_context_0'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['reply_equel_context_1'] = False\n",
    "all_data.loc[all_data['context_1'] == all_data['reply'], 'reply_equel_context_1'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['reply_equel_context_2'] = False\n",
    "all_data.loc[all_data['context_2'] == all_data['reply'], 'reply_equel_context_2'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 259 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# фразы типа -он всё знает, -что значит \"всё знает\"\n",
    "all_data['what_mean'] = all_data['reply'].str.extract('что значит ([^?]*) ?', expand=False).str.strip()\n",
    "all_data['what_mean_same'] = False\n",
    "all_data.loc[all_data['what_mean'].notnull(), 'what_mean_same'] = [x[0] in x[1] for x in zip(all_data[all_data['what_mean'].notnull()]['what_mean'], all_data[all_data['what_mean'].notnull()]['context_0'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка, что что-то нашлось\n",
    "len(all_data[all_data['what_mean'].notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data[all_data['what_mean_same']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# первое слово\n",
    "field_name = 'reply'\n",
    "all_data[field_name + '_first_word'] = ''\n",
    "all_data[field_name + '_first_word'] = all_data[all_data[field_name + '_word_len'] > 0][field_name + '_words'].apply(lambda x: x[0])\n",
    "all_data[field_name + '_first_word'].fillna('', inplace=True)\n",
    "field_name = 'context_0'\n",
    "all_data[field_name + '_first_word'] = ''\n",
    "all_data[field_name + '_first_word'] = all_data[all_data[field_name + '_word_len'] > 0][field_name + '_words'].apply(lambda x: x[0])\n",
    "all_data[field_name + '_first_word'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# последнее слово\n",
    "field_name = 'reply'\n",
    "all_data[field_name + '_last_word'] = ''\n",
    "all_data[field_name + '_last_word'] = all_data[all_data[field_name + '_word_len'] > 0][field_name + '_words'].apply(lambda x: x[-1])\n",
    "all_data[field_name + '_last_word'].fillna('', inplace=True)\n",
    "field_name = 'context_0'\n",
    "all_data[field_name + '_last_word'] = ''\n",
    "all_data[field_name + '_last_word'] = all_data[all_data[field_name + '_word_len'] > 0][field_name + '_words'].apply(lambda x: x[-1])\n",
    "all_data[field_name + '_last_word'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наличие местоимений в вопросе и ответе\n",
    "# ты - я\n",
    "all_data['you_i'] = False\n",
    "all_data.loc[all_data['context_0_words'].apply(lambda x: 'ты' in x) & all_data['reply_words'].apply(lambda x: 'я' in x), 'you_i'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# я - ты\n",
    "all_data['i_you'] = False\n",
    "all_data.loc[all_data['context_0_words'].apply(lambda x: 'я' in x) & all_data['reply_words'].apply(lambda x: 'ты' in x), 'i_you'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# он - он\n",
    "all_data['he_he'] = False\n",
    "all_data.loc[all_data['context_0_words'].apply(lambda x: 'он' in x) & all_data['reply_words'].apply(lambda x: 'он' in x), 'he_he'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# она - она\n",
    "all_data['she_she'] = False\n",
    "all_data.loc[all_data['context_0_words'].apply(lambda x: 'она' in x) & all_data['reply_words'].apply(lambda x: 'она' in x), 'she_she'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# учёт различных приветствий \n",
    "# возможно тут лучше было сделать 3 значения\n",
    "# - нет приветствия ни в одной из фраз\n",
    "# - есть приветствие только в одной из фраз\n",
    "# - есть соответствующие приветствия в обеих фразах (да и соответствие я не учитывал)\n",
    "greetings = ['привет', 'прощай', 'прощайте', 'спокойной ночи', 'доброй ночи', 'добрый вечер', 'добрый день', 'сладких снов', 'здравствуй', 'здравствуйте', 'пока', 'салют', 'алло', 'до свидания', 'всего доброго', 'здорово', 'здоров', 'хай', 'бывайте', 'бывай', 'будь', 'до встречи', 'увидемся', 'услышимся']\n",
    "thanks = ['спасибо', 'благодарю', 'благодарен', 'благодарим']\n",
    "wellcome = ['пожалуйста', 'не за что', 'незачто', 'на здоровье', 'не стоит благодарности', 'мелочи', 'обращайтесь']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['hello_hello'] = False\n",
    "all_data.loc[all_data['context_0_words'].apply(lambda x: any(gr in x for gr in greetings)) & all_data['reply_words'].apply(lambda x: any(gr in x for gr in greetings)), 'hello_hello'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 808)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим, что получилось\n",
    "len(all_data[all_data['hello_hello'] & all_data['is_train']]), len(all_data[all_data['hello_hello'] & ~all_data['is_train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['thanks_wellcome'] = False\n",
    "all_data.loc[all_data['context_0_words'].apply(lambda x: any(gr in x for gr in thanks)) & all_data['reply_words'].apply(lambda x: any(gr in x for gr in wellcome)), 'thanks_wellcome'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 294)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим, что получилось\n",
    "len(all_data[all_data['thanks_wellcome'] & all_data['is_train']]), len(all_data[all_data['thanks_wellcome'] & ~all_data['is_train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вопросительное предложение\n",
    "field_name = 'reply'\n",
    "all_data[field_name + '_question'] = all_data[field_name].apply(lambda x: x[-1:])=='?'\n",
    "field_name = 'context_0'\n",
    "all_data[field_name + '_question'] = all_data[field_name].apply(lambda x: x[-1:])=='?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление грамматических признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# грамматические признаки первого и последнего слова\n",
    "# наличие грамматической характеристики во фразе\n",
    "# использование \"at\" на порядок ускоряет вычисления\n",
    "\n",
    "def make_gramma(df, field_names):\n",
    "    for field_name in field_names:\n",
    "        df[field_name + '_gramm_order'] = '' # порядок следования частей речи во фразе\n",
    "\n",
    "        df[field_name + '_gramm_pos_first'] = ''\n",
    "        df[field_name + '_gramm_case_first'] = ''\n",
    "        df[field_name + '_gramm_gender_first'] = ''\n",
    "        df[field_name + '_gramm_number_first'] = ''\n",
    "        df[field_name + '_gramm_animacy_first'] = ''\n",
    "        df[field_name + '_gramm_tense_first'] = ''\n",
    "        df[field_name + '_gramm_aspect_first'] = ''\n",
    "        df[field_name + '_gramm_person_first'] = ''\n",
    "        df[field_name + '_gramm_involvement_first'] = ''\n",
    "        df[field_name + '_gramm_mood_first'] = ''\n",
    "        df[field_name + '_gramm_transitivity_first'] = ''\n",
    "        df[field_name + '_gramm_voice_first'] = ''\n",
    "        \n",
    "        df[field_name + '_gramm_pos_last'] = ''\n",
    "        df[field_name + '_gramm_case_last'] = ''\n",
    "        df[field_name + '_gramm_gender_last'] = ''\n",
    "        df[field_name + '_gramm_number_last'] = ''\n",
    "        df[field_name + '_gramm_animacy_last'] = ''\n",
    "        df[field_name + '_gramm_tense_last'] = ''\n",
    "        df[field_name + '_gramm_aspect_last'] = ''\n",
    "        df[field_name + '_gramm_person_last'] = ''\n",
    "        df[field_name + '_gramm_involvement_last'] = ''\n",
    "        df[field_name + '_gramm_mood_last'] = ''\n",
    "        df[field_name + '_gramm_transitivity_last'] = ''\n",
    "        df[field_name + '_gramm_voice_last'] = ''\n",
    "\n",
    "        df[field_name + '_gramm_name'] = False\n",
    "        df[field_name + '_gramm_surn'] = False\n",
    "        df[field_name + '_gramm_patr'] = False\n",
    "        df[field_name + '_gramm_geox'] = False\n",
    "        df[field_name + '_gramm_orgn'] = False\n",
    "        df[field_name + '_gramm_qual'] = False\n",
    "        df[field_name + '_gramm_anum'] = False\n",
    "        df[field_name + '_gramm_apro'] = False\n",
    "    for i, row in df.iterrows():\n",
    "        for field_name in field_names:\n",
    "            for word in row[field_name + '_words']:\n",
    "                sem = morph.parse(word)[0]\n",
    "                if sem.tag.POS:\n",
    "                    df.at[i, field_name + '_gramm_order'] += str(sem.tag.POS)\n",
    "                    if df.at[i, field_name + '_gramm_pos_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_pos_first'] = str(sem.tag.POS)\n",
    "                    df.at[i, field_name + '_gramm_pos_last'] = str(sem.tag.POS)\n",
    "                    df.at[i, field_name + '_gramm_pos_' + sem.tag.POS] = True\n",
    "                if sem.tag.case:\n",
    "                    if df.at[i, field_name + '_gramm_case_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_case_first'] = str(sem.tag.case)\n",
    "                    df.at[i, field_name + '_gramm_case_last'] = str(sem.tag.case)\n",
    "                    df.at[i, field_name + '_gramm_case_' + sem.tag.case] = True\n",
    "                if sem.tag.gender:\n",
    "                    if df.at[i, field_name + '_gramm_gender_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_gender_first'] = str(sem.tag.gender)\n",
    "                    df.at[i, field_name + '_gramm_gender_last'] = str(sem.tag.gender)\n",
    "                    df.at[i, field_name + '_gramm_gender_' + sem.tag.gender] = True\n",
    "                if sem.tag.number:\n",
    "                    if df.at[i, field_name + '_gramm_number_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_number_first'] = str(sem.tag.number)\n",
    "                    df.at[i, field_name + '_gramm_number_last'] = str(sem.tag.number)\n",
    "                    df.at[i, field_name + '_gramm_number_' + sem.tag.number] = True\n",
    "                if sem.tag.animacy:\n",
    "                    if df.at[i, field_name + '_gramm_animacy_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_animacy_first'] = str(sem.tag.animacy)\n",
    "                    df.at[i, field_name + '_gramm_animacy_last'] = str(sem.tag.animacy)\n",
    "                    df.at[i, field_name + '_gramm_animacy_' + sem.tag.animacy] = True\n",
    "                if sem.tag.tense:\n",
    "                    if df.at[i, field_name + '_gramm_tense_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_tense_first'] = str(sem.tag.tense)\n",
    "                    df.at[i, field_name + '_gramm_tense_last'] = str(sem.tag.tense)\n",
    "                    df.at[i, field_name + '_gramm_tense_' + sem.tag.tense] = True\n",
    "                if sem.tag.aspect:\n",
    "                    if df.at[i, field_name + '_gramm_aspect_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_aspect_first'] = str(sem.tag.aspect)\n",
    "                    df.at[i, field_name + '_gramm_aspect_last'] = str(sem.tag.aspect)\n",
    "                    df.at[i, field_name + '_gramm_aspect_' + sem.tag.aspect] = True\n",
    "                if sem.tag.person:\n",
    "                    if df.at[i, field_name + '_gramm_person_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_person_first'] = str(sem.tag.person)\n",
    "                    df.at[i, field_name + '_gramm_person_last'] = str(sem.tag.person)\n",
    "                    df.at[i, field_name + '_gramm_person_' + sem.tag.person] = True\n",
    "                if sem.tag.involvement:\n",
    "                    if df.at[i, field_name + '_gramm_involvement_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_involvement_first'] = str(sem.tag.involvement)\n",
    "                    df.at[i, field_name + '_gramm_involvement_last'] = str(sem.tag.involvement)\n",
    "                    df.at[i, field_name + '_gramm_involvement_' + sem.tag.involvement] = True\n",
    "                if sem.tag.mood:\n",
    "                    if df.at[i, field_name + '_gramm_mood_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_mood_first'] = str(sem.tag.mood)\n",
    "                    df.at[i, field_name + '_gramm_mood_last'] = str(sem.tag.mood)\n",
    "                    df.at[i, field_name + '_gramm_mood_' + sem.tag.mood] = True\n",
    "                if sem.tag.transitivity:\n",
    "                    if df.at[i, field_name + '_gramm_transitivity_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_transitivity_first'] = str(sem.tag.transitivity)\n",
    "                    df.at[i, field_name + '_gramm_transitivity_last'] = str(sem.tag.transitivity)\n",
    "                    df.at[i, field_name + '_gramm_transitivity_' + sem.tag.transitivity] = True\n",
    "                if sem.tag.voice:\n",
    "                    if df.at[i, field_name + '_gramm_voice_first'] == '':\n",
    "                        df.at[i, field_name + '_gramm_voice_first'] = str(sem.tag.voice)\n",
    "                    df.at[i, field_name + '_gramm_voice_last'] = str(sem.tag.voice)\n",
    "                    df.at[i, field_name + '_gramm_voice_' + sem.tag.voice] = True\n",
    "                \n",
    "                if ~df.at[i, field_name + '_gramm_name']:\n",
    "                    df.at[i, field_name + '_gramm_name'] = 'Name' in sem.tag\n",
    "                if ~df.at[i, field_name + '_gramm_surn']:\n",
    "                    df.at[i, field_name + '_gramm_surn'] = 'Surn' in sem.tag\n",
    "                if ~df.at[i, field_name + '_gramm_patr']:\n",
    "                    df.at[i, field_name + '_gramm_patr'] = 'Patr' in sem.tag\n",
    "                if ~df.at[i, field_name + '_gramm_geox']:\n",
    "                    df.at[i, field_name + '_gramm_geox'] = 'Geox' in sem.tag\n",
    "                if ~df.at[i, field_name + '_gramm_orgn']:\n",
    "                    df.at[i, field_name + '_gramm_orgn'] = 'Orgn' in sem.tag\n",
    "                if ~df.at[i, field_name + '_gramm_qual']:\n",
    "                    df.at[i, field_name + '_gramm_qual'] = 'Qual' in sem.tag\n",
    "                if ~df.at[i, field_name + '_gramm_anum']:\n",
    "                    df.at[i, field_name + '_gramm_anum'] = 'Anum' in sem.tag\n",
    "                if ~df.at[i, field_name + '_gramm_apro']:\n",
    "                    df.at[i, field_name + '_gramm_apro'] = 'Apro' in sem.tag\n",
    "    df.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_gramma(all_data, ['reply', 'context_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверяем одинаковы ли род, время, число для слов контекста и ответа\n",
    "надо помнить, что это делается только для последнего слова во фразе имеющего грамматическую характеристику такого типа, а не для, скажем, подлежащего или сказуемого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# совпадения для первых слов\n",
    "# совпадает падеж\n",
    "all_data['reply_first_context_0_first_same_case'] = False\n",
    "all_data.loc[all_data['context_0_gramm_case_first'] == all_data['reply_gramm_case_first'], 'reply_first_context_0_first_same_case'] = True\n",
    "\n",
    "# совпадает род\n",
    "all_data['reply_first_context_0_first_same_gender'] = False\n",
    "all_data.loc[all_data['context_0_gramm_gender_first'] == all_data['reply_gramm_gender_first'], 'reply_first_context_0_first_same_gender'] = True\n",
    "\n",
    "# совпадает число\n",
    "all_data['reply_first_context_0_first_same_number'] = False\n",
    "all_data.loc[all_data['context_0_gramm_number_first'] == all_data['reply_gramm_number_first'], 'reply_first_context_0_first_same_number'] = True\n",
    "\n",
    "# совпадает время\n",
    "all_data['reply_first_context_0_first_same_tense'] = False\n",
    "all_data.loc[all_data['context_0_gramm_tense_first'] == all_data['reply_gramm_tense_first'], 'reply_first_context_0_first_same_tense'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# совпадения для первых слов ответа с последним словом контекста\n",
    "# совпадает падеж\n",
    "all_data['reply_first_context_0_last_same_case'] = False\n",
    "all_data.loc[all_data['context_0_gramm_case_last'] == all_data['reply_gramm_case_first'], 'reply_first_context_0_last_same_case'] = True\n",
    "\n",
    "# совпадает род\n",
    "all_data['reply_first_context_0_last_same_gender'] = False\n",
    "all_data.loc[all_data['context_0_gramm_gender_last'] == all_data['reply_gramm_gender_first'], 'reply_first_context_0_last_same_gender'] = True\n",
    "\n",
    "# совпадает число\n",
    "all_data['reply_first_context_0_last_same_number'] = False\n",
    "all_data.loc[all_data['context_0_gramm_number_last'] == all_data['reply_gramm_number_first'], 'reply_first_context_0_last_same_number'] = True\n",
    "\n",
    "# совпадает время\n",
    "all_data['reply_first_context_0_last_same_tense'] = False\n",
    "all_data.loc[all_data['context_0_gramm_tense_last'] == all_data['reply_gramm_tense_first'], 'reply_first_context_0_last_same_tense'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# совпадает третье лицо\n",
    "all_data['reply_context_0_same_3per'] = False\n",
    "all_data.loc[all_data['context_0_gramm_person_3per'] & all_data['reply_gramm_person_3per'], 'reply_context_0_same_3per'] = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# признак представляющий сочетание порядка частей речи в вопросе и ответе\n",
    "# казалось должно было помочь, но оказалось, что ухудшает\n",
    "all_data['context_0_reply_gramm_order'] = (all_data['context_0_gramm_order']+'_'+all_data['reply_gramm_order'])\n",
    "# удалим низкочастотные сочетания частей речи\n",
    "col = 'context_0_reply_gramm_order'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = '<RARE_VALUE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитав материалы очередного семинара курса DMiA, решил, что будет полезно избавится от низкочастотных значений, так и оказалось, скор существенно вырос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим низкочастотные фразы и сочетания частей речи\n",
    "col = 'reply_gramm_order'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = '<RARE_VALUE>'\n",
    "\n",
    "col = 'context_0_gramm_order'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = '<RARE_VALUE>'\n",
    "\n",
    "col = 'reply'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = '<RARE_VALUE>'\n",
    "\n",
    "col = 'context_0'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = '<RARE_VALUE>'\n",
    "\n",
    "col = 'context_1'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = '<RARE_VALUE>'\n",
    "\n",
    "col = 'context_2'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = '<RARE_VALUE>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим низкочастотные первые слова\n",
    "col = 'reply_first_word'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = ''\n",
    "\n",
    "col = 'context_0_first_word'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим низкочастотные последние слова\n",
    "col = 'reply_last_word'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = ''\n",
    "\n",
    "col = 'context_0_last_word'\n",
    "new_col = col + '_rife'\n",
    "all_data[new_col] = all_data[col]\n",
    "all_data.loc[all_data[new_col].value_counts()[all_data[new_col]].values < 30, new_col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 840 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = all_data[all_data['is_train']].drop(['is_train'], axis = 1)\n",
    "test = all_data[~all_data['is_train']].drop(['is_train'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['confidence', 'confidence_delta', 'context_0', 'context_1', 'context_2',\n",
       "        'context_id', 'label', 'label_num', 'reply', 'reply_id',\n",
       "        ...\n",
       "        'reply_gramm_order_rife', 'context_0_gramm_order_rife', 'reply_rife',\n",
       "        'context_0_rife', 'context_1_rife', 'context_2_rife',\n",
       "        'reply_first_word_rife', 'context_0_first_word_rife',\n",
       "        'reply_last_word_rife', 'context_0_last_word_rife'],\n",
       "       dtype='object', length=220),\n",
       " Index(['confidence', 'confidence_delta', 'context_0', 'context_1', 'context_2',\n",
       "        'context_id', 'label', 'label_num', 'reply', 'reply_id',\n",
       "        ...\n",
       "        'reply_gramm_order_rife', 'context_0_gramm_order_rife', 'reply_rife',\n",
       "        'context_0_rife', 'context_1_rife', 'context_2_rife',\n",
       "        'reply_first_word_rife', 'context_0_first_word_rife',\n",
       "        'reply_last_word_rife', 'context_0_last_word_rife'],\n",
       "       dtype='object', length=220))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проконтролируем результат\n",
    "train.columns, test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подсчитаем частоту слов (на частотные слова следует обратить особенное внимание)\n",
    "для диалогов частотными оказались местоимения, поэтому для них делал отдельные фичи (далеко не все что можно было бы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('я', 17413), ('не', 14793), ('что', 12126), ('ты', 9693), ('это', 8703), ('и', 7864), ('в', 7794), ('на', 4573), ('с', 4466), ('нет', 4158), ('он', 4036), ('да', 3847), ('мы', 3734), ('как', 3565), ('мне', 3560), ('вы', 3476), ('меня', 3167), ('у', 3137), ('так', 3126), ('но', 3041), ('то', 2895), ('тебя', 2728), ('а', 2640), ('его', 2283), ('она', 2280), ('все', 2203), ('о', 2117), ('тебе', 2115), ('за', 1945), ('если', 1898), ('бы', 1808), ('просто', 1661), ('есть', 1501), ('они', 1474), ('ну', 1459), ('кто', 1456), ('хорошо', 1446), ('из', 1435), ('чтобы', 1435), ('же', 1426), ('знаю', 1375), ('здесь', 1353), ('для', 1282), ('может', 1245), ('по', 1245), ('только', 1244), ('когда', 1240), ('было', 1219), ('вот', 1162), ('спасибо', 1161), ('всё', 1159), ('был', 1109), ('быть', 1092), ('вас', 1086), ('могу', 1081), ('почему', 1048), ('хочу', 1020), ('нас', 1015), ('к', 1001), ('где', 945), ('вам', 936), ('ладно', 920), ('нужно', 912), ('будет', 907), ('уже', 901), ('знаешь', 889), ('очень', 884), ('нам', 878), ('от', 878), ('еще', 867), ('или', 866), ('сейчас', 856), ('ее', 853), ('чем', 848), ('этого', 846), ('думаю', 833), ('ничего', 819), ('была', 815), ('там', 735), ('их', 728), ('мой', 713), ('давай', 709), ('теперь', 695), ('этом', 690), ('надо', 682), ('потому', 671), ('больше', 657), ('сказал', 657), ('привет', 643), ('тоже', 642), ('пока', 627), ('её', 624), ('можешь', 622), ('эй', 605), ('со', 603), ('до', 592), ('время', 587), ('тут', 586), ('хочешь', 583), ('конечно', 562)]\n"
     ]
    }
   ],
   "source": [
    "# в train context_0\n",
    "words = list(itertools.chain(*train['context_0_words']))\n",
    "print(Counter(words).most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('не', 17451), ('я', 17294), ('что', 11145), ('и', 8513), ('ты', 7065), ('нет', 6605), ('это', 6423), ('в', 6382), ('да', 5811), ('он', 4641), ('мы', 3513), ('но', 3204), ('на', 3162), ('с', 3145), ('а', 3080), ('мне', 2961), ('она', 2837), ('меня', 2783), ('его', 2728), ('вы', 2542), ('у', 2493), ('то', 2407), ('тебя', 2390), ('как', 2292), ('так', 2238), ('хорошо', 1892), ('за', 1882), ('все', 1840), ('тебе', 1823), ('знаю', 1761), ('ничего', 1715), ('тоже', 1687), ('о', 1634), ('ну', 1499), ('если', 1488), ('просто', 1382), ('они', 1365), ('бы', 1363), ('же', 1358), ('тогда', 1357), ('был', 1241), ('есть', 1207), ('здесь', 1160), ('очень', 1159), ('может', 1149), ('только', 1136), ('конечно', 1131), ('для', 1100), ('было', 1067), ('могу', 1044), ('потому', 1003), ('чтобы', 992), ('спасибо', 975), ('ее', 971), ('из', 942), ('быть', 939), ('вас', 936), ('будет', 903), ('кто', 887), ('всё', 871), ('хочу', 864), ('вот', 858), ('уже', 858), ('думаю', 855), ('по', 836), ('еще', 834), ('нас', 833), ('чем', 831), ('вам', 773), ('значит', 771), ('знаешь', 768), ('её', 755), ('когда', 748), ('всегда', 745), ('к', 729), ('там', 708), ('от', 700), ('нужно', 697), ('ему', 685), ('ладно', 682), ('была', 665), ('почему', 653), ('их', 639), ('сказал', 631), ('можешь', 631), ('или', 630), ('сейчас', 626), ('раз', 614), ('пока', 600), ('до', 591), ('порядке', 586), ('этого', 585), ('нам', 579), ('надо', 578), ('где', 576), ('давай', 556), ('пожалуйста', 555), ('правда', 551), ('со', 547), ('должен', 546)]\n"
     ]
    }
   ],
   "source": [
    "# в train reply\n",
    "words = list(itertools.chain(*train['reply_words']))\n",
    "print(Counter(words).most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('я', 18547), ('не', 16072), ('что', 14017), ('ты', 11069), ('это', 9266), ('и', 8742), ('в', 8676), ('на', 5042), ('с', 4480), ('нет', 4292), ('да', 4195), ('он', 4104), ('мы', 4069), ('мне', 4042), ('как', 3813), ('вы', 3807), ('у', 3612), ('меня', 3577), ('так', 3434), ('то', 3330), ('но', 3050), ('а', 2961), ('тебя', 2703), ('все', 2679), ('она', 2645), ('о', 2430), ('его', 2356), ('тебе', 2201), ('если', 2138), ('за', 2086), ('бы', 1835), ('просто', 1806), ('знаю', 1737), ('же', 1727), ('хорошо', 1726), ('кто', 1623), ('ну', 1620), ('здесь', 1602), ('они', 1601), ('чтобы', 1566), ('когда', 1479), ('всё', 1464), ('из', 1449), ('есть', 1440), ('был', 1383), ('было', 1272), ('для', 1245), ('по', 1234), ('вас', 1198), ('только', 1185), ('может', 1174), ('нас', 1147), ('могу', 1141), ('почему', 1132), ('к', 1080), ('от', 1060), ('вот', 1058), ('спасибо', 1029), ('знаешь', 1029), ('уже', 1020), ('чем', 1002), ('быть', 1000), ('нужно', 998), ('сейчас', 993), ('ладно', 981), ('будет', 972), ('хочу', 960), ('еще', 956), ('нам', 935), ('где', 912), ('ничего', 879), ('очень', 864), ('была', 863), ('ее', 856), ('или', 852), ('этого', 852), ('вам', 840), ('со', 836), ('думаю', 833), ('привет', 782), ('давай', 780), ('этом', 774), ('больше', 761), ('мой', 756), ('потому', 753), ('там', 748), ('теперь', 748), ('хочешь', 734), ('время', 728), ('их', 728), ('до', 720), ('нибудь', 708), ('надо', 680), ('никогда', 672), ('мной', 668), ('ему', 636), ('сказать', 629), ('ли', 626), ('раз', 624), ('пожалуйста', 624)]\n"
     ]
    }
   ],
   "source": [
    "# в test context_0\n",
    "words = list(itertools.chain(*test['context_0_words']))\n",
    "print(Counter(words).most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('не', 18990), ('я', 18641), ('что', 11989), ('и', 9118), ('ты', 7861), ('нет', 7033), ('это', 6984), ('в', 6727), ('да', 6354), ('он', 5229), ('мы', 3761), ('но', 3500), ('на', 3480), ('с', 3292), ('а', 3201), ('мне', 3061), ('она', 3035), ('меня', 2939), ('его', 2837), ('вы', 2791), ('у', 2639), ('то', 2537), ('как', 2479), ('так', 2376), ('тебя', 2364), ('хорошо', 2072), ('за', 2058), ('тебе', 2009), ('знаю', 1955), ('ничего', 1945), ('все', 1943), ('о', 1899), ('тоже', 1831), ('просто', 1672), ('ну', 1650), ('бы', 1587), ('если', 1581), ('же', 1533), ('они', 1494), ('тогда', 1424), ('был', 1415), ('есть', 1362), ('здесь', 1273), ('может', 1247), ('только', 1242), ('конечно', 1194), ('очень', 1149), ('для', 1144), ('было', 1142), ('потому', 1090), ('чтобы', 1090), ('могу', 1047), ('вас', 1041), ('ее', 1030), ('кто', 995), ('быть', 971), ('еще', 962), ('из', 960), ('спасибо', 951), ('будет', 945), ('думаю', 945), ('всё', 943), ('знаешь', 924), ('чем', 909), ('хочу', 900), ('по', 891), ('нас', 890), ('вот', 884), ('уже', 875), ('когда', 854), ('к', 840), ('ему', 839), ('значит', 837), ('от', 832), ('вам', 803), ('её', 783), ('ладно', 749), ('всегда', 746), ('нужно', 738), ('почему', 738), ('этого', 727), ('сейчас', 709), ('давай', 694), ('сказал', 691), ('порядке', 683), ('там', 682), ('была', 681), ('можешь', 679), ('нам', 672), ('их', 670), ('правда', 661), ('раз', 659), ('или', 650), ('должен', 638), ('до', 632), ('надо', 617), ('мой', 608), ('ей', 604), ('со', 600), ('где', 585)]\n"
     ]
    }
   ],
   "source": [
    "# в test reply\n",
    "words = list(itertools.chain(*test['reply_words']))\n",
    "print(Counter(words).most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.528119\n",
       "bad        0.356495\n",
       "neutral    0.115387\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# распределение оценок\n",
    "train['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем распределение оценок для разных признаков, если их распределение совпадает с основным, то вероятно этот признак не будет иметь большого значения. Но так как оставалась надежда на сочетания разных признаков, то всё равно все оставил."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad        0.867889\n",
       "neutral    0.099874\n",
       "good       0.032238\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['reply_equel_context_0']==True]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.754601\n",
       "neutral    0.205521\n",
       "bad        0.039877\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['thanks_wellcome']]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подсчитаем частоту сочетаний личных местоимений (примерно, не учитываются местоимения в начале фразы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.673664\n",
       "bad        0.297710\n",
       "neutral    0.028626\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' он ') & train['reply'].str.contains(' он ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.597561\n",
       "bad        0.394309\n",
       "neutral    0.008130\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' она ') & train['reply'].str.contains(' она ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    0.75\n",
       "bad     0.25\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' он ') & train['reply'].str.contains(' она ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.500000\n",
       "bad        0.428571\n",
       "neutral    0.071429\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' она ') & train['reply'].str.contains(' он ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.549020\n",
       "bad        0.397759\n",
       "neutral    0.053221\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' я ') & train['reply'].str.contains(' я ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.624044\n",
       "bad        0.345355\n",
       "neutral    0.030601\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' я ') & train['reply'].str.contains(' ты ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       722\n",
       "bad        326\n",
       "neutral     89\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' ты ') & train['reply'].str.contains(' я ')]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.594891\n",
       "bad        0.375912\n",
       "neutral    0.029197\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' ты ') & train['reply'].str.contains(' ты ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad        0.689655\n",
       "neutral    0.172414\n",
       "good       0.137931\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_0'].str.contains(' тоже ') & train['reply'].str.contains(' тоже ')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad        0.867889\n",
       "neutral    0.099874\n",
       "good       0.032238\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# совпадение контекста и ответа\n",
    "train[train['context_0'] == train['reply']]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad        0.923529\n",
       "neutral    0.047059\n",
       "good       0.029412\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_1'] == train['reply']]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad        0.875000\n",
       "neutral    0.065217\n",
       "good       0.059783\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['context_2'] == train['reply']]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1747"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Количество эпизодов у которых совпадает контекст и ответ\n",
    "len(test[test['context_0'] == test['reply']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[test['context_1'] == test['reply']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[test['context_2'] == test['reply']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       0.721088\n",
       "bad        0.217687\n",
       "neutral    0.061224\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сочетания что значит\n",
    "train[train['reply'].str.contains('что значит')]['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train['reply'].str.contains('что значит')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "да                                                                                                              338\n",
       "хорошо                                                                                                          250\n",
       "нет                                                                                                             222\n",
       "спасибо                                                                                                         195\n",
       "отлично                                                                                                         182\n",
       "ничего                                                                                                          177\n",
       "что ?                                                                                                           169\n",
       "хороший да ?                                                                                                    167\n",
       "пожалуйста                                                                                                      148\n",
       "ладно                                                                                                           142\n",
       "                                                                                                                130\n",
       "не за что                                                                                                       129\n",
       "и я не мог его достать                                                                                          101\n",
       "привет                                                                                                          100\n",
       "что значит нет ?                                                                                                 90\n",
       "прости                                                                                                           84\n",
       "конечно                                                                                                          82\n",
       "тогда я попытался с двумя другими женщинами и они обе уничтожили меня                                            78\n",
       "всегда пожалуйста                                                                                                77\n",
       "я знаю                                                                                                           75\n",
       "пока                                                                                                             69\n",
       "правда                                                                                                           69\n",
       "прекрасно                                                                                                        66\n",
       "какой идиот                                                                                                      65\n",
       "ага                                                                                                              61\n",
       "давай                                                                                                            61\n",
       "пошли                                                                                                            56\n",
       "я тоже                                                                                                           54\n",
       "я не могу                                                                                                        53\n",
       "простите                                                                                                         52\n",
       "                                                                                                               ... \n",
       "да напряженно                                                                                                     1\n",
       "приподнимись                                                                                                      1\n",
       "ревную ? ты шутишь ?                                                                                              1\n",
       "у него было полно шансов помочь                                                                                   1\n",
       "я ненавижу джаз                                                                                                   1\n",
       "тогда давай вести себя как друзья                                                                                 1\n",
       "и он только что чуть не откусил мне голову                                                                        1\n",
       "решай ты                                                                                                          1\n",
       "он был слишком поверхностным                                                                                      1\n",
       "а твой брат                                                                                                       1\n",
       "ты винишь меня                                                                                                    1\n",
       "быть не могло                                                                                                     1\n",
       "хорошо чжон хён                                                                                                   1\n",
       "я тебя больше                                                                                                     1\n",
       "мы могли не спать вместе                                                                                          1\n",
       "он очень маленький                                                                                                1\n",
       "рад тебя здесь видеть                                                                                             1\n",
       "я так не говорю                                                                                                   1\n",
       "ничего э просто работа меня достала                                                                               1\n",
       "у нас должна быть власть                                                                                          1\n",
       "похоже на какую то энергию может на статическое электричество ?                                                   1\n",
       "эй знаешь я могу их покормить                                                                                     1\n",
       "она была в сильном смятении из за того что пострадала                                                             1\n",
       "а подружка невесты та рыженькая ?                                                                                 1\n",
       "похоже она знает о нас слишком личные подробности                                                                 1\n",
       " эйн                                                                                                              1\n",
       "поскольку я не твоя жена раз ты был недееспособен получается что решения за тебя могут принимать только они       1\n",
       "с лего мы не шутим                                                                                                1\n",
       "нет милая я всегда буду любить тебя                                                                               1\n",
       "поэтому я обязательно должен был поехать                                                                          1\n",
       "Name: reply, Length: 67778, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# частота различных ответов в train\n",
    "train['reply'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "да                                                                   415\n",
       "хорошо                                                               297\n",
       "нет                                                                  249\n",
       "что ?                                                                208\n",
       "ничего                                                               190\n",
       "отлично                                                              185\n",
       "спасибо                                                              169\n",
       "ладно                                                                167\n",
       "пожалуйста                                                           148\n",
       "                                                                     146\n",
       "привет                                                               125\n",
       "не за что                                                            123\n",
       "хороший да ?                                                         122\n",
       "прости                                                               108\n",
       "конечно                                                               90\n",
       "давай                                                                 85\n",
       "всегда пожалуйста                                                     83\n",
       "я знаю                                                                82\n",
       "прекрасно                                                             73\n",
       "замечательно                                                          68\n",
       "правда                                                                67\n",
       "я не знаю                                                             64\n",
       "и я не мог его достать                                                61\n",
       "ага                                                                   60\n",
       "пока                                                                  60\n",
       "почему ?                                                              59\n",
       "пошли                                                                 59\n",
       "я тоже                                                                57\n",
       "держи                                                                 56\n",
       "никто                                                                 55\n",
       "                                                                    ... \n",
       "спасибо что пришла                                                     1\n",
       "вы и правда беспокоитесь о нем                                         1\n",
       "такое тоже не ношу                                                     1\n",
       "я имею в виду что 90 % времени семья действует тебе на нервы           1\n",
       "и я умею терпеть                                                       1\n",
       "а я не уверен                                                          1\n",
       "я только что видел как ты выбежала из ресторана с тедом                1\n",
       "ты и меня повсюду видишь                                               1\n",
       "это точно не задержка                                                  1\n",
       "вы когда либо были там ?                                               1\n",
       "все хотят жить                                                         1\n",
       "спасибо вам за то что делаем это вместе                                1\n",
       "в смысле человеческие дети ?                                           1\n",
       "я видел много вещей такой высоты но не такого рода                     1\n",
       "ёто было просто восхитительно                                          1\n",
       "а вчера вы плакали                                                     1\n",
       "и я тебя брат монтана                                                  1\n",
       "скажи люку чтобы он не продавал мои вещи                               1\n",
       "ты не помнишь ?                                                        1\n",
       "тогда я зафиксирую его и насильно введу антибиотики и физраствор       1\n",
       "не теон миледи                                                         1\n",
       "сразу после вашего отъезда                                             1\n",
       "они оба умерли                                                         1\n",
       "фрэнни я пустая ракушка на берегу без тебя                             1\n",
       "ну тогда боб ты остаешься сам с собой                                  1\n",
       "я с ним и сам справлюсь                                                1\n",
       "ну значит это скверный закон                                           1\n",
       "он будет процветать                                                    1\n",
       "программистов ?                                                        1\n",
       "добрый веер мсье                                                       1\n",
       "Name: reply, Length: 72208, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# частота различных ответов в test\n",
    "test['reply'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100162635340393    6\n",
       "4401566740888      6\n",
       "1743779660374      6\n",
       "87714158040440     6\n",
       "87068983477514     6\n",
       "36758341366322     6\n",
       "132698020492839    6\n",
       "72816844376899     6\n",
       "130720975544621    6\n",
       "243969317635243    6\n",
       "85400520508570     6\n",
       "87396092950004     6\n",
       "124036553476640    6\n",
       "241171872325608    6\n",
       "144366406327269    6\n",
       "95273543262575     6\n",
       "11660958455676     6\n",
       "192982879157739    6\n",
       "56873000455164     6\n",
       "184251557757396    6\n",
       "122730260997588    6\n",
       "268646064017459    6\n",
       "73737198412678     6\n",
       "38645959227499     6\n",
       "71704405148018     6\n",
       "15626679572220     6\n",
       "25232690756256     6\n",
       "225552710041413    6\n",
       "68775261376148     6\n",
       "221916173036839    6\n",
       "                  ..\n",
       "233118867847263    1\n",
       "266917446312938    1\n",
       "233144637440770    1\n",
       "12763232720077     1\n",
       "214214715292261    1\n",
       "140891017590688    1\n",
       "32901099077912     1\n",
       "153159062511300    1\n",
       "146851943657362    1\n",
       "97101884421964     1\n",
       "19175969026295     1\n",
       "269574431188882    1\n",
       "2678113712049      1\n",
       "194821786980010    1\n",
       "82453708670157     1\n",
       "152214719704196    1\n",
       "276898782850611    1\n",
       "83924874716561     1\n",
       "138363049854134    1\n",
       "214154510704838    1\n",
       "195521237736775    1\n",
       "123804833149728    1\n",
       "221645825826855    1\n",
       "7881246497432      1\n",
       "225934293529511    1\n",
       "50814535746691     1\n",
       "277155580634612    1\n",
       "78112561726327     1\n",
       "81177775888406     1\n",
       "206708200342074    1\n",
       "Name: context_id, Length: 17178, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество примеров для кажого context_id в train\n",
    "train['context_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    15830\n",
       "1      604\n",
       "2      425\n",
       "3      217\n",
       "4       62\n",
       "5       40\n",
       "Name: context_id, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество фрагментов с определённым количеством примеров\n",
    "train['context_id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48103100830247     6\n",
       "3765968002046      6\n",
       "42150106331448     6\n",
       "115106921512524    6\n",
       "213334849481508    6\n",
       "131242188904833    6\n",
       "262133101188465    6\n",
       "169772772720499    6\n",
       "258894713176044    6\n",
       "161380118037212    6\n",
       "247310959870507    6\n",
       "41772685330582     6\n",
       "9698809921026      6\n",
       "130517326987554    6\n",
       "8523050099041      6\n",
       "249463308895219    6\n",
       "97089448429096     6\n",
       "256686148513462    6\n",
       "164891224244476    6\n",
       "145764991807563    6\n",
       "56943217816855     6\n",
       "55155509564180     6\n",
       "153703696837656    6\n",
       "153063688068214    6\n",
       "196411843758263    6\n",
       "87079456798287     6\n",
       "55206725613769     6\n",
       "52341764283932     6\n",
       "173775396318921    6\n",
       "246468065376732    6\n",
       "                  ..\n",
       "183194207245515    2\n",
       "235915562147937    2\n",
       "77843188655912     2\n",
       "149604400672780    2\n",
       "130904442636004    2\n",
       "27751790253921     2\n",
       "53630809649579     2\n",
       "56880161398753     2\n",
       "43808683719283     2\n",
       "157979505909851    2\n",
       "114445820756074    2\n",
       "79270853974234     2\n",
       "184914203480537    2\n",
       "83526287702502     2\n",
       "186961863685061    2\n",
       "97520862483394     2\n",
       "108306540971057    2\n",
       "267274989310563    2\n",
       "203858276535561    2\n",
       "159982061498170    2\n",
       "172353308335359    2\n",
       "19255548816579     2\n",
       "93722093091110     2\n",
       "8759472597454      2\n",
       "203767990509064    2\n",
       "23731223302542     2\n",
       "28482712333835     2\n",
       "228928450570887    2\n",
       "164313207576206    2\n",
       "190294982679886    2\n",
       "Name: context_id, Length: 17554, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество примеров для каждого context_id в test\n",
    "test['context_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    17386\n",
       "2       66\n",
       "3       46\n",
       "4       32\n",
       "5       24\n",
       "Name: context_id, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# количество фрагментов с определённым количеством примеров\n",
    "test['context_id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOEiSOoaDJKljOEiSOoaDJKljOEiSOv8X/pw9Ovy1epwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xebd138e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# распределение целевой переменной для 3-х зачений\n",
    "# видим, что распределение неравномерное \n",
    "# попытка приведения распределения к равномерному, удалением context_id c большим перевесом в good \n",
    "# сильно уменьшало обучающую выборку и ухудшало скор\n",
    "hist, bins = np.histogram(train['label_num'], bins=3)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngrox/k6DHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeb80e9bfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# распределение целевой переменной для всех значений\n",
    "# видно, что значения для neutral имеют небольшой разброс по частоте\n",
    "hist, bins = np.histogram(train['y'], bins=100)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаемся и делаем предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.copy()\n",
    "y = train['y']\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем вспомогательные поля\n",
    "X_train.drop(['confidence', 'confidence_delta', 'label', 'label_num', 'y', 'reply_words', 'context_0_words', 'context_1_words', 'context_2_words', 'what_mean'], axis=1, inplace=True)\n",
    "X_test.drop(['confidence', 'confidence_delta', 'label', 'label_num', 'y', 'reply_words', 'context_0_words', 'context_1_words', 'context_2_words', 'what_mean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем исходные поля\n",
    "X_train.drop(['context_2', 'context_1', 'context_0', 'reply'], axis=1, inplace=True)\n",
    "X_test.drop(['context_2', 'context_1', 'context_0', 'reply'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем id\n",
    "X_train.drop(['context_id', 'reply_id', 'context_0_gramm_orgn', 'reply_gramm_orgn'], axis=1, inplace=True)\n",
    "X_test.drop(['context_id', 'reply_id', 'context_0_gramm_orgn', 'reply_gramm_orgn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем _gramm_order\n",
    "X_train.drop(['reply_gramm_order', 'context_0_gramm_order'], axis=1, inplace=True)\n",
    "X_test.drop(['reply_gramm_order', 'context_0_gramm_order'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем _first_word\n",
    "X_train.drop(['reply_first_word', 'context_0_first_word'], axis=1, inplace=True)\n",
    "X_test.drop(['reply_first_word', 'context_0_first_word'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем _last_word\n",
    "X_train.drop(['reply_last_word', 'context_0_last_word'], axis=1, inplace=True)\n",
    "X_test.drop(['reply_last_word', 'context_0_last_word'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем _len\n",
    "X_train.drop(['reply_word_len', 'context_0_word_len', 'reply_char_len'], axis=1, inplace=True)\n",
    "X_test.drop(['reply_word_len', 'context_0_word_len', 'reply_char_len'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply_gramm_patr\n",
      "context_0_gramm_patr\n",
      "context_0_gramm_involvement_incl\n",
      "reply_gramm_case_gen2\n"
     ]
    }
   ],
   "source": [
    "# найдём и удалим признаки с небольшим количеством примеров\n",
    "for c in X_train.columns:\n",
    "    if (type(X_train[c][0])==np.bool_) & (len(X_train[X_train[c]==True]) < 31):\n",
    "        print(c)\n",
    "        X_train.drop([c], axis=1, inplace=True)\n",
    "        X_test.drop([c], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply_gramm_pos_first\n",
      "reply_gramm_case_first\n",
      "reply_gramm_gender_first\n",
      "reply_gramm_number_first\n",
      "reply_gramm_animacy_first\n",
      "reply_gramm_tense_first\n",
      "reply_gramm_aspect_first\n",
      "reply_gramm_person_first\n",
      "reply_gramm_involvement_first\n",
      "reply_gramm_mood_first\n",
      "reply_gramm_transitivity_first\n",
      "reply_gramm_voice_first\n",
      "reply_gramm_pos_last\n",
      "reply_gramm_case_last\n",
      "reply_gramm_gender_last\n",
      "reply_gramm_number_last\n",
      "reply_gramm_animacy_last\n",
      "reply_gramm_tense_last\n",
      "reply_gramm_aspect_last\n",
      "reply_gramm_person_last\n",
      "reply_gramm_involvement_last\n",
      "reply_gramm_mood_last\n",
      "reply_gramm_transitivity_last\n",
      "reply_gramm_voice_last\n",
      "context_0_gramm_pos_first\n",
      "context_0_gramm_case_first\n",
      "context_0_gramm_gender_first\n",
      "context_0_gramm_number_first\n",
      "context_0_gramm_animacy_first\n",
      "context_0_gramm_tense_first\n",
      "context_0_gramm_aspect_first\n",
      "context_0_gramm_person_first\n",
      "context_0_gramm_involvement_first\n",
      "context_0_gramm_mood_first\n",
      "context_0_gramm_transitivity_first\n",
      "context_0_gramm_voice_first\n",
      "context_0_gramm_pos_last\n",
      "context_0_gramm_case_last\n",
      "context_0_gramm_gender_last\n",
      "context_0_gramm_number_last\n",
      "context_0_gramm_animacy_last\n",
      "context_0_gramm_tense_last\n",
      "context_0_gramm_aspect_last\n",
      "context_0_gramm_person_last\n",
      "context_0_gramm_involvement_last\n",
      "context_0_gramm_mood_last\n",
      "context_0_gramm_transitivity_last\n",
      "context_0_gramm_voice_last\n",
      "reply_gramm_order_rife\n",
      "context_0_gramm_order_rife\n",
      "reply_rife\n",
      "context_0_rife\n",
      "context_1_rife\n",
      "context_2_rife\n",
      "reply_first_word_rife\n",
      "context_0_first_word_rife\n",
      "reply_last_word_rife\n",
      "context_0_last_word_rife\n"
     ]
    }
   ],
   "source": [
    "cat_features = np.where(X_train.dtypes == 'object')[0].tolist()\n",
    "print(\"\\n\".join(X_train.columns[cat_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'final_catboost_1000_seed_17_new_features_corrected_12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 9min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CatBoostRegressor(random_seed=17, iterations=1000, depth=12, logging_level='Silent')\n",
    "model.fit(X_train, y, cat_features=cat_features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_save = test.copy()\n",
    "test_to_save['result'] = preds\n",
    "test_to_save.sort_values(by=['context_id', 'result'], ascending=[1, 0], inplace=True)\n",
    "test_to_save[['context_id', 'reply_id']].to_csv(file_name + '.csv', encoding='utf-8', sep=' ', index=False, header=False)\n",
    "test_to_save.to_csv('full_' + file_name + '.csv', encoding='utf-8', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(file_name + '.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_feature_importances = pd.DataFrame(X_test.columns, model.feature_importances_).sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.16575629164592 reply_first_word_rife\n",
      "4.945148491765426 context_0_first_word_rife\n",
      "4.204964722823379 context_0_last_word_rife\n",
      "4.147606899156413 reply_gramm_pos_first\n",
      "4.147570217736325 reply_last_word_rife\n",
      "3.076522428062693 reply_context_0_intersection_part\n",
      "2.7786566499572407 reply_gramm_order_rife\n",
      "1.9340266709895186 reply_gramm_case_last\n",
      "1.9172303715770969 context_0_gramm_order_rife\n",
      "1.8334085220382417 context_1_rife\n",
      "1.8257901279320314 context_2_rife\n",
      "1.64477923135395 reply_gramm_pos_last\n",
      "1.5990919095614886 reply_gramm_case_first\n",
      "1.5899851217198242 context_0_gramm_case_last\n",
      "1.453182327997118 context_0_gramm_pos_first\n",
      "1.3247254186244133 reply_gramm_person_last\n",
      "1.3154241568629021 reply_gramm_person_first\n",
      "1.2934415607615874 context_0_gramm_pos_last\n",
      "1.2779902722088825 context_0_question\n",
      "1.272529856574806 reply_question\n",
      "1.1529365329435022 context_0_gramm_gender_last\n",
      "1.061545123502539 context_0_gramm_person_first\n",
      "1.0490560630948034 reply_gramm_pos_CONJ\n",
      "1.0187786403171095 reply_gramm_animacy_last\n",
      "1.000758968427457 reply_gramm_gender_masc\n",
      "0.9995357571198111 context_0_gramm_gender_first\n",
      "0.9988165745160957 reply_gramm_tense_last\n",
      "0.9691717794742051 context_0_gramm_person_last\n",
      "0.9498769990790946 context_0_gramm_case_first\n",
      "0.9406530040654201 reply_gramm_pos_PRCL\n",
      "0.9345652194000095 reply_gramm_gender_first\n",
      "0.9199390867847209 reply_gramm_pos_ADVB\n",
      "0.8946885769417635 reply_gramm_pos_ADJF\n",
      "0.8603933779481652 context_0_gramm_tense_last\n",
      "0.8440412636453595 reply_gramm_animacy_first\n",
      "0.8226281488012028 context_0_rife\n",
      "0.7875891369163622 context_0_gramm_pos_PRCL\n",
      "0.7659205616312447 reply_first_context_0_first_same_gender\n",
      "0.7554935909699133 reply_gramm_person_1per\n",
      "0.7355167362657681 reply_gramm_gender_last\n",
      "0.7117898888731882 context_0_gramm_gender_femn\n",
      "0.7090337932218468 context_0_gramm_pos_NOUN\n",
      "0.7005804870264487 context_0_gramm_pos_CONJ\n",
      "0.6635548482284627 reply_gramm_qual\n",
      "0.6536540273817052 reply_rife\n",
      "0.6253469024877091 context_0_gramm_animacy_last\n",
      "0.600507212824453 reply_first_context_0_first_same_case\n",
      "0.5873735578933057 context_0_gramm_aspect_first\n",
      "0.5867178621467635 context_0_gramm_case_gent\n",
      "0.5714448469449619 reply_gramm_tense_first\n",
      "0.5351720199716765 reply_equel_context_0\n",
      "0.5330337943326375 context_0_gramm_transitivity_last\n",
      "0.5153262764302603 reply_gramm_transitivity_intr\n",
      "0.5137869684470341 reply_first_context_0_last_same_tense\n",
      "0.4974824964197121 reply_gramm_pos_NPRO\n",
      "0.4964950997878254 reply_gramm_aspect_first\n",
      "0.48801230960627384 context_0_gramm_transitivity_tran\n",
      "0.46716207116916825 reply_first_context_0_last_same_gender\n",
      "0.4522165102466814 context_0_gramm_animacy_first\n",
      "0.4497143847051015 context_0_gramm_pos_PREP\n",
      "0.44864291843126336 reply_gramm_gender_neut\n",
      "0.44270768268225846 reply_gramm_transitivity_tran\n",
      "0.4375004630488207 reply_gramm_transitivity_first\n",
      "0.4321376159712484 context_0_gramm_tense_first\n",
      "0.4277606674831014 reply_context_0_same_3per\n",
      "0.42750452942242967 context_0_gramm_animacy_inan\n",
      "0.42645972868325793 context_0_gramm_gender_masc\n",
      "0.4250938348762906 context_0_gramm_mood_last\n",
      "0.4226416869394709 reply_gramm_gender_femn\n",
      "0.4190660878783406 context_0_gramm_transitivity_first\n",
      "0.41421808442774516 reply_gramm_aspect_last\n",
      "0.4015017819454402 context_0_gramm_pos_ADJF\n",
      "0.3981056001857417 context_0_gramm_person_2per\n",
      "0.39515240982477184 context_0_gramm_number_last\n",
      "0.392190835766178 context_0_gramm_person_1per\n",
      "0.3904123776380314 reply_gramm_pos_PREP\n",
      "0.38336431806992743 reply_gramm_number_plur\n",
      "0.38200544262582087 reply_gramm_animacy_inan\n",
      "0.3683184428907489 reply_gramm_mood_first\n",
      "0.3675321396932398 reply_gramm_transitivity_last\n",
      "0.3550234345500461 context_0_gramm_number_plur\n",
      "0.34879286268745496 reply_gramm_mood_last\n",
      "0.34012833659153546 reply_gramm_pos_INFN\n",
      "0.3380442108461844 reply_gramm_aspect_impf\n",
      "0.32525357149384265 context_0_gramm_case_accs\n",
      "0.3236993506791994 context_0_gramm_pos_NPRO\n",
      "0.30206791811517536 reply_gramm_case_nomn\n",
      "0.2978794955130562 context_0_gramm_animacy_anim\n",
      "0.28430498518411357 reply_gramm_person_3per\n",
      "0.28393048077815836 reply_first_context_0_last_same_case\n",
      "0.28357729849505875 reply_gramm_number_last\n",
      "0.28083047438766057 reply_first_context_0_first_same_tense\n",
      "0.27273215710016785 reply_gramm_case_datv\n",
      "0.2724270793587886 reply_gramm_tense_pres\n",
      "0.27081860989223533 reply_gramm_pos_NOUN\n",
      "0.2671599545180681 context_0_gramm_gender_neut\n",
      "0.26713465950131465 hello_hello\n",
      "0.2607760239530274 context_0_gramm_aspect_perf\n",
      "0.2568028285500991 context_0_gramm_apro\n",
      "0.24503664177420825 reply_equel_context_1\n",
      "0.24307439902413333 context_0_gramm_pos_ADVB\n",
      "0.23212703151425773 context_0_gramm_name\n",
      "0.21877305586151438 context_0_gramm_tense_past\n",
      "0.21628623430646152 reply_gramm_tense_past\n",
      "0.21583653586027296 context_0_gramm_number_first\n",
      "0.21046856318908763 reply_gramm_case_gent\n",
      "0.20901615371547708 context_0_gramm_tense_pres\n",
      "0.20772975079189204 reply_first_context_0_first_same_number\n",
      "0.20684609941436777 reply_gramm_pos_INTJ\n",
      "0.19684146218441273 reply_first_context_0_last_same_number\n",
      "0.19462497401446727 context_0_gramm_transitivity_intr\n",
      "0.19356814411916948 context_0_gramm_pos_INTJ\n",
      "0.18630401025598822 reply_context_0_intersection_count\n",
      "0.18091238794247821 reply_gramm_person_2per\n",
      "0.17781108775135168 context_0_gramm_aspect_impf\n",
      "0.17211249409858212 reply_gramm_aspect_perf\n",
      "0.16402951794960077 reply_gramm_number_first\n",
      "0.1562404077502927 context_0_gramm_person_3per\n",
      "0.15034950465546634 context_0_gramm_mood_first\n",
      "0.14997390600904395 context_0_gramm_mood_indc\n",
      "0.14633899590731556 context_0_gramm_aspect_last\n",
      "0.14477736774553102 context_0_gramm_pos_VERB\n",
      "0.12406312984230246 context_0_gramm_geox\n",
      "0.12042215455632543 reply_gramm_voice_first\n",
      "0.11993059596379044 context_0_gramm_case_nomn\n",
      "0.11989755253094868 context_0_gramm_case_loct\n",
      "0.11409501893436891 reply_gramm_animacy_anim\n",
      "0.11233993589277035 context_0_gramm_involvement_first\n",
      "0.1114913394332277 reply_gramm_involvement_last\n",
      "0.11082250264662213 context_0_gramm_pos_NUMR\n",
      "0.1036596288150729 reply_gramm_case_accs\n",
      "0.10232420145468343 reply_gramm_pos_NUMR\n",
      "0.09851225508493777 you_i\n",
      "0.09731660285141218 context_0_gramm_pos_INFN\n",
      "0.0966866893161313 context_0_gramm_pos_COMP\n",
      "0.09255333933046887 he_he\n",
      "0.09101143010246428 context_0_gramm_pos_ADJS\n",
      "0.09027391388184548 context_0_gramm_qual\n",
      "0.08437892410301248 reply_gramm_apro\n",
      "0.08101372634418415 reply_gramm_pos_ADJS\n",
      "0.08072673181345788 context_0_gramm_tense_futr\n",
      "0.0675548196097464 what_mean_same\n",
      "0.06659990724872247 context_0_gramm_pos_PRED\n",
      "0.06496484610226488 context_0_gramm_voice_first\n",
      "0.06063387288122398 reply_gramm_pos_PRED\n",
      "0.058970776017706686 reply_gramm_tense_futr\n",
      "0.05865948982311922 reply_gramm_mood_impr\n",
      "0.05691457562291462 context_0_gramm_case_ablt\n",
      "0.056859246613242216 reply_gramm_involvement_first\n",
      "0.05362627981900784 context_0_gramm_anum\n",
      "0.05306948859000144 reply_gramm_mood_indc\n",
      "0.05074475778902934 context_0_gramm_pos_PRTF\n",
      "0.04754873737998418 reply_gramm_number_sing\n",
      "0.04687512911367414 reply_gramm_name\n",
      "0.04394251821259976 reply_gramm_involvement_incl\n",
      "0.04217828287484495 context_0_gramm_case_datv\n",
      "0.0398847623456176 reply_gramm_involvement_excl\n",
      "0.036813100319570455 context_0_gramm_voice_pssv\n",
      "0.03346612332890975 context_0_gramm_voice_last\n",
      "0.03259068229906593 context_0_gramm_surn\n",
      "0.03219840190486509 context_0_gramm_mood_impr\n",
      "0.031455983777234096 reply_gramm_pos_PRTS\n",
      "0.030362663018052096 reply_gramm_voice_last\n",
      "0.02029164924228702 reply_gramm_pos_VERB\n",
      "0.01886781881716317 i_you\n",
      "0.0176804857014933 reply_gramm_case_loct\n",
      "0.015087319042789964 reply_gramm_case_ablt\n",
      "0.013011762653638027 reply_gramm_surn\n",
      "0.011845258532324552 reply_gramm_case_loc2\n",
      "0.011822969133658816 reply_gramm_geox\n",
      "0.011495648557659468 reply_gramm_anum\n",
      "0.011341440132999675 context_0_gramm_number_sing\n",
      "0.010597630787166247 reply_equel_context_2\n",
      "0.006463447578718154 she_she\n",
      "0.0060457945122635295 reply_gramm_pos_GRND\n",
      "0.004117041465689865 context_0_gramm_pos_PRTS\n",
      "0.0011988319437316853 context_0_gramm_case_voct\n",
      "0.001003695244377795 reply_gramm_pos_PRTF\n",
      "0.0007742332109205518 context_0_gramm_pos_GRND\n",
      "0.0 thanks_wellcome\n",
      "0.0 reply_gramm_pos_COMP\n",
      "0.0 context_0_gramm_case_loc2\n",
      "0.0 context_0_gramm_involvement_excl\n",
      "0.0 context_0_gramm_case_gen2\n",
      "0.0 context_0_gramm_involvement_last\n",
      "0.0 context_0_gramm_voice_actv\n",
      "0.0 reply_gramm_voice_actv\n",
      "0.0 reply_gramm_case_voct\n",
      "0.0 reply_gramm_voice_pssv\n"
     ]
    }
   ],
   "source": [
    "for i, row in cb_feature_importances.iterrows():\n",
    "    print(i, row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_feature_importances.to_csv(file_name + '_feature_importances.csv', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Среднее по разным сидам\n",
    "Пробовал усреднять непосредственно по предсказанным значениям, но оказалось, что для разных моделей они лежат в разных диапазонах и результат оказался неудовлетворительный.\n",
    "Поэтому беру результат ранжирования, сделанного по предсказанным значениям, выставляю ранги, беру среднее значение ранга для reply_id и финальный результат получаю сортировкой по этим усреднённым рангам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'final_remote_catboost_1_new_features_corrected_depth_12_seed_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при генерации с разными \"случайными\" сидами заметил, что часто catboost выдаёт одинаковый результат для разных значений \n",
    "# (вроде бы это можно определить по cкору на первой итерации), поэтому подбирал значения, чтобы резуьтат был уникальным\n",
    "files = []\n",
    "for e in [11, 17, 27, 42, 44, 71, 101, 335, 888, 999, 1107]:\n",
    "    model = CatBoostRegressor(random_seed=e, iterations=1, depth=12)\n",
    "    model.fit(X_train, y, cat_features=cat_features, logging_level='Info');\n",
    "    preds = model.predict(X_test)\n",
    "    test_to_save = test.copy()\n",
    "    test_to_save['result'] = preds\n",
    "    test_to_save.sort_values(by=['context_id', 'result'], ascending=[1, 0], inplace=True)\n",
    "    result_filename = file_name + '_' + str(e) + '.csv'\n",
    "    files.append(result_filename)\n",
    "    test_to_save[['context_id', 'reply_id']].to_csv(result_filename, encoding='utf-8', sep=' ', index=False, header=False)\n",
    "    cb_feature_importances = pd.DataFrame(X_test.columns, model.feature_importances_).sort_index(ascending=False)\n",
    "    cb_feature_importances.to_csv(file_name + '_' + str(e) + '_feature_importances.csv', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def Ordr(row):\n",
    "    row['rank'] = range(0, len(row))\n",
    "    return row\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep=' ', header=None, names=[ 'context_id', 'reply_id'])\n",
    "    df = df.groupby('context_id').apply(Ordr)\n",
    "    df.sort_values(by=['context_id', 'reply_id'], ascending=[1, 1], inplace=True)\n",
    "    results.append(df['rank'].astype('float'))\n",
    "result = np.mean(results, axis=0)\n",
    "print(len(result))\n",
    "\n",
    "test_to_save = test.copy()\n",
    "test_to_save['rank'] = result\n",
    "\n",
    "file_name_mean = file_name + '_mean.csv'\n",
    "test_to_save.sort_values(by=['context_id', 'rank'], ascending=[1, 1], inplace=True)\n",
    "test_to_save[['context_id', 'reply_id']].to_csv(file_name_mean, encoding='utf-8', sep=' ', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
