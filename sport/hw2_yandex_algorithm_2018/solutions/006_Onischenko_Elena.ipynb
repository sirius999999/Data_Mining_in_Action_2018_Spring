{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yandex Algorithm 2018 ML track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://contest.yandex.ru/algorithm2018/contest/7914/problems/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T13:48:44.386796Z",
     "start_time": "2018-04-25T13:48:44.382590Z"
    }
   },
   "source": [
    "** 6 место private LB (elena-vo@yandex.ru) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вспомогательные-функции\" data-toc-modified-id=\"Вспомогательные-функции-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Вспомогательные функции</a></span></li><li><span><a href=\"#Читаем-train_set,-test_set,-соединяем-в-один-датасет\" data-toc-modified-id=\"Читаем-train_set,-test_set,-соединяем-в-один-датасет-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Читаем train_set, test_set, соединяем в один датасет</a></span></li><li><span><a href=\"#Y\" data-toc-modified-id=\"Y-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Y</a></span></li></ul></li><li><span><a href=\"#Cleaning-и-новые-статистические-признаки\" data-toc-modified-id=\"Cleaning-и-новые-статистические-признаки-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cleaning и новые статистические признаки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Уберем-id-по-которым-не-более-одного-хорошего-(l_n&gt;=1)-ответа\" data-toc-modified-id=\"Уберем-id-по-которым-не-более-одного-хорошего-(l_n>=1)-ответа-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Уберем id по которым не более одного хорошего (l_n&gt;=1) ответа</a></span></li><li><span><a href=\"#Нехорошие-символы\" data-toc-modified-id=\"Нехорошие-символы-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Нехорошие символы</a></span></li><li><span><a href=\"#Подготовка-текста,-нормализация\" data-toc-modified-id=\"Подготовка-текста,-нормализация-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Подготовка текста, нормализация</a></span></li><li><span><a href=\"#Сontext_sum,-дубликаты-по-context_sum-с-разными-context_id\" data-toc-modified-id=\"Сontext_sum,-дубликаты-по-context_sum-с-разными-context_id-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Сontext_sum, дубликаты по context_sum с разными context_id</a></span></li><li><span><a href=\"#Количество-пересекающихся-слов-в-reply-и-контекстах\" data-toc-modified-id=\"Количество-пересекающихся-слов-в-reply-и-контекстах-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Количество пересекающихся слов в reply и контекстах</a></span></li><li><span><a href=\"#Длины,-гласные,-согласные-и-др.-признаки\" data-toc-modified-id=\"Длины,-гласные,-согласные-и-др.-признаки-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Длины, гласные, согласные и др. признаки</a></span></li></ul></li><li><span><a href=\"#FastText\" data-toc-modified-id=\"FastText-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>FastText</a></span></li><li><span><a href=\"#Валидация\" data-toc-modified-id=\"Валидация-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Валидация</a></span><ul class=\"toc-item\"><li><span><a href=\"#Функции-для-валидации\" data-toc-modified-id=\"Функции-для-валидации-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Функции для валидации</a></span></li><li><span><a href=\"#Признаки-и-параметры\" data-toc-modified-id=\"Признаки-и-параметры-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Признаки и параметры</a></span></li></ul></li><li><span><a href=\"#Predict\" data-toc-modified-id=\"Predict-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Predict</a></span></li><li><span><a href=\"#Submition\" data-toc-modified-id=\"Submition-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Submition</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.462903Z",
     "start_time": "2018-04-25T15:02:56.103123Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pymorphy2\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import sklearn\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.465842Z",
     "start_time": "2018-04-25T15:02:56.463994Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.578446Z",
     "start_time": "2018-04-25T15:02:56.466715Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.583556Z",
     "start_time": "2018-04-25T15:02:56.579453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.587943Z",
     "start_time": "2018-04-25T15:02:56.584502Z"
    }
   },
   "outputs": [],
   "source": [
    "PTD = '../data/Ya/'\n",
    "\n",
    "PTIN = PTD + 'raw/'\n",
    "PTR = PTD + 'result/'\n",
    "PTTMP = PTD + '_tmp/'\n",
    "PTSUB = PTD + 'sub/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.592291Z",
     "start_time": "2018-04-25T15:02:56.588911Z"
    }
   },
   "outputs": [],
   "source": [
    "col_service = [\n",
    "    'context_id',\n",
    "    'context_2',\n",
    "    'context_1',\n",
    "    'context_0',\n",
    "    'reply_id',\n",
    "    'reply',\n",
    "    'label',\n",
    "    'confidence',\n",
    "    'is_train',\n",
    "    'l_n',\n",
    "    'y', 'context_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.596457Z",
     "start_time": "2018-04-25T15:02:56.593181Z"
    }
   },
   "outputs": [],
   "source": [
    "n_splits_n, random_state_n = (10, 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T13:56:20.685799Z",
     "start_time": "2018-04-19T13:56:20.683257Z"
    }
   },
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.611644Z",
     "start_time": "2018-04-25T15:02:56.597422Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_files(pref, ext, suf_out=None, path=PTTMP):\n",
    "    \n",
    "    suf = ('' if suf_out==None else \"\".join((str(suf_out))))\n",
    "    ext = '.' + ext\n",
    "    name_file =  \"_\".join((path, pref, suf,  ext))\n",
    "    # name_file = PATH_TO_DATA +  'y_valid_'+ suf +'_.pcl'\n",
    "    #print(name_file)    \n",
    "    #    X=pd.DataFrame()\n",
    "    try:\n",
    "        if ext=='.npz':\n",
    "            X = scipy.sparse.load_npz(name_file)\n",
    "        elif ext=='.pcl':\n",
    "            X = pd.read_pickle(name_file)\n",
    "        elif ext=='.csv':\n",
    "            X = pd.read_csv(name_file, index_col=0)\n",
    "        else:\n",
    "            print('Error! Расширение файла: ',ext,'мне не понравилось!')\n",
    "        #print (\"ok\")\n",
    "    except Exception as e:\n",
    "        print('Error!' , str(e))\n",
    "        # break\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.628589Z",
     "start_time": "2018-04-25T15:02:56.612758Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_df_to_file(df, pref, ext, suf_out=None, path=PTTMP, verbose=True):\n",
    "    \"\"\"\n",
    "    Сохранение на диск файла: имя = _pref_suf_.ext с расширением ext = ['npz','pcl','csv']\n",
    "    путь = path\n",
    "    имя = _pref_suf_.ext\n",
    "    \"\"\"\n",
    "    \n",
    "    suf = ('' if suf_out is None else \"\".join((str(suf_out))))\n",
    "    ext = '.' + ext\n",
    "    \n",
    "    name_file_out =  \"_\".join((path, pref, suf,  ext))\n",
    "    #print(name_file_out) \n",
    "    \n",
    "    try:\n",
    "        if ext=='.npz':\n",
    "            scipy.sparse.save_npz(name_file_out, df)\n",
    "        elif ext=='.pcl':\n",
    "            df.to_pickle(name_file_out)\n",
    "        elif ext=='.csv':\n",
    "            df.to_csv(name_file_out)\n",
    "        else:\n",
    "            if verbose: print('Error! Расширение файла',ext,'мне не понравилось!')\n",
    "        print('Записали на диск файл', name_file_out)\n",
    "    except Exception as e:\n",
    "        print('Error!', str(e))\n",
    "    \n",
    "    \n",
    "    return name_file_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.635312Z",
     "start_time": "2018-04-25T15:02:56.629615Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_feature(df, func, cols=['context_2', 'context_1', 'context_0', 'context_sum', 'reply']):\n",
    "    new_f_names = []\n",
    "    if (type(func) != list): func = [func]\n",
    "    \n",
    "    for col in cols:\n",
    "        for f in func:\n",
    "            df[col + '_' + f.__name__] = df[col].apply(f)\n",
    "            new_f_names.append(col + '_' + f.__name__)\n",
    "    \n",
    "    return df, new_f_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.640622Z",
     "start_time": "2018-04-25T15:02:56.636234Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ind_for_model(dt, drop_col=None, col_service=col_service):\n",
    "    if drop_col is None: drop_col=[]\n",
    "    return [list(dt.columns).index(item) for item in list(dt.columns)\n",
    "            if ((item not in col_service) & (item not in drop_col))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.644571Z",
     "start_time": "2018-04-25T15:02:56.641446Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_plot_importance(booster, figsize, max_num_features=20, **kwargs):\n",
    "    from xgboost import plot_importance\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, max_num_features=max_num_features,   ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Читаем train_set, test_set, соединяем в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:56.648534Z",
     "start_time": "2018-04-25T15:02:56.645340Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_cols = ['context_id','context_2','context_1','context_0','reply_id','reply','label','confidence']\n",
    "te_cols = ['context_id','context_2','context_1','context_0','reply_id','reply']\n",
    "all_cont_cols = ['context_2','context_1','context_0', 'reply']\n",
    "new_fs =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.040395Z",
     "start_time": "2018-04-25T15:02:56.649319Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(PTIN + 'train.tsv', sep = \"\\t\", header = None, names=tr_cols, quoting=csv.QUOTE_NONE)\n",
    "test = pd.read_csv(PTIN + 'final.tsv', sep = \"\\t\", header = None,names=te_cols, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.044044Z",
     "start_time": "2018-04-25T15:02:57.041420Z"
    }
   },
   "outputs": [],
   "source": [
    "train['is_train'] = np.int32(1)\n",
    "test['is_train'] = np.int32(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:18:37.260342Z",
     "start_time": "2018-04-25T15:18:37.255338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97533, 11), (104834, 7), 202367)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, (train.shape[0] + test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим финальный data-set(test) на наличие 'context_id' из train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.063911Z",
     "start_time": "2018-04-25T15:02:57.044967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_2</th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_0</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43896</th>\n",
       "      <td>125857571229545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на кого я похожа ?</td>\n",
       "      <td>0</td>\n",
       "      <td>на меня .</td>\n",
       "      <td>good</td>\n",
       "      <td>0.687344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43897</th>\n",
       "      <td>125857571229545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на кого я похожа ?</td>\n",
       "      <td>1</td>\n",
       "      <td>на друга моего брата .</td>\n",
       "      <td>good</td>\n",
       "      <td>0.724717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            context_id context_2 context_1           context_0  reply_id  \\\n",
       "43896  125857571229545       NaN       NaN  на кого я похожа ?         0   \n",
       "43897  125857571229545       NaN       NaN  на кого я похожа ?         1   \n",
       "\n",
       "                        reply label  confidence  is_train  \n",
       "43896               на меня .  good    0.687344         1  \n",
       "43897  на друга моего брата .  good    0.724717         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_cont_ind = list(train.groupby('context_id')['label'].count().index)\n",
    "train.loc[train.context_id==125857571229545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.073783Z",
     "start_time": "2018-04-25T15:02:57.064864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_2</th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_0</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>reply</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46862</th>\n",
       "      <td>125857571229545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на кого я похожа ?</td>\n",
       "      <td>0</td>\n",
       "      <td>на твою тётю .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46863</th>\n",
       "      <td>125857571229545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на кого я похожа ?</td>\n",
       "      <td>1</td>\n",
       "      <td>на себя .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46864</th>\n",
       "      <td>125857571229545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на кого я похожа ?</td>\n",
       "      <td>2</td>\n",
       "      <td>на милую , нормальную девушку .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46865</th>\n",
       "      <td>125857571229545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>на кого я похожа ?</td>\n",
       "      <td>3</td>\n",
       "      <td>на литл - уэйна .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            context_id context_2 context_1           context_0  reply_id  \\\n",
       "46862  125857571229545       NaN       NaN  на кого я похожа ?         0   \n",
       "46863  125857571229545       NaN       NaN  на кого я похожа ?         1   \n",
       "46864  125857571229545       NaN       NaN  на кого я похожа ?         2   \n",
       "46865  125857571229545       NaN       NaN  на кого я похожа ?         3   \n",
       "\n",
       "                                 reply  is_train  \n",
       "46862                   на твою тётю .         0  \n",
       "46863                        на себя .         0  \n",
       "46864  на милую , нормальную девушку .         0  \n",
       "46865                на литл - уэйна .         0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[test.context_id.isin(tr_cont_ind), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.082562Z",
     "start_time": "2018-04-25T15:02:57.074769Z"
    }
   },
   "outputs": [],
   "source": [
    "d_n = {\n",
    "    'good' : 2, \n",
    "    'neutral' : 1, \n",
    "    'bad' : 0\n",
    "}\n",
    "\n",
    "train['l_n'] = train.label.map(d_n).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Y' - целое число: 'label' перераспределён на 4 класса c учётом 'confidence.**              \n",
    "*Вычисление 'y' здесь в два этапа только для наглядности*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.171307Z",
     "start_time": "2018-04-25T15:02:57.083510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amin</th>\n",
       "      <th>amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.106646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.117896</td>\n",
       "      <td>0.338686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344573</td>\n",
       "      <td>0.999899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         amin      amax\n",
       "l_n                    \n",
       "0    0.000011  0.106646\n",
       "1    0.117896  0.338686\n",
       "2    0.344573  0.999899"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPS = 0.1\n",
    "train.loc[train['l_n'] > 0, 'y'] = ((train.l_n + 1 + EPS) * train.confidence) / 6.2\n",
    "train.loc[train['l_n'] == 2, 'y'] = train['y'] * 2 \n",
    "train.loc[train['l_n'] == 0, 'y'] = (-train.confidence + 1) / 6.2\n",
    "\n",
    "\n",
    "train.groupby('l_n')['y'].agg([np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.181696Z",
     "start_time": "2018-04-25T15:02:57.172525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amin</th>\n",
       "      <th>amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amin  amax\n",
       "l_n            \n",
       "0    -1.0  -1.0\n",
       "1    -1.0   0.0\n",
       "2     0.0   2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['y'] = np.around((train.y * 3.1).astype(np.double)) - 1\n",
    "train.groupby('l_n')['y'].agg([np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.252589Z",
     "start_time": "2018-04-25T15:02:57.182802Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = pd.concat([train, test])\n",
    "dt = dt[train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning и новые статистические признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:57.442669Z",
     "start_time": "2018-04-25T15:02:57.253805Z"
    }
   },
   "outputs": [],
   "source": [
    "dt.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Уберем id по которым не более одного хорошего (l_n>=1) ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:58.327235Z",
     "start_time": "2018-04-25T15:02:57.443832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199345, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_train = dt[dt['is_train'] == 1].groupby('context_id')['l_n'].sum()\n",
    "cont_train = cont_train[cont_train<=1].index\n",
    "\n",
    "dt = dt.loc[~dt.context_id.isin(cont_train), :]\n",
    "dt.index = range(len(dt))\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нехорошие символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:58.330315Z",
     "start_time": "2018-04-25T15:02:58.328415Z"
    }
   },
   "outputs": [],
   "source": [
    "vowels = 'аеёиоуыэюя'\n",
    "consonant = 'бвгджзйклмнпрстфхцчшщъь'\n",
    "alphabet = vowels + consonant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:02:59.478133Z",
     "start_time": "2018-04-25T15:02:58.331265Z"
    }
   },
   "outputs": [],
   "source": [
    "def symbols(sentence , n):\n",
    "    res = []\n",
    "    for s in sentence:\n",
    "        res.extend(list(s.lower()))\n",
    "    return set(res)\n",
    "\n",
    "dt.reply.str.cat([dt.context_1, dt.context_2], sep=' ')\n",
    "all_symbols = symbols(dt.reply.str.cat([dt.context_1, dt.context_2], sep=' ').values, 1)\n",
    "bad_symbols = all_symbols ^ set(alphabet) ^ set(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:03:01.006086Z",
     "start_time": "2018-04-25T15:02:59.479211Z"
    }
   },
   "outputs": [],
   "source": [
    "def bad_chs(x):\n",
    "    return len([s for s in x.lower() if s in bad_symbols])\n",
    "\n",
    "dt, new_fs = simple_feature(dt, bad_chs, cols=['context_2', 'context_1', 'context_0', 'reply'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:03:01.041419Z",
     "start_time": "2018-04-25T15:03:01.007208Z"
    }
   },
   "outputs": [],
   "source": [
    "dt['is_dupl_r'] = dt['reply'].duplicated(keep=False).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка текста, нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:03:01.099310Z",
     "start_time": "2018-04-25T15:03:01.042583Z"
    }
   },
   "outputs": [],
   "source": [
    "ws =['что', 'чего', 'чему', 'чем', 'кто','кого', 'кому', 'кем', 'где', 'когда', 'как', 'столько', 'сколько','куда', \n",
    "     'первых', 'вторых', 'третьих', 'четрвертых', 'пятых', 'шестых', 'седьмых']\n",
    "prs = ['кое', 'во']\n",
    "chs = ['нибудь', 'либо', 'то']\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def drop_gap(text):\n",
    "    for w in ws:\n",
    "        for pr in prs:\n",
    "            text = text.replace(pr + ' ' + '-' + ' ' + w, pr + '-' + w)\n",
    "        for ch in chs:\n",
    "            text = text.replace(w + ' ' + '-' + ' ' + ch, w + '-' + ch)\n",
    "    return text\n",
    "\n",
    "\n",
    "# stops = set(stopwords.words(\"english\")) | set(stopwords.words(\"russian\"))\n",
    "def review_to_words(review, normalize=True):\n",
    "    \"\"\"\n",
    "    0) заменим <censored> на 'нецензурный'\n",
    "    01) уберем пробел в 'кто - нибудь' etc\n",
    "    1)удалим все символы кроме букв верхнего и нижнего регистра,цифр и -;\n",
    "    2)преобразуем слова к нижнему регистру;\n",
    "    # 3)удалим стоп слова;\n",
    "    4)лемматизация\n",
    "    5)приведем к строке\n",
    "    \n",
    "    Результат:\n",
    "    Возвращает строку из слов (для w2v - последнюю строку убрать)\n",
    "    \"\"\"\n",
    "    \n",
    "    #0)\n",
    "    review = review.replace('<CENSORED>', 'нецензурный')\n",
    "    #01)\n",
    "    review = drop_gap(review)\n",
    "    #1)\n",
    "    # review_ = re.sub(\"[0-9]\",\"7\", review) до sub.18 вкл.\n",
    "    review_text = re.sub(\"[^а-яёА-Я0-9\\-]\",\" \", review)\n",
    "    review_text = review_text.replace(' - ', ' ') # 22.4\n",
    "    #2)\n",
    "    words = review_text.lower().split()\n",
    "    #3)\n",
    "    # words = [w for w in words if not w in stops]\n",
    "    #4)\n",
    "    if normalize: words = [morph.parse(w)[0].normal_form for w in words ]\n",
    "    words = \" \".join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:04:15.461974Z",
     "start_time": "2018-04-25T15:03:01.100675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 150 ms, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cont_rep = ['context_2','context_1','context_0','reply']\n",
    "for col in cont_rep:\n",
    "    dt[col] = dt[col].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сontext_sum, дубликаты по context_sum с разными context_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:04:15.562136Z",
     "start_time": "2018-04-25T15:04:15.463222Z"
    }
   },
   "outputs": [],
   "source": [
    "dt['context_sum'] = dt['context_2'].str.cat([dt['context_1'], dt['context_0']], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:04:15.673088Z",
     "start_time": "2018-04-25T15:04:15.564365Z"
    }
   },
   "outputs": [],
   "source": [
    "dt['is_dupl_sum'] = dt.loc[(dt.reply_id == 0), ['context_sum']].duplicated(keep=False).astype('int8')\n",
    "\n",
    "dup_ind = dt.loc[dt['is_dupl_sum']==1, :].groupby('context_id')['y'].count().index.tolist()\n",
    "dt.loc[dt.context_id.isin(dup_ind), 'is_dupl_sum'] = 1\n",
    "dt.loc[~dt.context_id.isin(dup_ind), 'is_dupl_sum'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Количество пересекающихся слов в reply и контекстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:04:15.682022Z",
     "start_time": "2018-04-25T15:04:15.674343Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_overlap(data_row):\n",
    "    \"\"\"\n",
    "    Возвращает количество n пересекающихся слов в reply и контекстах- dict[context_i] = n \n",
    "    data_row - строка, dt.loc[data_ind]\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    overlap = {}\n",
    "\n",
    "    for col in ['context_2', 'context_1', 'context_0', 'reply','context_sum']:\n",
    "        words[col] = data_row[col].split()\n",
    "    \n",
    "    reply_words = set(words['reply'])\n",
    "        \n",
    "    for col in ['context_2', 'context_1', 'context_0', 'context_sum']:\n",
    "        context_words = set(words[col])\n",
    "        overlap[col] = len(context_words.intersection(reply_words))\n",
    "                \n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:16.103934Z",
     "start_time": "2018-04-25T15:04:15.683477Z"
    }
   },
   "outputs": [],
   "source": [
    "context_cols = ['context_2', 'context_1', 'context_0', 'context_sum']\n",
    "overlap_df = pd.DataFrame(columns=context_cols)\n",
    "\n",
    "\n",
    "for data_ind in range(len(dt)):\n",
    "    ov = get_overlap(dt.loc[data_ind])\n",
    "    \n",
    "    for col in context_cols:\n",
    "        overlap_df.loc[data_ind, col] = ov[col]\n",
    "\n",
    "map_ = {col : col + '_ovr' for col in context_cols}\n",
    "overlap_df = overlap_df.rename(map_, axis=1).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:16.130846Z",
     "start_time": "2018-04-25T15:15:16.105291Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = pd.concat([dt, overlap_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:16.134073Z",
     "start_time": "2018-04-25T15:15:16.132063Z"
    }
   },
   "outputs": [],
   "source": [
    "def len_ws(x):\n",
    "    \"\"\"\n",
    "    Количество РАЗНЫХ слов \n",
    "    \"\"\"\n",
    "    return len(set(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:16.954166Z",
     "start_time": "2018-04-25T15:15:16.135041Z"
    }
   },
   "outputs": [],
   "source": [
    "dt, new_lws_names = simple_feature(dt, len_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:16.959039Z",
     "start_time": "2018-04-25T15:15:16.955509Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ratio(df, col_part, col, suf='_ratio'):\n",
    "    \n",
    "    new_col = col_part + '__' + col + suf\n",
    "    df[new_col] = 0\n",
    "    df.loc[df[col]!=0, new_col] = df[col_part] / df[col]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:17.123390Z",
     "start_time": "2018-04-25T15:15:16.960080Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_part= ['context_2_ovr', 'context_1_ovr', 'context_0_ovr', 'context_sum_ovr']\n",
    "col = 'reply_len_ws'\n",
    "\n",
    "for col_part  in cols_part:\n",
    "    dt = get_ratio(dt, col_part, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:17.126404Z",
     "start_time": "2018-04-25T15:15:17.124529Z"
    }
   },
   "outputs": [],
   "source": [
    "del overlap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Длины, гласные, согласные и др. признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:17.132107Z",
     "start_time": "2018-04-25T15:15:17.127560Z"
    }
   },
   "outputs": [],
   "source": [
    "vowels = '[аеёиоуыэюя]'\n",
    "consonants = '[бвгджзйклмнпрстфхцчшщъь]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:17.140366Z",
     "start_time": "2018-04-25T15:15:17.133279Z"
    }
   },
   "outputs": [],
   "source": [
    "def vow(x):\n",
    "    return len(re.findall(vowels, x))\n",
    "\n",
    "\n",
    "def cons(x):\n",
    "    return len(re.findall(consonants, x))\n",
    "\n",
    "\n",
    "def div_vov_cons(x):\n",
    "    if cons(x)!=0:\n",
    "        return vow(x)/(cons(x))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def len_chs(x):\n",
    "    return len(''.join(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:17.147734Z",
     "start_time": "2018-04-25T15:15:17.141359Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_feature(df, func, cols=['context_2', 'context_1', 'context_0', 'context_sum', 'reply']):\n",
    "    new_f_names = []\n",
    "    if (type(func) != list): func = [func]\n",
    "    \n",
    "    for col in cols:\n",
    "        for f in func:\n",
    "            df[col + '_' + f.__name__] = df[col].apply(f)\n",
    "            new_f_names.append(col + '_' + f.__name__)\n",
    "    \n",
    "    return df, new_f_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:28.411253Z",
     "start_time": "2018-04-25T15:15:17.148736Z"
    }
   },
   "outputs": [],
   "source": [
    "func = [len_chs, vow, cons, div_vov_cons]\n",
    "dt, new_fsf_names = simple_feature(dt, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:28.459587Z",
     "start_time": "2018-04-25T15:15:28.412331Z"
    }
   },
   "outputs": [],
   "source": [
    "dt['context_sum_bad_chs'] = dt[['context_2_bad_chs', 'context_1_bad_chs', 'context_0_bad_chs']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:29.865907Z",
     "start_time": "2018-04-25T15:15:28.460659Z"
    }
   },
   "outputs": [],
   "source": [
    "func = [len_chs, vow, cons, bad_chs]\n",
    "cont_cols=['context_2', 'context_1', 'context_0', 'context_sum']\n",
    "\n",
    "for f in func:\n",
    "    col_part = 'reply_' + f.__name__\n",
    "    cols = [c + '_' + f.__name__ for c in cont_cols]\n",
    "    \n",
    "    for col  in cols:\n",
    "        try:\n",
    "            dt = get_ratio(dt, col_part, col)\n",
    "        except:\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:29.872656Z",
     "start_time": "2018-04-25T15:15:29.866948Z"
    }
   },
   "outputs": [],
   "source": [
    "col_for_dif = {}\n",
    "col_r = {}\n",
    "\n",
    "col_for_dif[0] = ['context_2_len_ws', 'context_1_len_ws', 'context_0_len_ws', 'context_sum_len_ws']\n",
    "col_r[0] = 'reply_len_ws'\n",
    "\n",
    "col_for_dif[1] = ['context_2_len_chs', 'context_1_len_chs', 'context_0_len_chs', 'context_sum_len_chs']\n",
    "col_r[1] = 'reply_len_chs'\n",
    "\n",
    "col_for_dif[2] = ['context_0_vow', 'context_sum_vow']\n",
    "col_r[2] = 'reply_vow'\n",
    "\n",
    "col_for_dif[3] = ['context_0_cons', 'context_sum_cons']\n",
    "col_r[3] = 'reply_cons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:29.881687Z",
     "start_time": "2018-04-25T15:15:29.873631Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dif(df, col_c, col_r):\n",
    "    \n",
    "    new_col = col_c + '-' + col_r\n",
    "    df[new_col] = df[col_c] - df[col_r]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_part(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = dt[col].map(df[col].value_counts(normalize=True))\n",
    "    return df\n",
    "\n",
    "def get_log(df, cols):\n",
    "    for col in cols:\n",
    "        df[col] = np.log(dt[col] + 1)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:29.899901Z",
     "start_time": "2018-04-25T15:15:29.882654Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    for c in col_for_dif[i]:\n",
    "        dt = get_dif(dt, c, col_r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:29.902794Z",
     "start_time": "2018-04-25T15:15:29.900925Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_for_part = ['is_dupl_r', \n",
    "                 'context_2_bad_chs', 'context_1_bad_chs', 'context_0_bad_chs', 'reply_bad_chs', \n",
    "                 'context_0_ovr', 'context_1_ovr', 'context_2_ovr', 'context_sum_ovr',\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:29.906744Z",
     "start_time": "2018-04-25T15:15:29.903804Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_for_log = ['context_2_len_ws', 'context_2_len_chs', 'context_2_vow','context_2_cons',\n",
    "                'context_1_len_ws', 'context_1_len_chs', 'context_1_vow','context_1_cons',\n",
    "                'context_0_len_ws', 'context_0_len_chs', 'context_0_vow','context_0_cons',\n",
    "                'context_sum_len_ws', 'context_sum_len_chs', 'context_sum_vow','context_sum_cons',\n",
    "                'reply_len_ws', 'reply_len_chs', 'reply_vow', 'reply_cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:30.213100Z",
     "start_time": "2018-04-25T15:15:29.907649Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = get_part(dt, cols_for_part)\n",
    "dt = get_log(dt, cols_for_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-12T19:31:48.337802Z",
     "start_time": "2018-04-12T19:31:48.334991Z"
    }
   },
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:30.223426Z",
     "start_time": "2018-04-25T15:15:30.214353Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastText as ft\n",
    "from fastText import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:47.912549Z",
     "start_time": "2018-04-25T15:15:30.224617Z"
    }
   },
   "outputs": [],
   "source": [
    "model_ff = load_model('/home/maatkara/fastText/cc_vec/cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:47.918763Z",
     "start_time": "2018-04-25T15:15:47.913780Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vect(x):\n",
    "    return model_ff.get_sentence_vector(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:47.924908Z",
     "start_time": "2018-04-25T15:15:47.921052Z"
    }
   },
   "outputs": [],
   "source": [
    "cols=['context_id', 'context_2', 'context_1', 'context_0', 'context_sum', 'reply_id', 'reply']\n",
    "all_context_col = ['context_2', 'context_1', 'context_0', 'context_sum','reply']\n",
    "context_col = ['context_2', 'context_1', 'context_0', 'context_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:59.900491Z",
     "start_time": "2018-04-25T15:15:47.925959Z"
    }
   },
   "outputs": [],
   "source": [
    "new_col = []\n",
    "ft_d = {}\n",
    "for col in all_context_col:\n",
    "    ft_d[col] = np.vstack(dt[col].apply(get_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:15:59.905836Z",
     "start_time": "2018-04-25T15:15:59.901759Z"
    }
   },
   "outputs": [],
   "source": [
    "cs_cols = ['c_' + str(i) for i in range(300)]\n",
    "fts = pd.DataFrame(ft_d['context_sum'],columns=cs_cols)\n",
    "\n",
    "r_cols = ['r_' + str(i) for i in range(300)]\n",
    "ftr = pd.DataFrame(ft_d['reply'],columns=r_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:16:01.098738Z",
     "start_time": "2018-04-25T15:15:59.907096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199345, 680)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.concat([dt, fts, ftr], axis=1)\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:16:01.415835Z",
     "start_time": "2018-04-25T15:16:01.100098Z"
    }
   },
   "outputs": [],
   "source": [
    "del model_ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T20:40:25.085044Z",
     "start_time": "2018-04-24T20:40:25.061793Z"
    }
   },
   "outputs": [],
   "source": [
    "def dcg(label):\n",
    "    \n",
    "    dcg = 0\n",
    "    for i in range(len(label)):\n",
    "        if label[i] > 0:\n",
    "            dcg += float(label[i] / np.log2(i+2))\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def ndcg_p(x):\n",
    "    \n",
    "    lab = x.values.tolist()\n",
    "    best_lab = x.values.tolist()\n",
    "    best_lab.sort()\n",
    "    best_lab.reverse()\n",
    "    \n",
    "    label, best_label = dcg(lab), dcg(best_lab)\n",
    "    if label != 0 and best_label != 0:\n",
    "        return label/best_label\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def score_(vl):\n",
    "\n",
    "    vl = vl.sort_values(by=['context_id', 'y_pred'], ascending=False)\n",
    "    scr = vl.groupby('context_id')['l_n'].agg(ndcg_p).mean()\n",
    "    \n",
    "    return scr * 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T20:40:26.764650Z",
     "start_time": "2018-04-24T20:40:26.727338Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_matrix_cv_numerical(data_name, n_splits=n_splits_n, random_state=random_state_n,\n",
    "                            drop_col=None, col_service=col_service, with_ft=False):\n",
    "    \"\"\"\n",
    "    Создадим матрицы для валидации и запишем на диск\n",
    "    Возвращает res_tr, res_vl  - списки с именами файлов\n",
    "    \"\"\"\n",
    "    i = 0 \n",
    "    res_tr = []\n",
    "    res_vl = []\n",
    "    \n",
    "   \n",
    "    \n",
    "    data = load_files(data_name, 'csv')\n",
    "    \n",
    "    ind = get_ind_for_model(dt, drop_col=drop_col, col_service=col_service)\n",
    "    xs = list(data.columns[ind])\n",
    "    \n",
    "    if with_ft: \n",
    "        x_name_suf = 'with_ft'\n",
    "    else:\n",
    "        xs = xs[:-600]\n",
    "        x_name_suf = 'without_ft'\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    cont_train = data[data['is_train'] == 1].groupby('context_id')['y'].sum().index\n",
    "    \n",
    "    \n",
    "    #разобъем train на train/valid для валидации по 'context_id'\n",
    "    for train_index, test_index in kf.split(cont_train):\n",
    "    \n",
    "        tr = pd.DataFrame(cont_train[train_index], columns = ['context_id']).merge(data.loc[data.is_train==1,:],\n",
    "                                                                                   how = 'left')\n",
    "        vl = pd.DataFrame(cont_train[test_index], columns = ['context_id']).merge(data.loc[data.is_train==1,:],\n",
    "                                                                                  how = 'left')\n",
    "        \n",
    "        \n",
    "        X_tr_cv = tr[xs]\n",
    "        X_vl_cv = vl[xs]\n",
    "        \n",
    "        res_tr.append(save_df_to_file(X_tr_cv, 'X_tr_cv_' + x_name_suf , 'csv', suf_out=i, verbose=False))\n",
    "        res_vl.append(save_df_to_file(X_vl_cv, 'X_vl_cv_' + x_name_suf, 'csv', suf_out=i, verbose=False))\n",
    "        print(X_tr_cv.shape, X_vl_cv.shape)       \n",
    "        i += 1\n",
    "    \n",
    "    return res_tr, res_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T20:40:28.408219Z",
     "start_time": "2018-04-24T20:40:28.327321Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_num(data,  param, num_round, n_splits=n_splits_n, drop_col=None, random_state=random_state_n, with_ft=True):\n",
    "    \n",
    "    \n",
    "    if with_ft: \n",
    "        x_name_suf = 'with_ft'\n",
    "    else:\n",
    "        x_name_suf = 'without_ft'\n",
    "\n",
    "    \n",
    "    i = 0 \n",
    "    score = 0\n",
    "    res = []\n",
    "    score_l = []\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    y = data.loc[data.is_train == 1, 'y'].values\n",
    "    \n",
    "    ind = get_ind_for_model(data, drop_col=drop_col, col_service=col_service)\n",
    "    xs = list(data.columns[ind])\n",
    "    \n",
    "    \n",
    "    cont_train = data[data['is_train'] == 1].groupby('context_id')['l_n'].count().index\n",
    "    \n",
    "    #разобъем train на train/valid для валидации по 'context_id'\n",
    "    for train_index, test_index in kf.split(cont_train):\n",
    "        \n",
    "        if i!=25: # для возможности \"отключения\" одной из папок\n",
    "            tr = pd.DataFrame(cont_train[train_index], columns = ['context_id']).merge(data.loc[data.is_train==1,:],\n",
    "                                                                                       how = 'left')\n",
    "            vl = pd.DataFrame(cont_train[test_index], columns = ['context_id']).merge(data.loc[data.is_train==1,:],\n",
    "                                                                                      how = 'left')\n",
    "        \n",
    "            gr_tr = tr.groupby('context_id')['l_n'].count().values\n",
    "            gr_vl = vl.groupby('context_id')['l_n'].count().values\n",
    "        \n",
    "            X_tr_cv = load_files('X_tr_cv_' + x_name_suf, 'csv', suf_out=i)\n",
    "            X_vl_cv = load_files('X_vl_cv_' + x_name_suf, 'csv', suf_out=i)\n",
    "        \n",
    "            y_tr = tr['y']\n",
    "            y_vl = vl['y']\n",
    "            \n",
    "            dtrain = xgb.DMatrix(X_tr_cv[xs], label=y_tr)\n",
    "            dvalid = xgb.DMatrix(X_vl_cv[xs], label=y_vl)\n",
    "            \n",
    "            dtrain.set_group(gr_tr)\n",
    "            dvalid.set_group(gr_vl)\n",
    "        \n",
    "            evallist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "        \n",
    "            clf = xgb.train(param, dtrain, num_round, evallist,  verbose_eval=0)\n",
    "            vl['y_pred'] = clf.predict(dvalid)\n",
    "        \n",
    "            score = score_(vl)\n",
    "            score_l.append(score)\n",
    "        i +=1\n",
    "    \n",
    "    res = {'mean' : np.mean(score_l), \n",
    "           'std' : np.std(score_l), \n",
    "           'score_list' : score_l}\n",
    "    print('-'*50)\n",
    "    print(res['mean'], ' mean, std=', res['std'], ' max=', np.max(score_l), ' min=', np.min(score_l))\n",
    "    print('-'*50)\n",
    "    return res\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T20:40:34.451280Z",
     "start_time": "2018-04-24T20:40:34.448949Z"
    }
   },
   "outputs": [],
   "source": [
    "res_tr_n, res_vl_n = get_matrix_cv_numerical('dt', n_splits=n_splits_n, with_ft=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T20:26:23.905614Z",
     "start_time": "2018-04-24T20:26:23.903127Z"
    }
   },
   "source": [
    "### Признаки и параметры "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исключаем признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:19:40.370602Z",
     "start_time": "2018-04-25T15:19:40.363651Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_col = ['context_sum_bad_chs',\n",
    " 'reply_len_chs__context_2_len_chs_ratio',\n",
    " 'reply_len_chs__context_1_len_chs_ratio',\n",
    " 'reply_len_chs__context_0_len_chs_ratio',\n",
    " 'reply_len_chs__context_sum_len_chs_ratio',\n",
    " 'reply_vow__context_2_vow_ratio',\n",
    " 'reply_vow__context_1_vow_ratio',\n",
    " 'reply_vow__context_0_vow_ratio',\n",
    " 'reply_vow__context_sum_vow_ratio',\n",
    " 'reply_cons__context_2_cons_ratio',\n",
    " 'reply_cons__context_1_cons_ratio',\n",
    " 'reply_cons__context_0_cons_ratio',\n",
    " 'reply_cons__context_sum_cons_ratio',\n",
    " 'reply_bad_chs__context_2_bad_chs_ratio',\n",
    " 'reply_bad_chs__context_1_bad_chs_ratio',\n",
    " 'reply_bad_chs__context_0_bad_chs_ratio',\n",
    " 'reply_bad_chs__context_sum_bad_chs_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T01:42:47.606547Z",
     "start_time": "2018-04-23T01:42:47.603232Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 8,\n",
    "    'eta': 0.05,\n",
    "    'colsample_bytree': 1,\n",
    "    'min_child_weight': 7, \n",
    "    'subsample': 1, \n",
    "    'gamma': 1, \n",
    "    \n",
    "    'booster': 'gbtree',\n",
    "    'silent':1, \n",
    "    'objective':'rank:pairwise', \n",
    "    'eval_metric': 'ndcg',\n",
    "    'nthread':8,\n",
    "    'seed' : 42,\n",
    "}\n",
    "\n",
    "num_round = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T20:18:33.981561Z",
     "start_time": "2018-04-24T20:18:33.978378Z"
    }
   },
   "outputs": [],
   "source": [
    "validate_num(dt, param, num_round, drop_col=drop_col, with_ft=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-15T19:51:30.849186Z",
     "start_time": "2018-04-15T19:51:30.846465Z"
    }
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:19:20.842955Z",
     "start_time": "2018-04-25T15:19:20.836737Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 9, \n",
    "    'eta': 0.005 , \n",
    "    'colsample_bytree': 1,\n",
    "    'min_child_weight': 7, \n",
    "    'subsample': 1, \n",
    "    'gamma': 1, \n",
    "    \n",
    "    'booster': 'gbtree',\n",
    "    'silent':1, \n",
    "    'objective':'rank:pairwise', \n",
    "    'eval_metric': 'ndcg',\n",
    "    'nthread':8,\n",
    "    'seed' : 0,\n",
    "}\n",
    "with_ft = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:19:22.631574Z",
     "start_time": "2018-04-25T15:19:22.629381Z"
    }
   },
   "outputs": [],
   "source": [
    "num_round = 4000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:19:50.683164Z",
     "start_time": "2018-04-25T15:19:49.662499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, (94511, 651), (104834, 651))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = get_ind_for_model(dt, drop_col=drop_col, col_service=col_service)\n",
    "xs = list(dt.columns[ind])\n",
    "    \n",
    "if with_ft: \n",
    "    x_name_suf = 'with_ft'\n",
    "else:\n",
    "    xs = xs[:-600]\n",
    "    x_name_suf = 'without_ft'\n",
    "\n",
    "    \n",
    "X_tr = dt.loc[dt.is_train == 1, xs]\n",
    "X_te = dt.loc[dt.is_train == 0, xs]\n",
    "\n",
    "len(xs), X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:21:00.615892Z",
     "start_time": "2018-04-25T15:21:00.340203Z"
    }
   },
   "outputs": [],
   "source": [
    "gr_train = dt.loc[dt.is_train == 1, :].groupby('context_id')['y'].count().values\n",
    "gr_test  = dt.loc[dt.is_train == 0, :].groupby('context_id')['y'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T16:16:06.271411Z",
     "start_time": "2018-04-25T15:21:02.764385Z"
    }
   },
   "outputs": [],
   "source": [
    "y_tr = dt.loc[dt.is_train == 1, 'y']\n",
    "\n",
    "dtrain = xgb.DMatrix(X_tr, label=y_tr) \n",
    "dvalid = xgb.DMatrix(X_te) \n",
    "dtrain.set_group(gr_train)\n",
    "dvalid.set_group(gr_test)\n",
    "        \n",
    "clf1 = xgb.train(param, dtrain, num_round)\n",
    "te_pr = dt.loc[dt.is_train == 0, ['context_id', 'reply_id']]\n",
    "te_pr['y_pred'] = - clf1.predict(dvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T05:42:46.492669Z",
     "start_time": "2018-04-23T05:42:46.454772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94513</th>\n",
       "      <td>4909294510</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.248553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94512</th>\n",
       "      <td>4909294510</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.246581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94515</th>\n",
       "      <td>4909294510</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.965466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94514</th>\n",
       "      <td>4909294510</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.442126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94511</th>\n",
       "      <td>4909294510</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.338845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       context_id  reply_id    y_pred\n",
       "94513  4909294510         2 -1.248553\n",
       "94512  4909294510         1 -1.246581\n",
       "94515  4909294510         4 -0.965466\n",
       "94514  4909294510         3 -0.442126\n",
       "94511  4909294510         0 -0.338845"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_pr = te_pr.sort_values(by=['context_id', 'y_pred'])\n",
    "te_pr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T05:42:52.096983Z",
     "start_time": "2018-04-23T05:42:52.092887Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = te_pr[['context_id', 'reply_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T05:42:53.951297Z",
     "start_time": "2018-04-23T05:42:53.945737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((104834, 2), 104834)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape, dt.loc[dt.is_train == 0, 'y'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T05:42:54.804545Z",
     "start_time": "2018-04-23T05:42:54.796382Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_submission(preds, number_sub, index=False, header=True):\n",
    "    \n",
    "    preds = pd.DataFrame(preds)\n",
    "    output = PTSUB + 'submition_' + str(number_sub) + '.csv'\n",
    "    preds.to_csv(output, sep=' ', index=index, header=header)\n",
    "    clf1.save_model(PTR + 'xgb' + '_'+  str(number_sub) + '.model')\n",
    "    \n",
    "    print('Sub ', number_sub, ' in ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-23T05:43:01.018660Z",
     "start_time": "2018-04-23T05:43:01.015994Z"
    }
   },
   "outputs": [],
   "source": [
    "number_sub = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T22:13:01.022541Z",
     "start_time": "2018-04-24T22:13:01.019531Z"
    }
   },
   "outputs": [],
   "source": [
    "write_submission(sub, number_sub, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "15px",
    "width": "223px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
