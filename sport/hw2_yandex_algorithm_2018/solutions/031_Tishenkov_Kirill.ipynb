{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый из файлов субтитров в датасете OpenSubtitles [2], который мы использовали в качестве источника реплик и разговоров, содержит упорядоченный набор реплик. В большинстве случаев, каждая реплика – это ответ на предыдущую, в разговоре между двумя персонажами фильма. Мы случайно выбрали эпизоды этих разговоров в качестве наших тренировочных и тестовых примеров.\n",
    "\n",
    "Каждый эпизод состоит из двух частей – контекста (Context) и финальной реплики (Reply). Например,\n",
    "\n",
    "**context_2:** Персонаж A говорит реплику   \n",
    "**context_1:** Персонаж B отвечает на нее   \n",
    "**context_0:** Персонаж А произносит вторую реплику  \n",
    "**reply:** Персонаж B отвечает на вторую реплику  \n",
    "Контекстная часть может состоять из трех реплик (как в примере) – в 50% случаев, двух – в 25%, и одного – в оставшихся 25% случаев. Финальная реплика (Reply) всегда завершает любой эпизод, то есть следует за контекстом (Context). Задача участников – найти наиболее подходящую и интересную реплику для данного контекста среди предложенных кандидатов (числом до 6), случайно выбранных из топа кандидатов, возвращенных бейзлайном высокого качества, натренированным командой Алисы (который, в свою очередь, отобрал кандидатов среди всех возможных реплик OpenSubtitles).  \n",
    "\n",
    "Все реплики-кандидаты размечены асессорами на сервисе Яндекс.Толока с помощью следующей инструкции для разметки:  \n",
    "\n",
    "- **Good (2):** реплика уместна (имеет смысл для данного контекста) и интересна (нетривиальна, специфична именно для данного контекста, мотивирует продолжать разговор)  \n",
    "- **Neutral (1):** реплика уместна (имеет смысл для данного контекста), но не интересна (тривиальна, не специфична для данного контекста и скорее подталкивает пользователя закончить разговор)  \n",
    "- **Bad (0):** реплика не имеет никакого смысла в данном контексте  \n",
    "Каждая метка в тренировочной части датасета (и только в ней), сопровождается также уверенностью (confidence) – числом в интервале от 0 до 1 – которое показывает насколько уверенными в своей разметке были асессоры с Толоки, совместно предложившие данную метку. Мы хотим обратить особое внимание участников на эту информацию, она может быть очень полезна при обучении их моделей.  \n",
    "\n",
    "Мы хотим особо отметить, что все участники имеют право скачать датасет OpenSubtitles [2], который использовался для подготовки датасета и применять его для тренировки своих моделей по своему усмотрению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы скачать данные, перейдите по ссылке /algorithm2018/contest/7914/download/1/ или Скачать условие задачи под описанием задачи.\n",
    "\n",
    "Каждая строка в тренировочной части датасета представлена в следующем формате:\n",
    "\n",
    "- **context_id** – идентификатор эпизода  \n",
    "- **context_2,context_1,context_0** – текст реплик, предшествующих финальной (может состоять из трех частей)  \n",
    "- **reply_id** – идентификатор реплики-кандидата  \n",
    "- **reply** – текст реплики-кандидата  \n",
    "- **label** – метка реплики-кандидата (good, neutral или bad)  \n",
    "- **confidence** - уверенность в метке реплики-кандидата (число от 0 до 1)  \n",
    "Каждая строка в тестовой части датасета представлена в следующем формате (по аналогии с тренировочной, но без информации о метках):  \n",
    "\n",
    "- **context_id,context_2,context_1,context_0,reply_id,reply**  \n",
    "\n",
    "Все строки в файле, который присылают участники должны быть организованы следующим образом:\n",
    "\n",
    "- **context_id, reply_id**\n",
    "\n",
    "где все context_id должны быть отсортированы на уровне посылаемого файла в возрастающем порядке\n",
    "и все reply_id должны быть в порядке ранжирования реплик (то есть, в порядке убывания их скоров), который возвратила ваша система для данного context_id\n",
    "context_id и reply_id должны быть отделены либо символом пробела либо tab\n",
    "каждый файл-решение должен содержать то же число строк, что и файл с тестовыми данными\n",
    "Обратите внимание, что финальный тестсет, для которого участники должны будут прислать свое ранжирование будет выложен за 48 часов до окончания конкурса.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрика\n",
    "Задача участников – возвратить ранжирование реплик-кандидатов представленных в порядке убывания скоров, выданных моделями участников. Метрика для оценивания этих ранжирований – NDCG. Больше информации о метрике можно найти на вики-странице https://en.wikipedia.org/wiki/Discounted_cumulative_gain - обратите внимание, что мы используем первый из двух вариантов DCG, представленных на странице.\n",
    "![image.png](https://contest.yandex.ru/testsys/statement-image?imageId=a3d60fc7162405b413487b0b1bb2d46e438be4a018a50c1768f4b8d576750cda)\n",
    "\n",
    "**IDCG** – это максимально возможное значение метрики DCG для данного набора кандидатов, оно измеряется после ранжирования кандидатов в порядке убывания значений их меток (не предсказанных скоров).\n",
    "\n",
    "**reli** принимает три возможных значения - 2, 1 и 0 - для меток **good, neutral** и **bad** соответственно.\n",
    "\n",
    "Особо отмечаем, что информация об уверенности меток (доступная только для тренировочных данных) никак не учитывается в метрике.\n",
    "\n",
    "Скор участников отображаемый в контесте - это среднее **NDCG** для всех **context_id** тестовых данных, умноженное на 100 000.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:27.405398Z",
     "start_time": "2018-04-21T00:05:26.615835Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:27.409205Z",
     "start_time": "2018-04-21T00:05:27.406716Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:27.701750Z",
     "start_time": "2018-04-21T00:05:27.410848Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    './data/train.tsv',\n",
    "    names=[\n",
    "        'context_id', 'context_2', 'context_1', 'context_0', 'reply_id',\n",
    "        'reply', 'label', 'confidence'\n",
    "    ],\n",
    "    sep='\\t', quoting=3, header=None, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:27.733496Z",
     "start_time": "2018-04-21T00:05:27.703271Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    './data/public.tsv',\n",
    "    names=[\n",
    "        'context_id', 'context_2', 'context_1', 'context_0', 'reply_id',\n",
    "        'reply'\n",
    "    ],\n",
    "    sep='\\t', quoting=3, error_bad_lines=False, header=None, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:29.524230Z",
     "start_time": "2018-04-21T00:05:29.512055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_2</th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_0</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22579918886</td>\n",
       "      <td>кликни на меня а потом на надпись \" видео - зв...</td>\n",
       "      <td>о , я тебя вижу .</td>\n",
       "      <td>ладно , повесь трубку .</td>\n",
       "      <td>0</td>\n",
       "      <td>не могу .</td>\n",
       "      <td>good</td>\n",
       "      <td>0.875352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22579918886</td>\n",
       "      <td>кликни на меня а потом на надпись \" видео - зв...</td>\n",
       "      <td>о , я тебя вижу .</td>\n",
       "      <td>ладно , повесь трубку .</td>\n",
       "      <td>1</td>\n",
       "      <td>нет , звонить буду я .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.900968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22579918886</td>\n",
       "      <td>кликни на меня а потом на надпись \" видео - зв...</td>\n",
       "      <td>о , я тебя вижу .</td>\n",
       "      <td>ладно , повесь трубку .</td>\n",
       "      <td>2</td>\n",
       "      <td>слушай , я не мог уйти .</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.884320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    context_id                                          context_2  \\\n",
       "0  22579918886  кликни на меня а потом на надпись \" видео - зв...   \n",
       "1  22579918886  кликни на меня а потом на надпись \" видео - зв...   \n",
       "2  22579918886  кликни на меня а потом на надпись \" видео - зв...   \n",
       "\n",
       "           context_1                context_0  reply_id  \\\n",
       "0  о , я тебя вижу .  ладно , повесь трубку .         0   \n",
       "1  о , я тебя вижу .  ладно , повесь трубку .         1   \n",
       "2  о , я тебя вижу .  ладно , повесь трубку .         2   \n",
       "\n",
       "                      reply    label  confidence  \n",
       "0                 не могу .     good    0.875352  \n",
       "1    нет , звонить буду я .  neutral    0.900968  \n",
       "2  слушай , я не мог уйти .      bad    0.884320  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:30.138459Z",
     "start_time": "2018-04-21T00:05:30.129091Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_2</th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_0</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138920940977</td>\n",
       "      <td>знаешь , я иногда подумываю , что тебе надо пр...</td>\n",
       "      <td>не - а .</td>\n",
       "      <td>нет ?</td>\n",
       "      <td>0</td>\n",
       "      <td>неа .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138920940977</td>\n",
       "      <td>знаешь , я иногда подумываю , что тебе надо пр...</td>\n",
       "      <td>не - а .</td>\n",
       "      <td>нет ?</td>\n",
       "      <td>1</td>\n",
       "      <td>нет , не хочу .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138920940977</td>\n",
       "      <td>знаешь , я иногда подумываю , что тебе надо пр...</td>\n",
       "      <td>не - а .</td>\n",
       "      <td>нет ?</td>\n",
       "      <td>2</td>\n",
       "      <td>нет .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     context_id                                          context_2 context_1  \\\n",
       "0  138920940977  знаешь , я иногда подумываю , что тебе надо пр...  не - а .   \n",
       "1  138920940977  знаешь , я иногда подумываю , что тебе надо пр...  не - а .   \n",
       "2  138920940977  знаешь , я иногда подумываю , что тебе надо пр...  не - а .   \n",
       "\n",
       "  context_0  reply_id            reply  \n",
       "0     нет ?         0            неа .  \n",
       "1     нет ?         1  нет , не хочу .  \n",
       "2     нет ?         2            нет .  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:31.986752Z",
     "start_time": "2018-04-21T00:05:31.983297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97533, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:44:07.738796Z",
     "start_time": "2018-04-21T01:44:07.662066Z"
    }
   },
   "outputs": [],
   "source": [
    "import fastText\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:21:05.149819Z",
     "start_time": "2018-04-21T01:21:05.113607Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymorphy2 as morphy\n",
    "from pymorphy2.tokenizers import simple_word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:05:49.883922Z",
     "start_time": "2018-04-21T00:05:49.881360Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:06:06.405514Z",
     "start_time": "2018-04-21T00:05:50.731062Z"
    }
   },
   "outputs": [],
   "source": [
    "ft_model = fastText.load_model(\"./data/wiki.ru/wiki.ru.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:06:06.420882Z",
     "start_time": "2018-04-21T00:06:06.412197Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank2num(st):\n",
    "    return {'good': 2, 'neutral': 1, 'bad': 0}[st]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:06:06.511121Z",
     "start_time": "2018-04-21T00:06:06.422897Z"
    }
   },
   "outputs": [],
   "source": [
    "train.fillna('', inplace=True)\n",
    "test.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:06:06.574964Z",
     "start_time": "2018-04-21T00:06:06.513470Z"
    }
   },
   "outputs": [],
   "source": [
    "train['rank'] = train['label'].apply(rank2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:06:06.581312Z",
     "start_time": "2018-04-21T00:06:06.576789Z"
    }
   },
   "outputs": [],
   "source": [
    "train['target'] = train['rank'] * train['confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T14:47:46.645161Z",
     "start_time": "2018-04-20T14:47:46.600834Z"
    }
   },
   "outputs": [],
   "source": [
    "train['summed_str'] = train['context_2'] + train['context_1'] + train['context_0']\n",
    "test['summed_str'] = test['context_2'] + test['context_1'] + test['context_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:00:25.820316Z",
     "start_time": "2018-04-21T00:00:25.741354Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_symb(sentence):\n",
    "    return sum(1 for x in sentence if x in '.,<>?!@#$%^&*()/\\;:')\n",
    "\n",
    "def count_vow(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'аеёиоюэя')\n",
    "\n",
    "def count_consn(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'бвгджзклмнпрстфхцчшщ')\n",
    "\n",
    "def count_ship(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'жчшщ')\n",
    "\n",
    "def count_swist(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'цзс')\n",
    "\n",
    "def count_zvon_parn(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'бвгджз')\n",
    "\n",
    "def count_glukh_parn(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'пфктшс')\n",
    "\n",
    "def count_zvon_neparn(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'лмнрй')\n",
    "\n",
    "def count_glukh_neparn(sentence):\n",
    "    return sum(1 for x in sentence.lower() if x in 'хцчщ')\n",
    "\n",
    "def count_low(sentence):\n",
    "    return sum(1 for x in sentence if x.islower())\n",
    "\n",
    "def count_up(sentence):\n",
    "    return sum(1 for x in sentence if x.isupper())\n",
    "\n",
    "def count_words(sentence):\n",
    "    return len(sentence.split(' '))\n",
    "\n",
    "funcs_dict = {\n",
    "    'count_symb': count_symb,\n",
    "    'count_vow': count_vow,\n",
    "    'count_consn': count_consn,\n",
    "    'count_ship': count_ship,\n",
    "    'count_swist': count_swist,\n",
    "    'count_zvon_parn': count_zvon_parn,\n",
    "    'count_glukh_parn': count_glukh_parn,\n",
    "    'count_zvon_neparn': count_zvon_neparn,\n",
    "    'count_glukh_neparn': count_glukh_neparn,\n",
    "    'count_low': count_low,\n",
    "    'count_up': count_up,\n",
    "    'count_words':count_words,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T14:47:56.303930Z",
     "start_time": "2018-04-20T14:47:47.752096Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, c_function in funcs_dict.items():\n",
    "    train[key] = train['summed_str'].apply(c_function)\n",
    "for key, c_function in funcs_dict.items():\n",
    "    train['reply_' + key] = train['reply'].apply(c_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T14:47:57.231452Z",
     "start_time": "2018-04-20T14:47:56.306131Z"
    }
   },
   "outputs": [],
   "source": [
    "for key, c_function in funcs_dict.items():\n",
    "    test[key] = test['summed_str'].apply(c_function)\n",
    "for key, c_function in funcs_dict.items():\n",
    "    test['reply_' + key] = test['reply'].apply(c_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T22:58:52.140802Z",
     "start_time": "2018-04-20T22:58:51.800226Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solo/.pyenv/versions/jupyter3.6.4/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "train['cont_2_words'] = scale(train['context_2'].apply(count_words))\n",
    "train['cont_1_words'] = scale(train['context_1'].apply(count_words))\n",
    "train['cont_0_words'] = scale(train['context_0'].apply(count_words))\n",
    "train['reply_words'] = scale(train['reply'].apply(count_words))\n",
    "\n",
    "test['cont_2_words'] = scale(test['context_2'].apply(count_words))\n",
    "test['cont_1_words'] = scale(test['context_1'].apply(count_words))\n",
    "test['cont_0_words'] = scale(test['context_0'].apply(count_words))\n",
    "test['reply_words'] = scale(test['reply'].apply(count_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T16:33:53.621819Z",
     "start_time": "2018-04-20T16:33:53.502529Z"
    }
   },
   "outputs": [],
   "source": [
    "train['context_2_len'] = train['context_2'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "train['context_1_len'] = train['context_1'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "train['context_0_len'] = train['context_0'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "train['context_count'] = train['context_2_len'] + train['context_1_len'] + train['context_0_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T16:33:54.379057Z",
     "start_time": "2018-04-20T16:33:54.354852Z"
    }
   },
   "outputs": [],
   "source": [
    "test['context_2_len'] = test['context_2'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "test['context_1_len'] = test['context_1'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "test['context_0_len'] = test['context_0'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "test['context_count'] = test['context_2_len'] + test['context_1_len'] + test['context_0_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:21:08.790743Z",
     "start_time": "2018-04-21T01:21:08.722797Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer = morphy.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:21:10.536362Z",
     "start_time": "2018-04-21T01:21:10.514167Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_poses(string):\n",
    "    interesting = {\n",
    "        'NOUN':0,\n",
    "        'ADJ':0,\n",
    "        'VERB':0,\n",
    "        'ADVB': 0,\n",
    "        'PRTF': 0,\n",
    "        'NPRO': 0,\n",
    "        'NUMR': 0,\n",
    "        'GRND': 0,\n",
    "        'NUMB': 0,\n",
    "        'LATN': 0\n",
    "    }\n",
    "    for token in simple_word_tokenize(string):\n",
    "        pos = analyzer.tag(token)[0].POS\n",
    "        if pos == 'ADJF' or pos == 'ADJS':\n",
    "            interesting['ADJ'] +=1\n",
    "            continue\n",
    "        if pos == 'VERB' or pos == 'INFN':\n",
    "            interesting['VERB'] +=1\n",
    "            continue\n",
    "        if pos == 'PRTF' or 'PRTS':\n",
    "            interesting['PRTF'] += 1\n",
    "            continue\n",
    "        if pos in interesting:\n",
    "            interesting[pos] += 1\n",
    "    return interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T16:33:57.080393Z",
     "start_time": "2018-04-20T16:33:57.075550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['context_id', 'context_2', 'context_1', 'context_0', 'reply_id',\n",
       "       'reply', 'cont_2_words', 'cont_1_words', 'cont_0_words', 'reply_words',\n",
       "       'context_2_len', 'context_1_len', 'context_0_len', 'context_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:06:09.500731Z",
     "start_time": "2018-04-21T00:06:09.479149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>context_2</th>\n",
       "      <th>context_1</th>\n",
       "      <th>context_0</th>\n",
       "      <th>reply_id</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>rank</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22579918886</td>\n",
       "      <td>кликни на меня а потом на надпись \" видео - зв...</td>\n",
       "      <td>о , я тебя вижу .</td>\n",
       "      <td>ладно , повесь трубку .</td>\n",
       "      <td>0</td>\n",
       "      <td>не могу .</td>\n",
       "      <td>good</td>\n",
       "      <td>0.875352</td>\n",
       "      <td>2</td>\n",
       "      <td>1.750703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22579918886</td>\n",
       "      <td>кликни на меня а потом на надпись \" видео - зв...</td>\n",
       "      <td>о , я тебя вижу .</td>\n",
       "      <td>ладно , повесь трубку .</td>\n",
       "      <td>1</td>\n",
       "      <td>нет , звонить буду я .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.900968</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    context_id                                          context_2  \\\n",
       "0  22579918886  кликни на меня а потом на надпись \" видео - зв...   \n",
       "1  22579918886  кликни на меня а потом на надпись \" видео - зв...   \n",
       "\n",
       "           context_1                context_0  reply_id  \\\n",
       "0  о , я тебя вижу .  ладно , повесь трубку .         0   \n",
       "1  о , я тебя вижу .  ладно , повесь трубку .         1   \n",
       "\n",
       "                    reply    label  confidence  rank    target  \n",
       "0               не могу .     good    0.875352     2  1.750703  \n",
       "1  нет , звонить буду я .  neutral    0.900968     1  0.900968  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T14:48:54.799606Z",
     "start_time": "2018-04-20T14:48:48.908003Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t6_ft = np.vstack(train['count_symb'])\n",
    "t7_ft = np.vstack(train['count_vow'])\n",
    "t8_ft = np.vstack(train['count_consn'])\n",
    "t9_ft = np.vstack(train['count_ship'])\n",
    "t10_ft = np.vstack(train['count_swist'])\n",
    "t11_ft = np.vstack(train['count_zvon_parn'])\n",
    "t12_ft = np.vstack(train['count_glukh_parn'])\n",
    "t13_ft = np.vstack(train['count_zvon_neparn'])\n",
    "t14_ft = np.vstack(train['count_glukh_neparn'])\n",
    "t15_ft = np.vstack(train['count_low'])\n",
    "t16_ft = np.vstack(train['count_up'])\n",
    "t16_ft = np.vstack(train['reply_count_symb'])\n",
    "t17_ft = np.vstack(train['reply_count_vow'])\n",
    "t18_ft = np.vstack(train['reply_count_consn'])\n",
    "t19_ft = np.vstack(train['reply_count_ship'])\n",
    "t20_ft = np.vstack(train['reply_count_swist'])\n",
    "t21_ft = np.vstack(train['reply_count_zvon_parn'])\n",
    "t22_ft = np.vstack(train['reply_count_glukh_parn'])\n",
    "t23_ft = np.vstack(train['reply_count_zvon_neparn'])\n",
    "t24_ft = np.vstack(train['reply_count_glukh_neparn'])\n",
    "t25_ft = np.vstack(train['reply_count_low'])\n",
    "t26_ft = np.vstack(train['reply_count_up'])\n",
    "t27_ft = np.vstack(train['count_words'])\n",
    "t28_ft = np.vstack(train['reply_count_words'])\n",
    "\n",
    "te6_ft = np.vstack(test['count_symb'])\n",
    "te7_ft = np.vstack(test['count_vow'])\n",
    "te8_ft = np.vstack(test['count_consn'])\n",
    "te9_ft = np.vstack(test['count_ship'])\n",
    "te10_ft = np.vstack(test['count_swist'])\n",
    "te11_ft = np.vstack(test['count_zvon_parn'])\n",
    "te12_ft = np.vstack(test['count_glukh_parn'])\n",
    "te13_ft = np.vstack(test['count_zvon_neparn'])\n",
    "te14_ft = np.vstack(test['count_glukh_neparn'])\n",
    "te15_ft = np.vstack(test['count_low'])\n",
    "te16_ft = np.vstack(test['count_up'])\n",
    "te16_ft = np.vstack(test['reply_count_symb'])\n",
    "te17_ft = np.vstack(test['reply_count_vow'])\n",
    "te18_ft = np.vstack(test['reply_count_consn'])\n",
    "te19_ft = np.vstack(test['reply_count_ship'])\n",
    "te20_ft = np.vstack(test['reply_count_swist'])\n",
    "te21_ft = np.vstack(test['reply_count_zvon_parn'])\n",
    "te22_ft = np.vstack(test['reply_count_glukh_parn'])\n",
    "te23_ft = np.vstack(test['reply_count_zvon_neparn'])\n",
    "te24_ft = np.vstack(test['reply_count_glukh_neparn'])\n",
    "te25_ft = np.vstack(test['reply_count_low'])\n",
    "te26_ft = np.vstack(test['reply_count_up'])\n",
    "te27_ft = np.vstack(test['count_words'])\n",
    "te28_ft = np.vstack(test['reply_count_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T22:59:22.567650Z",
     "start_time": "2018-04-20T22:59:21.434558Z"
    }
   },
   "outputs": [],
   "source": [
    "t29_ft = np.vstack(train['cont_2_words'])\n",
    "t30_ft = np.vstack(train['cont_1_words'])\n",
    "t31_ft = np.vstack(train['cont_0_words'])\n",
    "t32_ft = np.vstack(train['reply_words'])\n",
    "\n",
    "te29_ft = np.vstack(test['cont_2_words'])\n",
    "te30_ft = np.vstack(test['cont_1_words'])\n",
    "te31_ft = np.vstack(test['cont_0_words'])\n",
    "te32_ft = np.vstack(test['reply_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T21:56:32.358016Z",
     "start_time": "2018-04-20T21:56:32.051503Z"
    }
   },
   "outputs": [],
   "source": [
    "t33_ft = np.vstack(train['context_count'])\n",
    "\n",
    "te33_ft = np.vstack(test['context_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:25:00.991324Z",
     "start_time": "2018-04-21T01:21:32.393376Z"
    }
   },
   "outputs": [],
   "source": [
    "train['pymorphy_reply'] = train['reply'].apply(lambda x: count_poses(x))\n",
    "t34_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['NOUN']))\n",
    "t35_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['ADJ']))\n",
    "t36_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['VERB']))\n",
    "t37_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['ADVB']))\n",
    "t38_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['PRTF']))\n",
    "t39_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['NPRO']))\n",
    "t40_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['NUMR']))\n",
    "t41_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['GRND']))\n",
    "t42_ft = np.vstack(train['pymorphy_reply'].apply(lambda x: x['NUMB']))\n",
    "train.drop('pymorphy_reply' , axis=1 , inplace=True)\n",
    "train['pymorphy_context_0'] = train['context_0'].apply(lambda x: count_poses(x))\n",
    "t43_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['NOUN']))\n",
    "t44_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['ADJ']))\n",
    "t45_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['VERB']))\n",
    "t46_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['ADVB']))\n",
    "t47_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['PRTF']))\n",
    "t48_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['NPRO']))\n",
    "t49_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['NUMR']))\n",
    "t50_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['GRND']))\n",
    "t51_ft = np.vstack(train['pymorphy_context_0'].apply(lambda x: x['NUMB']))\n",
    "train.drop('pymorphy_context_0' , axis=1 , inplace=True)\n",
    "\n",
    "test['pymorphy_reply'] = test['reply'].apply(lambda x: count_poses(x))\n",
    "te34_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['NOUN']))\n",
    "te35_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['ADJ']))\n",
    "te36_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['VERB']))\n",
    "te37_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['ADVB']))\n",
    "te38_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['PRTF']))\n",
    "te39_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['NPRO']))\n",
    "te40_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['NUMR']))\n",
    "te41_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['GRND']))\n",
    "te42_ft = np.vstack(test['pymorphy_reply'].apply(lambda x: x['NUMB']))\n",
    "test.drop('pymorphy_reply' , axis=1 , inplace=True)\n",
    "test['pymorphy_context_0'] = test['context_0'].apply(lambda x: count_poses(x))\n",
    "te43_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['NOUN']))\n",
    "te44_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['ADJ']))\n",
    "te45_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['VERB']))\n",
    "te46_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['ADVB']))\n",
    "te47_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['PRTF']))\n",
    "te48_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['NPRO']))\n",
    "te49_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['NUMR']))\n",
    "te50_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['GRND']))\n",
    "te51_ft = np.vstack(test['pymorphy_context_0'].apply(lambda x: x['NUMB']))\n",
    "test.drop('pymorphy_context_0' , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:36:29.166402Z",
     "start_time": "2018-04-21T01:34:10.416062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pymorphy_context_1 done\n",
      "test pymorphy_context_1 done\n",
      "train pymorphy_context_2 done\n",
      "test pymorphy_context_2 done\n"
     ]
    }
   ],
   "source": [
    "train['pymorphy_context_1'] = train['context_1'].apply(lambda x: count_poses(x))\n",
    "t52_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['NOUN']))\n",
    "t53_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['ADJ']))\n",
    "t54_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['VERB']))\n",
    "t55_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['ADVB']))\n",
    "t56_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['PRTF']))\n",
    "t57_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['NPRO']))\n",
    "t58_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['NUMR']))\n",
    "t59_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['GRND']))\n",
    "t60_ft = np.vstack(train['pymorphy_context_1'].apply(lambda x: x['NUMB']))\n",
    "train.drop('pymorphy_context_1' , axis=1 , inplace=True)\n",
    "print('train pymorphy_context_1 done')\n",
    "test['pymorphy_context_1'] = test['context_1'].apply(lambda x: count_poses(x))\n",
    "te52_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['NOUN']))\n",
    "te53_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['ADJ']))\n",
    "te54_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['VERB']))\n",
    "te55_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['ADVB']))\n",
    "te56_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['PRTF']))\n",
    "te57_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['NPRO']))\n",
    "te58_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['NUMR']))\n",
    "te59_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['GRND']))\n",
    "te60_ft = np.vstack(test['pymorphy_context_1'].apply(lambda x: x['NUMB']))\n",
    "test.drop('pymorphy_context_1' , axis=1 , inplace=True)\n",
    "print('test pymorphy_context_1 done')\n",
    "train['pymorphy_context_2'] = train['context_2'].apply(lambda x: count_poses(x))\n",
    "t61_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['NOUN']))\n",
    "t62_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['ADJ']))\n",
    "t63_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['VERB']))\n",
    "t64_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['ADVB']))\n",
    "t65_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['PRTF']))\n",
    "t66_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['NPRO']))\n",
    "t67_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['NUMR']))\n",
    "t68_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['GRND']))\n",
    "t69_ft = np.vstack(train['pymorphy_context_2'].apply(lambda x: x['NUMB']))\n",
    "train.drop('pymorphy_context_2' , axis=1 , inplace=True)\n",
    "print('train pymorphy_context_2 done')\n",
    "test['pymorphy_context_2'] = test['context_2'].apply(lambda x: count_poses(x))\n",
    "te61_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['NOUN']))\n",
    "te62_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['ADJ']))\n",
    "te63_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['VERB']))\n",
    "te64_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['ADVB']))\n",
    "te65_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['PRTF']))\n",
    "te66_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['NPRO']))\n",
    "te67_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['NUMR']))\n",
    "te68_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['GRND']))\n",
    "te69_ft = np.vstack(test['pymorphy_context_2'].apply(lambda x: x['NUMB']))\n",
    "test.drop('pymorphy_context_2' , axis=1 , inplace=True)\n",
    "print('test pymorphy_context_2 done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:06:24.975009Z",
     "start_time": "2018-04-21T00:06:14.879142Z"
    }
   },
   "outputs": [],
   "source": [
    "t1_ft = np.vstack(train['context_2'].apply(lambda x: ft_model.get_sentence_vector(x)))\n",
    "t2_ft = np.vstack(train['context_1'].apply(lambda x: ft_model.get_sentence_vector(x)))\n",
    "t3_ft = np.vstack(train['context_0'].apply(lambda x: ft_model.get_sentence_vector(x)))\n",
    "t5_ft = np.vstack(train['reply'].apply(lambda x: ft_model.get_sentence_vector(x)))\n",
    "\n",
    "te1_ft = np.vstack(test['context_2'].apply(lambda x: ft_model.get_sentence_vector(x)))\n",
    "te2_ft = np.vstack(test['context_1'].apply(lambda x: ft_model.get_sentence_vector(x)))\n",
    "te3_ft = np.vstack(test['context_0'].apply(lambda x: ft_model.get_sentence_vector(x)))\n",
    "te5_ft = np.vstack(test['reply'].apply(lambda x: ft_model.get_sentence_vector(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:53:16.226464Z",
     "start_time": "2018-04-21T01:53:15.442307Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.hstack([\n",
    "    t1_ft, t2_ft, t3_ft, t5_ft, \n",
    "#     t6_ft, t7_ft, t8_ft, t9_ft, t10_ft, t11_ft,\n",
    "#     t12_ft, t13_ft, t14_ft, t15_ft, t16_ft, \n",
    "#     t16_ft, t17_ft, \n",
    "#     t18_ft, t19_ft, t20_ft, t21_ft, t22_ft, t23_ft, t24_ft, t25_ft, t26_ft, \n",
    "#     t27_ft, t28_ft,\n",
    "#     t29_ft, t30_ft, t31_ft, t32_ft,\n",
    "#     t33_ft,\n",
    "    t34_ft, t35_ft, t36_ft, t37_ft, t38_ft, t39_ft, t40_ft, t41_ft, t42_ft, \n",
    "    t43_ft, t44_ft, t45_ft, t46_ft, t47_ft, t48_ft, t49_ft, t50_ft, t51_ft, \n",
    "    t52_ft, t53_ft, t54_ft, t55_ft, t56_ft, t57_ft, t58_ft, t59_ft, t60_ft,\n",
    "    t61_ft, t62_ft, t63_ft, t64_ft, t65_ft, t66_ft, t67_ft, t68_ft, t69_ft,\n",
    "])\n",
    "\n",
    "X_test = np.hstack([\n",
    "    te1_ft, te2_ft, te3_ft, te5_ft, \n",
    "#     te6_ft, te7_ft, te8_ft, te9_ft, te10_ft,\n",
    "#     te11_ft, te12_ft, te13_ft, te14_ft, te15_ft, \n",
    "#     te16_ft, te17_ft,\n",
    "#     te18_ft, te19_ft, te20_ft, te21_ft, te22_ft, te23_ft, te24_ft, te25_ft, te26_ft, \n",
    "#     te27_ft, te28_ft\n",
    "#     te29_ft, te30_ft, te31_ft, te32_ft,\n",
    "#     te33_ft,\n",
    "    te34_ft, te35_ft, te36_ft, te37_ft, te38_ft, te39_ft, te40_ft, te41_ft, te42_ft, \n",
    "    te43_ft, te44_ft, te45_ft, te46_ft, te47_ft, te48_ft, te49_ft, te50_ft, te51_ft,\n",
    "    te52_ft, te53_ft, te54_ft, te55_ft, te56_ft, te57_ft, te58_ft, te59_ft, te60_ft,\n",
    "    te61_ft, te62_ft, te63_ft, te64_ft, te65_ft, te66_ft, te67_ft, te68_ft, te69_ft, \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T03:17:22.796555Z",
     "start_time": "2018-04-21T03:17:22.792625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97533, 1236)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:37:07.398302Z",
     "start_time": "2018-04-21T01:37:07.395702Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:37:08.274083Z",
     "start_time": "2018-04-21T01:37:08.165955Z"
    }
   },
   "outputs": [],
   "source": [
    "train_part_size = int(0.75 * train['target'].shape[0])\n",
    "X_train_part = X_train[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid =  X_train[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:37:16.628728Z",
     "start_time": "2018-04-21T01:37:16.615195Z"
    }
   },
   "outputs": [],
   "source": [
    "def form_last_vec(models, X_vec):\n",
    "    return np.array([\n",
    "        models['m_00'].predict(X_vec),\n",
    "        models['m_01'].predict(X_vec),\n",
    "        models['m_02'].predict(X_vec),\n",
    "    ]).T\n",
    "\n",
    "\n",
    "def my_fit(models, X_train, y_train):\n",
    "    models['m_00'].fit(X_train, y_train)\n",
    "    models['m_01'].fit(X_train, y_train)\n",
    "    models['m_02'].fit(X_train, y_train)\n",
    "\n",
    "    models['m_10'].fit(form_last_vec(models, X_train), y_train)\n",
    "    return models['m_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T00:09:14.098507Z",
     "start_time": "2018-04-21T00:09:14.092691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001) \n",
      "\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) \n",
      "\n",
      " Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rid = Ridge()\n",
    "lin = LinearRegression()\n",
    "lasso = Lasso()\n",
    "print(rid, '\\n\\n', lin, '\\n\\n', lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge(Ridge+LinearRegression+Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:39:53.409021Z",
     "start_time": "2018-04-21T01:39:31.372575Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'm_00': Ridge(),\n",
    "    'm_01': LinearRegression(n_jobs=8),\n",
    "    'm_02': Lasso(),\n",
    "    'm_10': Ridge(),\n",
    "}\n",
    "\n",
    "models['m_10'] = my_fit(models, X_train_part, y_train_part)\n",
    "ridge_pred_up = models['m_10'].predict(form_last_vec(models, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:39:53.417310Z",
     "start_time": "2018-04-21T01:39:53.411651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216629051721983\n"
     ]
    }
   ],
   "source": [
    "valid_mae = mean_absolute_error(y_valid, ridge_pred_up)\n",
    "print(valid_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:40:43.832308Z",
     "start_time": "2018-04-21T01:40:11.426000Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_up = my_fit(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:40:57.324702Z",
     "start_time": "2018-04-21T01:40:57.286497Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = ridge_up.predict(form_last_vec(models, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean(Ridge+LinearRegression+Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:37:51.628431Z",
     "start_time": "2018-04-21T01:37:28.125539Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7337914681315665\n"
     ]
    }
   ],
   "source": [
    "random_state = 8123\n",
    "models = {\n",
    "    'm_00': Ridge(),\n",
    "    'm_01': LinearRegression(n_jobs=8, ),\n",
    "    'm_02': Lasso(),\n",
    "    'm_10': Ridge(max_iter=10000, random_state=random_state),\n",
    "}\n",
    "models['m_10'] = my_fit(models, X_train_part, y_train_part)\n",
    "\n",
    "mean_pred_up = form_last_vec(models, X_valid).mean(axis=1)\n",
    "valid_mae = mean_absolute_error(y_valid, mean_pred_up)\n",
    "print(valid_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T23:01:25.405895Z",
     "start_time": "2018-04-20T23:01:02.800964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7338830055207693\n"
     ]
    }
   ],
   "source": [
    "models['m_10'] = my_fit(models, X_train_part, y_train_part)\n",
    "\n",
    "mean_pred_up = form_last_vec(models, X_valid).mean(axis=1)\n",
    "valid_mae = mean_absolute_error(y_valid, mean_pred_up)\n",
    "print(valid_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:38:22.237766Z",
     "start_time": "2018-04-21T01:37:51.633288Z"
    }
   },
   "outputs": [],
   "source": [
    "models['m_10'] = my_fit(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final mean(Ridge+LinearRegression+Lasso+tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T01:53:25.008792Z",
     "start_time": "2018-04-21T01:53:24.991460Z"
    }
   },
   "outputs": [],
   "source": [
    "def form_last_vec(models, X_vec):\n",
    "    return np.array([\n",
    "        models['m_00'].predict(X_vec[:,:1200]),\n",
    "        models['m_01'].predict(X_vec[:,:1200]),\n",
    "        models['m_02'].predict(X_vec[:,:1200]),\n",
    "        models['m_03'].predict(X_vec),\n",
    "    ]).T\n",
    "\n",
    "\n",
    "def my_fit(models, X_train, y_train):\n",
    "    models['m_00'].fit(X_train[:,:1200], y_train)\n",
    "    models['m_01'].fit(X_train[:,:1200], y_train)\n",
    "    models['m_02'].fit(X_train[:,:1200], y_train)\n",
    "    models['m_03'].fit(X_train, y_train)\n",
    "    \n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T02:07:09.942814Z",
     "start_time": "2018-04-21T01:53:35.192379Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7345850971716941\n"
     ]
    }
   ],
   "source": [
    "random_state = 8123\n",
    "models = {\n",
    "    'm_00': Ridge(),\n",
    "    'm_01': LinearRegression(n_jobs=8, ),\n",
    "    'm_02': Lasso(),\n",
    "    'm_03': XGBRegressor(objective='rank:pairwise' , max_depth=15, min_child_weight=5, n_estimators=50, \n",
    "                         random_state=random_state, seed=random_state,),\n",
    "    'm_10': Ridge(max_iter=10000, random_state=random_state),\n",
    "}\n",
    "_ = my_fit(models, X_train_part, y_train_part)\n",
    "\n",
    "mean_pred_up = form_last_vec(models, X_valid).mean(axis=1)\n",
    "valid_mae = mean_absolute_error(y_valid, mean_pred_up)\n",
    "print(valid_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T02:26:16.694172Z",
     "start_time": "2018-04-21T02:07:41.775016Z"
    }
   },
   "outputs": [],
   "source": [
    "models['m_10'] = my_fit(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T02:26:17.093684Z",
     "start_time": "2018-04-21T02:26:16.695985Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = form_last_vec(models, X_test).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overfitted tree(Ridge+LinearRegression+Lasso+tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T02:31:30.302908Z",
     "start_time": "2018-04-21T02:31:30.286499Z"
    }
   },
   "outputs": [],
   "source": [
    "def form_last_vec(models, X_vec):\n",
    "    return np.array([\n",
    "        models['m_00'].predict(X_vec[:,:1200]),\n",
    "        models['m_01'].predict(X_vec[:,:1200]),\n",
    "        models['m_02'].predict(X_vec[:,:1200]),\n",
    "        models['m_03'].predict(X_vec),\n",
    "    ]).T\n",
    "\n",
    "\n",
    "def my_fit(models, X_train, y_train):\n",
    "    models['m_00'].fit(X_train[:,:1200], y_train)\n",
    "    models['m_01'].fit(X_train[:,:1200], y_train)\n",
    "    models['m_02'].fit(X_train[:,:1200], y_train)\n",
    "    models['m_03'].fit(X_train, y_train)\n",
    "    \n",
    "    return models['m_10'].fit(form_last_vec(models, X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T02:45:26.569607Z",
     "start_time": "2018-04-21T02:31:38.452423Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325799027853495\n"
     ]
    }
   ],
   "source": [
    "random_state = 8123\n",
    "models = {\n",
    "    'm_00': Ridge(),\n",
    "    'm_01': LinearRegression(n_jobs=8, ),\n",
    "    'm_02': Lasso(),\n",
    "    'm_03': XGBRegressor(objective='rank:pairwise' , max_depth=15, min_child_weight=5, n_estimators=50, \n",
    "                         random_state=random_state, seed=random_state,),\n",
    "    'm_10': XGBRegressor(objective='rank:pairwise' , max_depth=3, min_child_weight=5, n_estimators=5, \n",
    "                         random_state=random_state, seed=random_state,),\n",
    "}\n",
    "\n",
    "models['m_10'] = my_fit(models, X_train_part, y_train_part)\n",
    "\n",
    "tree_pred_up = models['m_10'].predict(form_last_vec(models, X_valid))\n",
    "valid_mae = mean_absolute_error(y_valid, tree_pred_up)\n",
    "print(valid_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T03:09:29.100634Z",
     "start_time": "2018-04-21T02:50:34.441075Z"
    }
   },
   "outputs": [],
   "source": [
    "models['m_10'] = my_fit(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T03:09:29.472896Z",
     "start_time": "2018-04-21T03:09:29.102330Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = models['m_10'].predict(form_last_vec(models, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-21T03:09:29.521509Z",
     "start_time": "2018-04-21T03:09:29.474561Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['context_id'] = test['context_id']\n",
    "sub['reply_id'] = test['reply_id']\n",
    "sub['rank'] = - y_test\n",
    "submission = sub.sort_values(by=['context_id', 'rank'])\n",
    "del submission['rank']\n",
    "submission.to_csv('./data/yandex-ml-stack-tree-tree-69.tsv',header=None, index=False, sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "364px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
