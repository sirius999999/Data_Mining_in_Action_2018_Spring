{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Yandex.Algorithm ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Каждый из файлов субтитров в датасете OpenSubtitles [2], который мы использовали в качестве источника реплик и разговоров, содержит упорядоченный набор реплик. В большинстве случаев, каждая реплика – это ответ на предыдущую, в разговоре между двумя персонажами фильма. Мы случайно выбрали эпизоды этих разговоров в качестве наших тренировочных и тестовых примеров.\n",
    "\n",
    "Каждый эпизод состоит из двух частей – контекста (Context) и финальной реплики (Reply). Например,\n",
    "\n",
    "- context_2: Персонаж A говорит реплику \n",
    "\n",
    "- context_1: Персонаж B отвечает на нее \n",
    "\n",
    "- context_0: Персонаж А произносит вторую реплику \n",
    "\n",
    "reply: Персонаж B отвечает на вторую реплику \n",
    "Контекстная часть может состоять из трех реплик (как в примере) – в 50% случаев, двух – в 25%, и одного – в оставшихся 25% случаев. Финальная реплика (Reply) всегда завершает любой эпизод, то есть следует за контекстом (Context). Задача участников – найти наиболее подходящую и интересную реплику для данного контекста среди предложенных кандидатов (числом до 6), случайно выбранных из топа кандидатов, возвращенных бейзлайном высокого качества, натренированным командой Алисы (который, в свою очередь, отобрал кандидатов среди всех возможных реплик OpenSubtitles).\n",
    "\n",
    "Все реплики-кандидаты размечены асессорами на сервисе Яндекс.Толока с помощью следующей инструкции для разметки:\n",
    "\n",
    "- Good (2): реплика уместна (имеет смысл для данного контекста) и интересна (нетривиальна, специфична именно для данного контекста, мотивирует продолжать разговор)\n",
    "\n",
    "- Neutral (1): реплика уместна (имеет смысл для данного контекста), но не интересна (тривиальна, не специфична для данного контекста и скорее подталкивает пользователя закончить разговор)\n",
    "\n",
    "- Bad (0): реплика не имеет никакого смысла в данном контексте\n",
    "\n",
    "Каждая метка в тренировочной части датасета (и только в ней), сопровождается также уверенностью (confidence) – числом в интервале от 0 до 1 – которое показывает насколько уверенными в своей разметке были асессоры с Толоки, совместно предложившие данную метку. Мы хотим обратить особое внимание участников на эту информацию, она может быть очень полезна при обучении их моделей.\n",
    "\n",
    "Мы хотим особо отметить, что все участники имеют право скачать датасет OpenSubtitles [2], который использовался для подготовки датасета и применять его для тренировки своих моделей по своему усмотрению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:27.544965Z",
     "start_time": "2018-04-08T16:28:27.386160Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T15:30:06.831306Z",
     "start_time": "2018-04-08T15:30:06.692348Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- context_id – идентификатор эпизода\n",
    "- context_2,context_1,context_0 – текст реплик, предшествующих финальной (может состоять из трех частей)\n",
    "- reply_id – идентификатор реплики-кандидата\n",
    "- reply – текст реплики-кандидата\n",
    "- label – метка реплики-кандидата (good, neutral или bad)\n",
    "- confidence - уверенность в метке реплики-кандидата (число от 0 до 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:27.778102Z",
     "start_time": "2018-04-08T16:28:27.593595Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.tsv', sep='\\t', quotechar=' ', header = None)\n",
    "df.columns = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply', 'label', 'confidence']\n",
    "test = pd.read_csv('data/public.tsv', sep='\\t', quotechar = ' ', header = None)\n",
    "test.columns = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T15:30:07.017819Z",
     "start_time": "2018-04-08T15:30:07.008779Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T15:30:07.050353Z",
     "start_time": "2018-04-08T15:30:07.019249Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "y - label, and prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:27.789680Z",
     "start_time": "2018-04-08T16:28:27.784285Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def label_enc(x ,reverse = False):\n",
    "    if reverse == False:\n",
    "        if x == 'bad':\n",
    "            return 0\n",
    "        elif x == 'neutral':\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        if x == 0:\n",
    "            return 'bad'\n",
    "        elif x == 1:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:27.832586Z",
     "start_time": "2018-04-08T16:28:27.803683Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x: label_enc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:27.956085Z",
     "start_time": "2018-04-08T16:28:27.848202Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:27.968875Z",
     "start_time": "2018-04-08T16:28:27.963398Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def DCG(label): return sum([float(label[i]/np.log2(i+2)) for i in range(len(label))])\n",
    "\n",
    "def nDCG(label, best_label):\n",
    "    label, best_label = DCG(label), DCG(best_label)\n",
    "    if label != 0 and best_label != 0:\n",
    "        return label/best_label\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "scorer = make_scorer(nDCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nan clearing\n",
    "Wanted more clever way to dell and fill nan, but dropna or fillna, will work good."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:31:43.934508Z",
     "start_time": "2018-04-08T13:30:33.730411Z"
    },
    "hidden": true
   },
   "source": [
    "for i in df['context_id'].unique():\n",
    "    if True in df[df['context_id'] == i].isnull().any().values:\n",
    "        if df[df['context_id'] == i].shape[0] in df[df['context_id'] == i].isnull().sum()[df[df['context_id'] == i].isnull().sum() > 0].values:\n",
    "            df.drop(index=df[df['context_id'] == i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:28.009067Z",
     "start_time": "2018-04-08T16:28:27.986095Z"
    },
    "hidden": true,
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "df.fillna('-', inplace=True)\n",
    "test.fillna('-', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:28.039095Z",
     "start_time": "2018-04-08T16:28:28.035511Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:29.548977Z",
     "start_time": "2018-04-08T16:28:28.064234Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def Vect(df, test):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    \n",
    "    context_0 = tfidf.fit_transform(df['context_0'])\n",
    "    context_0_t = tfidf.transform(test['context_0'])\n",
    "    \n",
    "    context_1 = tfidf.fit_transform(df['context_1'])\n",
    "    context_1_t = tfidf.transform(test['context_1'])\n",
    "\n",
    "    \n",
    "    context_2 = tfidf.fit_transform(df['context_2'])\n",
    "    context_2_t = tfidf.transform(test['context_1'])\n",
    "\n",
    "    reply = tfidf.fit_transform(df['reply'])\n",
    "    reply_t = tfidf.transform(test['reply'])\n",
    "    \n",
    "    return sps.hstack((context_0, context_1, context_2, reply)), \\\n",
    "           sps.hstack((context_0_t, context_1_t, context_2_t, reply_t))\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test = Vect(df, test)\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T13:51:00.034698Z",
     "start_time": "2018-04-08T13:51:00.031784Z"
    }
   },
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:29.619308Z",
     "start_time": "2018-04-08T16:28:29.598144Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:13:16.797765Z",
     "start_time": "2018-04-08T16:13:16.784279Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def Testing_grid_reg(X_train, Y_train, c=[10.0 ** i for i in range(-9, 8)]):\n",
    "    grid = {'C': c,\n",
    "           'penalty' : ['l1', 'l2']}\n",
    "    \n",
    "    clf = LogisticRegression(n_jobs=1)\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    gs = GridSearchCV(clf, scoring=scorer, param_grid=grid, cv=5, \n",
    "                      return_train_score=True, n_jobs=-1, verbose = True)\n",
    "    gs.fit(X_train,Y_train)\n",
    "    print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "    \n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    \n",
    "    for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    \n",
    "    return max(means), gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-08T16:13:19.260Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "Testing_grid_reg(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:32.910891Z",
     "start_time": "2018-04-08T16:28:29.631867Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:32.930585Z",
     "start_time": "2018-04-08T16:28:32.920358Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "pred_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:32.963975Z",
     "start_time": "2018-04-08T16:28:32.942589Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "pred_proba  = [i.max() for i in pred_proba]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:28:37.543892Z",
     "start_time": "2018-04-08T16:28:37.540774Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "test['confidence'] = pred_proba\n",
    "test['label']  = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-08T16:37:12.048236Z",
     "start_time": "2018-04-08T16:37:12.023128Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "test.sort_values(by=['context_id', 'confidence'], ascending=False)[['context_id', 'reply_id']].to_csv('subm.csv', encoding='utf-8', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}