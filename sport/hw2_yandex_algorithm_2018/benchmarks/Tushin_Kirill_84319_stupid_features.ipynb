{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:07.651977Z",
     "start_time": "2018-04-18T09:14:07.351410Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm_notebook\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score , GroupKFold\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns' , 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T08:55:56.939790Z",
     "start_time": "2018-04-18T08:55:56.937611Z"
    }
   },
   "source": [
    "# Simple functions applicable to the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:07.930489Z",
     "start_time": "2018-04-18T09:14:07.902081Z"
    }
   },
   "outputs": [],
   "source": [
    "def vowels_count(x):\n",
    "    '''\n",
    "        x : string\n",
    "            string for get vowels count\n",
    "    '''\n",
    "    return len(re.findall(vowels, x))\n",
    "\n",
    "\n",
    "def consonant_count(x):\n",
    "    '''\n",
    "        x : string\n",
    "            string for get consonant count\n",
    "    '''\n",
    "    return len(re.findall(consonant, x))\n",
    "\n",
    "\n",
    "def divide_vov_by_cons(x):\n",
    "    '''\n",
    "        x : string\n",
    "            string for get ratio of vowels to consonants\n",
    "    '''\n",
    "    return vowels_count(x)/(consonant_count(x) + 0.001)\n",
    "\n",
    "\n",
    "def count_word(x):\n",
    "    '''\n",
    "        x : string\n",
    "            string for get count of word in string\n",
    "    '''\n",
    "    return len(x.split(' '))\n",
    "\n",
    "func = [len, vowels_count, consonant_count, divide_vov_by_cons, count_word]\n",
    "func_name = ['len', 'vowels_count', 'consonant_count','divide_vov_by_cons', 'count_word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:08.241432Z",
     "start_time": "2018-04-18T09:14:08.220648Z"
    }
   },
   "outputs": [],
   "source": [
    "def dcg_at_k(r):\n",
    "    '''\n",
    "        r : int\n",
    "            Assigned label\n",
    "    '''\n",
    "    r = np.asfarray(r)\n",
    "    if r.size:\n",
    "        return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r):\n",
    "    '''\n",
    "        r : int\n",
    "            Assigned label\n",
    "    '''\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True))\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r) / dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:08.630699Z",
     "start_time": "2018-04-18T09:14:08.601488Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid(estimator, X, y, columns , n_folds = 5):\n",
    "    '''\n",
    "        estimator : estimator object implementing ‘fit’ and ‘predict’\n",
    "            The object to use to fit the data.\n",
    "        X : dataframe\n",
    "            Data for predict y\n",
    "        y : array , pandas.Series\n",
    "            label for predict\n",
    "        columns : list\n",
    "            Features that will be used in the prediction\n",
    "    '''\n",
    "    result = []\n",
    "    for tr_ind, vl_ind in GroupKFold(n_folds).split(X, groups=X['context_id']):\n",
    "        predict = X.loc[vl_ind, ['context_id', 'reply_id', 'label']].copy()\n",
    "        estimator.fit(X.loc[tr_ind, columns], y.loc[tr_ind])\n",
    "        predict['score'] = estimator.predict(X.loc[vl_ind, columns])\n",
    "\n",
    "        sub = predict.sort_values(by=['context_id', 'score'], \n",
    "                                  ascending=False)[['context_id', 'label']]\n",
    "\n",
    "        res = sub.groupby('context_id')['label'].apply(ndcg_at_k).mean()\n",
    "        result.append(res)\n",
    "    return np.array(result)*100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:08.970161Z",
     "start_time": "2018-04-18T09:14:08.952154Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_feature(X):\n",
    "    '''\n",
    "        X : dataframe\n",
    "            Dataset for preprocess\n",
    "    '''\n",
    "    X = X.copy()\n",
    "    X['context_2_notnull'] = X['context_2'].notnull().astype('int8')\n",
    "    X['context_1_notnull'] = X['context_1'].notnull().astype('int8')\n",
    "\n",
    "    X.fillna('', inplace=True)\n",
    "    X['is_duplicate_reply'] = X['reply'].duplicated(keep=False).astype('int8')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:09.361529Z",
     "start_time": "2018-04-18T09:14:09.337494Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_punctuation(x):\n",
    "    '''\n",
    "        x : string\n",
    "            String from which the punctuation is removed\n",
    "    '''\n",
    "    return re.sub('[%s]' % string.punctuation, ' ', x)\n",
    "\n",
    "def simple_feature(X):\n",
    "    '''\n",
    "        X : dataframe\n",
    "            Dataset for get first feature\n",
    "    '''\n",
    "    for col in ['reply', 'context_2', 'context_1', 'context_0']:\n",
    "        X[col] = X[col].apply(drop_punctuation)\n",
    "\n",
    "    for col in ['context_2', 'context_1', 'context_0', 'reply']:\n",
    "        for f, name in zip(func, func_name):\n",
    "            X[col + '_' + name] = X[col].apply(f)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:09.946479Z",
     "start_time": "2018-04-18T09:14:09.698417Z"
    }
   },
   "outputs": [],
   "source": [
    "train_col_names = ['context_id','context_2','context_1','context_0','reply_id','reply','label','confidence']\n",
    "public_col_names = ['context_id','context_2','context_1','context_0','reply_id','reply']\n",
    "\n",
    "\n",
    "train = pd.read_csv('data/train.tsv', sep='\\t' , quotechar=' ', header=None , names = train_col_names)\n",
    "public = pd.read_csv('data/public.tsv', sep='\\t', quotechar=' ', header=None , names = public_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:10.569640Z",
     "start_time": "2018-04-18T09:14:10.465876Z"
    }
   },
   "outputs": [],
   "source": [
    "map_label = {'bad': 0, 'neutral': 1, 'good': 2}\n",
    "\n",
    "train['label'] = train['label'].map(map_label)\n",
    "\n",
    "train['target'] = 0\n",
    "train.loc[train['label'] == 0, 'target'] = 1 - train.loc[train['label'] == 0, 'confidence']\n",
    "train.loc[train['label'] == 1, 'target'] = train.loc[train['label'] == 1, 'confidence']\n",
    "train.loc[train['label'] == 2, 'target'] = 2*train.loc[train['label'] == 2, 'confidence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:16.126000Z",
     "start_time": "2018-04-18T09:14:11.064635Z"
    }
   },
   "outputs": [],
   "source": [
    "vowels = '[аеиоуыэюя]'\n",
    "consonant = '[бвгджзйклмнпрстфхцчшщъьа]'\n",
    "alphabet = vowels[:-1] + consonant[1:]\n",
    "\n",
    "\n",
    "train = preprocess_feature(train)\n",
    "public = preprocess_feature(public)\n",
    "\n",
    "train = simple_feature(train)\n",
    "public = simple_feature(public)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:17.359346Z",
     "start_time": "2018-04-18T09:14:17.354817Z"
    }
   },
   "outputs": [],
   "source": [
    "to_drop = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id',\n",
    "       'reply', 'label', 'confidence' , 'target']\n",
    "\n",
    "columns = train.columns.drop(to_drop)\n",
    "\n",
    "model = XGBRegressor(objective='rank:pairwise' , max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:37.797886Z",
     "start_time": "2018-04-18T09:14:18.566706Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82955.0125798502 390.8996378980851\n"
     ]
    }
   ],
   "source": [
    "score = valid(model , X = train , y = train['target'] , columns=columns , n_folds=3)\n",
    "print (score.mean() , score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T09:14:48.334079Z",
     "start_time": "2018-04-18T09:14:38.940838Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "public['target'] = model.fit(train[columns] , train['target']).predict(public[columns])\n",
    "\n",
    "sub = public.sort_values(by=['context_id', 'target'], \n",
    "                                  ascending=False)[['context_id', 'reply_id']]\n",
    "    \n",
    "sub.to_csv('sub.tsv' , sep='\\t' , header=False , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
