{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.tsv', sep='\\t', quotechar=' ', header = None)\n",
    "train.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('public.tsv', sep='\\t', quoting=3, error_bad_lines=False, header=None, encoding=\"utf-8\")\n",
    "test.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply', 'label', 'confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.columns = ['context_id', 'context_2', 'context_1', 'context_0', 'reply_id', 'reply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2 as morphy\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "analyzer = morphy.MorphAnalyzer()\n",
    "\n",
    "def count_poses(string):\n",
    "    interesting = {\n",
    "        'NOUN':0,\n",
    "        'ADJ':0,\n",
    "        'VERB':0,\n",
    "        'ADVB': 0,\n",
    "        'PRTF': 0,\n",
    "        'NPRO': 0,\n",
    "        'NUMR': 0,\n",
    "        'GRND': 0,\n",
    "        'NUMB': 0,\n",
    "        'LATN': 0\n",
    "    }\n",
    "    for token in simple_word_tokenize(string):\n",
    "        pos = analyzer.tag(token)[0].POS\n",
    "        if pos == 'ADJF' or pos == 'ADJS':\n",
    "            interesting['ADJ'] +=1\n",
    "            continue\n",
    "        if pos == 'VERB' or pos == 'INFN':\n",
    "            interesting['VERB'] +=1\n",
    "            continue\n",
    "        if pos == 'PRTF' or 'PRTS':\n",
    "            interesting['PRTF'] += 1\n",
    "            continue\n",
    "        if pos in interesting:\n",
    "            interesting[pos] += 1\n",
    "    return interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_labels_as_numbers(label):\n",
    "    if label == 'bad':\n",
    "        return 0\n",
    "    if label == 'neutral':\n",
    "        return 1\n",
    "    if label == 'good':\n",
    "        return 2\n",
    "    return None\n",
    "\n",
    "def decode_labels_as_strings(label):\n",
    "    if label == 0:\n",
    "        return 'bad'\n",
    "    if label == 1:\n",
    "        return 'neutral'\n",
    "    if label == 2:\n",
    "        return 'good'\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank2num(st):\n",
    "    if st == 'good':\n",
    "        return 2\n",
    "    else:\n",
    "        if st == 'neutral':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pymorphy_reply'] = train['reply'].apply(lambda x: count_poses(x))\n",
    "train['reply_NOUN'] = train['pymorphy_reply'].apply(lambda x: x['NOUN'])\n",
    "train['reply_ADJ'] = train['pymorphy_reply'].apply(lambda x: x['ADJ'])\n",
    "train['reply_VERB'] = train['pymorphy_reply'].apply(lambda x: x['VERB'])\n",
    "train['reply_ADVB'] = train['pymorphy_reply'].apply(lambda x: x['ADVB'])\n",
    "train['reply_PRTF'] = train['pymorphy_reply'].apply(lambda x: x['PRTF'])\n",
    "train['reply_NPRO'] = train['pymorphy_reply'].apply(lambda x: x['NPRO'])\n",
    "train['reply_NUMR'] = train['pymorphy_reply'].apply(lambda x: x['NUMR'])\n",
    "train['reply_GRND'] = train['pymorphy_reply'].apply(lambda x: x['GRND'])\n",
    "train['reply_NUMB'] = train['pymorphy_reply'].apply(lambda x: x['NUMB'])\n",
    "train.drop('pymorphy_reply' , axis=1 , inplace=True)\n",
    "\n",
    "train['pymorphy_context_0'] = train['context_0'].apply(lambda x: count_poses(x))\n",
    "train['context_0_NOUN'] = train['pymorphy_context_0'].apply(lambda x: x['NOUN'])\n",
    "train['context_0_ADJ'] = train['pymorphy_context_0'].apply(lambda x: x['ADJ'])\n",
    "train['context_0_VERB'] = train['pymorphy_context_0'].apply(lambda x: x['VERB'])\n",
    "train['context_0_ADVB'] = train['pymorphy_context_0'].apply(lambda x: x['ADVB'])\n",
    "train['context_0_PRTF'] = train['pymorphy_context_0'].apply(lambda x: x['PRTF'])\n",
    "train['context_0_NPRO'] = train['pymorphy_context_0'].apply(lambda x: x['NPRO'])\n",
    "train['context_0_NUMR'] = train['pymorphy_context_0'].apply(lambda x: x['NUMR'])\n",
    "train['context_0_GRND'] = train['pymorphy_context_0'].apply(lambda x: x['GRND'])\n",
    "train['context_0_NUMB'] = train['pymorphy_context_0'].apply(lambda x: x['NUMB'])\n",
    "\n",
    "train.drop('pymorphy_context_0' , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pymorphy_reply'] = test['reply'].apply(lambda x: count_poses(x))\n",
    "test['reply_NOUN'] = test['pymorphy_reply'].apply(lambda x: x['NOUN'])\n",
    "test['reply_ADJ'] = test['pymorphy_reply'].apply(lambda x: x['ADJ'])\n",
    "test['reply_VERB'] = test['pymorphy_reply'].apply(lambda x: x['VERB'])\n",
    "test['reply_ADVB'] = test['pymorphy_reply'].apply(lambda x: x['ADVB'])\n",
    "test['reply_PRTF'] = test['pymorphy_reply'].apply(lambda x: x['PRTF'])\n",
    "test['reply_NPRO'] = test['pymorphy_reply'].apply(lambda x: x['NPRO'])\n",
    "test['reply_NUMR'] = test['pymorphy_reply'].apply(lambda x: x['NUMR'])\n",
    "test['reply_GRND'] = test['pymorphy_reply'].apply(lambda x: x['GRND'])\n",
    "test['reply_NUMB'] = test['pymorphy_reply'].apply(lambda x: x['NUMB'])\n",
    "test.drop('pymorphy_reply' , axis=1 , inplace=True)\n",
    "\n",
    "test['pymorphy_context_0'] = test['context_0'].apply(lambda x: count_poses(x))\n",
    "test['context_0_NOUN'] = test['pymorphy_context_0'].apply(lambda x: x['NOUN'])\n",
    "test['context_0_ADJ'] = test['pymorphy_context_0'].apply(lambda x: x['ADJ'])\n",
    "test['context_0_VERB'] = test['pymorphy_context_0'].apply(lambda x: x['VERB'])\n",
    "test['context_0_ADVB'] = test['pymorphy_context_0'].apply(lambda x: x['ADVB'])\n",
    "test['context_0_PRTF'] = test['pymorphy_context_0'].apply(lambda x: x['PRTF'])\n",
    "test['context_0_NPRO'] = test['pymorphy_context_0'].apply(lambda x: x['NPRO'])\n",
    "test['context_0_NUMR'] = test['pymorphy_context_0'].apply(lambda x: x['NUMR'])\n",
    "test['context_0_GRND'] = test['pymorphy_context_0'].apply(lambda x: x['GRND'])\n",
    "test['context_0_NUMB'] = test['pymorphy_context_0'].apply(lambda x: x['NUMB'])\n",
    "test.drop('pymorphy_context_0' , axis=1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_columns = ['reply_NOUN', 'reply_ADJ', 'reply_VERB', 'reply_ADVB', 'reply_PRTF', 'reply_NPRO', 'reply_NUMR', 'reply_GRND', 'reply_NUMB',  \n",
    "               'context_0_NOUN', 'context_0_ADJ', 'context_0_VERB', 'context_0_ADVB', 'context_0_PRTF', 'context_0_NPRO', 'context_0_NUMR', 'context_0_GRND', 'context_0_NUMB']\n",
    "pos_train = train[pos_columns]\n",
    "pos_test = test[pos_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = train['context_0'].append(train['context_1']).append(train['context_2']).append(train['reply'])\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit(content)\n",
    "\n",
    "context_0 = vectorizer.transform(train['context_0'])\n",
    "context_0_t = vectorizer.transform(test['context_0'])\n",
    "\n",
    "context_1 = vectorizer.transform(train['context_1'])\n",
    "context_1_t = vectorizer.transform(test['context_1'])\n",
    "\n",
    "context_2 = vectorizer.transform(train['context_2'])\n",
    "context_2_t = vectorizer.transform(test['context_2'])\n",
    "\n",
    "reply = vectorizer.transform(train['reply'])\n",
    "reply_t = vectorizer.transform(test['reply'])\n",
    "\n",
    "X = sps.hstack((context_0, context_1, context_2, reply))\n",
    "X_test = sps.hstack((context_0_t, context_1_t, context_2_t, reply_t))\n",
    "\n",
    "# y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97533, 163732), (9968, 163732))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['rank'] = train['label'].apply(rank2num)\n",
    "# train['target'] = train['rank'] * train['confidence']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_label = {'bad': 0, 'neutral': 1, 'good': 2}\n",
    "\n",
    "train['label'] = train['label'].map(map_label)\n",
    "\n",
    "train['target'] = 0\n",
    "train.loc[train['label'] == 0, 'target'] = 1 - train.loc[train['label'] == 0, 'confidence']\n",
    "train.loc[train['label'] == 1, 'target'] = train.loc[train['label'] == 1, 'confidence']\n",
    "train.loc[train['label'] == 2, 'target'] = 2*train.loc[train['label'] == 2, 'confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(objective='rank:pairwise' , max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "svd = TruncatedSVD(120)\n",
    "X = sps.hstack((X, pos_train))\n",
    "X_transformed = svd.fit_transform(X)\n",
    "\n",
    "X_test = sps.hstack((X_test, pos_test))\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='rank:pairwise', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_transformed, train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = model.predict(X_test)\n",
    "sub = test.sort_values(by=['context_id', 'target'], \n",
    "                                  ascending=False)[['context_id', 'reply_id']]\n",
    "    \n",
    "sub.to_csv('xgboost.tsv' , sep='\\t' , header=False , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
