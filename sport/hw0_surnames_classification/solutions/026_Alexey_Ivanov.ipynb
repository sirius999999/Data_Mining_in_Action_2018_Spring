{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "from keras.initializers import he_uniform\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавление от повторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train['Word'] = df_train.Word.apply(str.lower)\n",
    "df_train = df_train.groupby('Word', group_keys=True).apply(lambda x: x.loc[x.Label.idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на train и val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_val = df_train.iloc[:int(len(df_train)*0.15)]\n",
    "df_train = df_train.iloc[int(len(df_train)*0.15):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((df_train, df_test))\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1, 4), lowercase=False)\n",
    "vectorizer.fit(df['Word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисления для downsample-инга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "df_train_label_1 = df_train[df_train.Label == 1]\n",
    "n = df_train_label_1.shape[0]\n",
    "m = vectorizer.transform(df_train_label_1.Word).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизация val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "X_val = vectorizer.transform(df_val['Word'])\n",
    "y_val = df_val['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура MLP (простая т.к. фичи разреженные и предположительно разбить их на 2 класса лучше более линейной гиперплосокстью)\n",
    "\n",
    "Далее на каждом j идет downsampling к классу 1 и дообучение MLP (ВАЖНО!!! требуется достаточное кол-во свободной оперативном памяти ~ 10ГБ)\n",
    "\n",
    "При падении AUR ROC SCORE остановка обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch = 0\n",
      "local epoch = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 118s 7ms/step - loss: 0.4963 - acc: 0.7915\n",
      "val score 0.8915326488767519\n",
      "local epoch = 1\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 116s 6ms/step - loss: 0.3454 - acc: 0.8605\n",
      "val score 0.904226138327357\n",
      "local epoch = 2\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 112s 6ms/step - loss: 0.2752 - acc: 0.8895\n",
      "val score 0.9079330250646143\n",
      "local epoch = 3\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 115s 6ms/step - loss: 0.2222 - acc: 0.9121\n",
      "val score 0.9062154121290898\n",
      "SCORE WAS DECEREASED!!!!\n"
     ]
    }
   ],
   "source": [
    "model_MLP = Sequential()\n",
    "model_MLP.add(Dense(10, input_dim=m, activation='relu', kernel_initializer='he_uniform'))\n",
    "model_MLP.add(Dense(1, activation='sigmoid'))\n",
    "model_MLP.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "for i in range(1):\n",
    "    prev_score = 0\n",
    "    print('global epoch =',i)\n",
    "    for j in range(9):\n",
    "        print('local epoch =',j)\n",
    "        if j < 8:\n",
    "            df_train_downsampled = pd.concat([df_train_label_1, df_train[df_train.Label == 0][j*n:j*n+n]], axis=0)\n",
    "            df_train_downsampled = df_train_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "            X_train = vectorizer.transform(df_train_downsampled['Word'])\n",
    "        else:\n",
    "            df_train_downsampled = pd.concat([df_train_label_1, df_train[df_train.Label == 0][j*n:]], axis=0)\n",
    "            df_train_downsampled = df_train_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "            X_train = vectorizer.transform(df_train_downsampled['Word'])\n",
    "        \n",
    "        X_train_mtx = X_train.todense()\n",
    "        X_val_mtx = X_val.todense()\n",
    "        \n",
    "        model_MLP.fit(X_train_mtx, df_train_downsampled.Label, batch_size=10, epochs=1)\n",
    "        del(X_train_mtx)\n",
    "        score = roc_auc_score(y_val, model_MLP.predict(X_val_mtx))\n",
    "        print(\"val score\", roc_auc_score(y_val, model_MLP.predict(X_val_mtx)))\n",
    "        if score > prev_score:\n",
    "            prev_score = score\n",
    "        else:\n",
    "            print(\"SCORE WAS DECEREASED!!!!\")\n",
    "            del(X_val_mtx)\n",
    "            break\n",
    "        del(X_val_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_downsampled = pd.concat([df_train_label_1, df_train[df_train.Label == 0][:n]], axis=0)\n",
    "df_train_downsampled = df_train_downsampled.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str1 = ''.join(str(e) for e in df.Word.tolist())\n",
    "spl = list(str1)\n",
    "dicti = np.unique(spl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Hot Encoding (OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(dicti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OHE для train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_LSTM = df_train.copy()\n",
    "df_train_LSTM.Word = df_train.Word.apply(list)\n",
    "df_train_LSTM.Word = df_train_LSTM.Word.apply(le.transform)\n",
    "df_train_LSTM.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перевод в матрицу с длиной фич до 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "X_tr_lstm = np.zeros((df_train_LSTM.shape[0], maxlen), dtype=int)\n",
    "for k in range(df_train_LSTM.shape[0]):\n",
    "    X_tr_lstm[k][:df_train_LSTM.Word[k].shape[0]] = df_train_LSTM.Word[k][:maxlen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже те же самые операции только для val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_val_LSTM = df_val.copy()\n",
    "df_val_LSTM.Word = df_val.Word.apply(list)\n",
    "df_val_LSTM.Word = df_val_LSTM.Word.apply(le.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "X_val_lstm = np.zeros((df_val_LSTM.shape[0], maxlen), dtype=int)\n",
    "for k in range(df_val_LSTM.shape[0]):\n",
    "    X_val_lstm[k][:df_val_LSTM.Word[k].shape[0]] = df_val_LSTM.Word[k][:maxlen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура LSTM (Была идея использовать BiLSTM, но руки не дошли)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_LSTM = Sequential()\n",
    "model_LSTM.add(Embedding(10000, output_dim=64, input_length=X_tr_lstm.shape[1]))\n",
    "model_LSTM.add(LSTM(32))\n",
    "model_LSTM.add(Dropout(0.5))\n",
    "model_LSTM.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_LSTM.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение LSTM (принцип обучения такой же как у MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global epoch = 0\n",
      "local epoch = 0\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 39s 2ms/step - loss: 0.5851\n",
      "val score = 0.8035865548746469\n",
      "local epoch = 1\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.5133\n",
      "val score = 0.8426463217731308\n",
      "local epoch = 2\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 35s 2ms/step - loss: 0.4912\n",
      "val score = 0.8481275804248107\n",
      "local epoch = 3\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 35s 2ms/step - loss: 0.4722\n",
      "val score = 0.8589451962253795\n",
      "local epoch = 4\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 35s 2ms/step - loss: 0.4664\n",
      "val score = 0.8637137279730868\n",
      "local epoch = 5\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.4556\n",
      "val score = 0.871856367787251\n",
      "local epoch = 6\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.4477\n",
      "val score = 0.8770611590838494\n",
      "local epoch = 7\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 37s 2ms/step - loss: 0.4427\n",
      "val score = 0.8790357306843234\n",
      "local epoch = 8\n",
      "Epoch 1/1\n",
      "13021/13021 [==============================] - 26s 2ms/step - loss: 0.3916\n",
      "val score = 0.8812702532246828\n",
      "global epoch = 1\n",
      "local epoch = 0\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.4398\n",
      "val score = 0.8852235903227849\n",
      "local epoch = 1\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 37s 2ms/step - loss: 0.4323\n",
      "val score = 0.8878256914558346\n",
      "local epoch = 2\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.4279\n",
      "val score = 0.8887248347321787\n",
      "local epoch = 3\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.4166\n",
      "val score = 0.8904631108576134\n",
      "local epoch = 4\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.4172\n",
      "val score = 0.8928354900959942\n",
      "local epoch = 5\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 36s 2ms/step - loss: 0.4095\n",
      "val score = 0.8924128960546831\n",
      "AUC SCORE DECREASED!!!\n",
      "global epoch = 2\n",
      "local epoch = 0\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 37s 2ms/step - loss: 0.4128\n",
      "val score = 0.8952287445752647\n",
      "local epoch = 1\n",
      "Epoch 1/1\n",
      "18140/18140 [==============================] - 37s 2ms/step - loss: 0.4067\n",
      "val score = 0.8934906569395898\n",
      "AUC SCORE DECREASED!!!\n"
     ]
    }
   ],
   "source": [
    "prev_score = 0\n",
    "for i in range(3):\n",
    "    is_break = False\n",
    "    print('global epoch =',i)\n",
    "    if not is_break:\n",
    "        for j in range(9):\n",
    "            print('local epoch =',j)\n",
    "            if j < 8:\n",
    "                df_train_downsampled = pd.concat([df_train_label_1, df_train[df_train.Label == 0][j*n:j*n+n]], axis=0)\n",
    "                df_train_downsampled = df_train_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "            else:\n",
    "                df_train_downsampled = pd.concat([df_train_label_1, df_train[df_train.Label == 0][j*n:]], axis=0)\n",
    "                df_train_downsampled = df_train_downsampled.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "            df_train_downsampled.Word = df_train_downsampled.Word.apply(list)\n",
    "            df_train_downsampled.Word = df_train_downsampled.Word.apply(le.transform)\n",
    "\n",
    "            maxlen = 20\n",
    "            X_tr_lstm = np.zeros((df_train_downsampled.shape[0], maxlen), dtype=int)\n",
    "            for k in range(X_tr_lstm.shape[0]):\n",
    "                X_tr_lstm[k][:df_train_downsampled.Word[k].shape[0]] = df_train_downsampled.Word[k][:maxlen]\n",
    "\n",
    "            model_LSTM.fit(X_tr_lstm, df_train_downsampled.Label, batch_size=32, epochs=1)\n",
    "            score = roc_auc_score(df_val.Label, model_LSTM.predict(X_val_lstm))\n",
    "            print(\"val score =\", score)\n",
    "            if score > prev_score:\n",
    "                prev_score = score\n",
    "            else:\n",
    "                print(\"AUC SCORE DECREASED!!!\")\n",
    "                is_break = True\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Предикт и сабмит**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_part1 = df_test.iloc[0:30000]\n",
    "df_test_part2 = df_test.iloc[30000:60000]\n",
    "df_test_part3 = df_test.iloc[60000:90000]\n",
    "df_test_part4 = df_test.iloc[90000:120000]\n",
    "df_test_part5 = df_test.iloc[120000:150000]\n",
    "df_test_part6 = df_test.iloc[150000:180000]\n",
    "df_test_part7 = df_test.iloc[180000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexey\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "test_part1_vec = vectorizer.transform(df_test_part1.Word)\n",
    "test_part2_vec = vectorizer.transform(df_test_part2.Word)\n",
    "test_part3_vec = vectorizer.transform(df_test_part3.Word)\n",
    "test_part4_vec = vectorizer.transform(df_test_part4.Word)\n",
    "test_part5_vec = vectorizer.transform(df_test_part5.Word)\n",
    "test_part6_vec = vectorizer.transform(df_test_part6.Word)\n",
    "test_part7_vec = vectorizer.transform(df_test_part7.Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP_pred = np.zeros((df_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО!!! требуется достаточное кол-во свободной оперативном памяти ~ 10ГБ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP_pred[0:30000] = model_MLP.predict(test_part1_vec.toarray())\n",
    "MLP_pred[30000:60000] = model_MLP.predict(test_part2_vec.toarray())\n",
    "MLP_pred[60000:90000] = model_MLP.predict(test_part3_vec.toarray())\n",
    "MLP_pred[90000:120000] = model_MLP.predict(test_part4_vec.toarray())\n",
    "MLP_pred[120000:150000] = model_MLP.predict(test_part5_vec.toarray())\n",
    "MLP_pred[150000:180000] = model_MLP.predict(test_part6_vec.toarray())\n",
    "MLP_pred[180000:] = model_MLP.predict(test_part7_vec.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже операции с OHE для test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_le = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_le.Word = df_test.Word.apply(list)\n",
    "df_test_le.Word = df_test_le.Word.apply(le.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_lstm = np.zeros((df_test.shape[0], maxlen), dtype=int)\n",
    "for i in range(X_test_lstm.shape[0]):\n",
    "    X_test_lstm[i][:df_test_le.Word[i].shape[0]] = df_test_le.Word[i][:maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_pred = model_LSTM.predict(X_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24718853454341877"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((MLP_pred + LSTM_pred)/2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21580755974812832"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27856952"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_pred.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднение предсказываения MLP и LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_subm = pd.read_csv('submission.csv', encoding='utf-8')\n",
    "df_subm.Prediction = (LSTM_pred + MLP_pred)/2\n",
    "df_subm.to_csv(\"submission.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
