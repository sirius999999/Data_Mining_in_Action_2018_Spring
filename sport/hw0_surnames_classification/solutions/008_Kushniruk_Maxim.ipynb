{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/maxim/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics, cross_validation, preprocessing, pipeline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier, Perceptron\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer ,normalize, scale,StandardScaler\n",
    "import pickle\n",
    "sns.set()\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import transliterate\n",
    " \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv', encoding=\"utf-8\")\n",
    "df_test=pd.read_csv('test.csv', encoding=\"utf-8\")\n",
    "\n",
    "combine = [df, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONS = u\"бвгджзклмнпрстфхцчшщ\"\n",
    "VOV = u\"аеёиоуыэюя\"\n",
    "\n",
    "\n",
    "for dataset in combine:\n",
    "    #dataset.Word.apply(str)\n",
    "    duplicates = np.array(dataset[dataset.duplicated('Word')].Word)\n",
    "    duplicates_index=dataset[dataset.duplicated('Word') ].index.tolist() \n",
    "    \n",
    "    dataset['index_ind'] =  dataset.index.tolist() \n",
    "    dataset['istitle'] =  dataset.Word.apply(lambda x: 1  if x.istitle()  else 0  )\n",
    "    dataset['isupper'] =  dataset.Word.apply(lambda x: 1  if x.isupper()  else 0  )\n",
    "    dataset['isalpha'] =  dataset.Word.apply(lambda x: 1  if x.isalpha()  else 0  )\n",
    "    dataset['len']= dataset.Word.apply(lambda x: len(x) )\n",
    "    #dataset['len_other']= dataset.Word.apply(lambda x: 1 if len(x)>=2 and len(x)<=11  else 0  )\n",
    "    dataset['len_other']= dataset.Word.apply(lambda x: 1  )\n",
    "    dataset['CONS_count'] = dataset.Word.apply(lambda x: 0 )\n",
    "    #dataset['CONS_count'] = dataset.Word.apply(lambda x: len([char for char in x.lower() if char in CONS ]))\n",
    "    dataset['VOV_count'] = dataset.Word.apply(lambda x: len([char for char in x.lower() if char in VOV ]))\n",
    "    dataset['last_3'] =  dataset.Word.apply(lambda x:  x[-3:])\n",
    "   # dataset['natasha_person'] =  dataset.Word.apply(function_natasha)\n",
    "    \n",
    "    dataset['duplicates'] = dataset.Word.apply(lambda x: 1 if x in duplicates else 0 )\n",
    "    dataset['duplicates_ind'] =  dataset.index_ind.apply(lambda x:  1 if x in duplicates_index else 0)\n",
    "    \n",
    "\n",
    "    \n",
    "train_col=['Word','last_3',  'VOV_count','CONS_count','len','isalpha','isupper','istitle','len_other']  \n",
    "\n",
    "\n",
    "  \n",
    "# ['duplicates_ind','duplicates','VOV_count','CONS_count','len_other','len','isalpha','isupper','istitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False False False False False]\n",
      "[False  True False False False False False False False]\n",
      "[False False  True  True  True False False False False]\n",
      "[False False False False False  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "cat_col1=['Word']\n",
    "global categorical_data_indices1\n",
    "categorical_data_indices1 = np.array([(column in cat_col1) for column in df[train_col].columns], dtype = bool)\n",
    "print (categorical_data_indices1)\n",
    "\n",
    "cat_col2=['last_3']\n",
    "global categorical_data_indices2\n",
    "categorical_data_indices2 = np.array([(column in cat_col2) for column in df[train_col].columns], dtype = bool)\n",
    "print (categorical_data_indices2)\n",
    "\n",
    "float_col=['len','CONS_count','VOV_count']\n",
    "global numeric_data_indices\n",
    "numeric_data_indices = np.array([(column in float_col) for column in df[train_col].columns], dtype = bool)\n",
    "print (numeric_data_indices)\n",
    "\n",
    "global binary_data_indices \n",
    "binary_data_indices = np.array([(column not in float_col and column not in cat_col1 and column not in cat_col2) for column in df[train_col].columns], dtype = bool)\n",
    "print (binary_data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnExtractor_1st(object):\n",
    "    \n",
    "  #  def __init__(self, key):\n",
    "   #     self.key = key\n",
    "\n",
    "    def transform(self, X):\n",
    "        cols = X[:,0] # column 1st column\n",
    "        return cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "class ColumnExtractor_2st(object):\n",
    "    \n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        cols = X[:,1] # column 2nd column\n",
    "        return cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "class ColumnExtractor_3st(object):\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        cols = X[:,2:5] # column  continous \n",
    "        return cols.astype(float)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "class ColumnExtractor_4st(object):\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        cols = X[:,5:] # column  continous \n",
    "        return cols.astype(float)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MyPipe_v4(model):\n",
    "    pipe = pipeline.Pipeline([\n",
    "                         ('features', FeatureUnion([\n",
    "                             ('word_CountVectorizer', pipeline.Pipeline([\n",
    "                                 #('selecting', FunctionTransformer(lambda data: data[:, categorical_data_indices1])) ,\n",
    "                           \n",
    "                                 ('reduce_dim', ColumnExtractor_1st()),\n",
    "                                 ('vect', CountVectorizer(ngram_range=(2,7), analyzer='char',lowercase=False)),\n",
    "                                # ('TfidfTransformer',TfidfTransformer()),\n",
    "                                 #('scl', scaler),\n",
    "                                \n",
    "                                 \n",
    "                                 \n",
    "                                 \n",
    "                                 ])),\n",
    "                            ('last_3_CountVectorizer', pipeline.Pipeline([\n",
    "                                ('reduce_dim', ColumnExtractor_2st()),\n",
    "                                ('vect', CountVectorizer(ngram_range=(2,3), analyzer='char',lowercase=False)),\n",
    "                            ##     ('TfidfTransformer',TfidfTransformer()),\n",
    "                                #('scl', scaler),\n",
    "            \n",
    "                                ])),\n",
    "                             \n",
    "                            ('continuous', pipeline.Pipeline([\n",
    "                                  ('reduce_dim', ColumnExtractor_3st()),\n",
    "                                  ('scaling', MaxAbsScaler())\n",
    "                             ])),\n",
    "                             ('binury', pipeline.Pipeline([\n",
    "                                  ('reduce_dim', ColumnExtractor_4st()),\n",
    "                                \n",
    "                             ])),\n",
    "                            \n",
    "                        \n",
    "                           \n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                             \n",
    "                             \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                         \n",
    "                              ])),\n",
    "                              \n",
    "                              \n",
    "                              ('clf', model)\n",
    "                            ])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valuesROC-AUC (LR): 0.931015713067/0.00150023424529\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(df[df.duplicates==0].Label, n_folds=5, shuffle=True)\n",
    "train_col=['Word','last_3',  'VOV_count','CONS_count','len','isalpha','isupper','istitle','len_other']\n",
    "\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(penalty='l2', n_jobs=4, random_state=42,\n",
    "                             class_weight='balanced',\n",
    "                             C = 0.1, max_iter=50, solver='sag')\n",
    "\n",
    "\n",
    "my_pipe_log=MyPipe_v4(log_reg)\n",
    "\n",
    "\n",
    "score_log=cross_val_score(my_pipe_log, np.array(df[df.duplicates==0][train_col]), df[df.duplicates==0].Label, cv=cv, scoring='roc_auc')\n",
    "print(\"valuesROC-AUC (LR): {}/{}\".format(score_log.mean(), score_log.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (LR): 0.932636098363/0.00220553953636\n",
      "0.932636098363 0.00220553953636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(df[df.duplicates==0].Label, n_folds=5, shuffle=True)\n",
    "train_col=['Word','last_3',  'VOV_count','CONS_count','len','isalpha','isupper','istitle','len_other']\n",
    "\n",
    "svm_sgd=SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3, n_iter=200, random_state=42, \n",
    "                      n_jobs=4, class_weight='balanced')\n",
    "\n",
    "sgd_pipe=MyPipe_v4(svm_sgd)\n",
    "\n",
    "\n",
    "score_svm_sgd=cross_val_score(sgd_pipe,np.array(df[df.duplicates==0][train_col]), df[df.duplicates==0].Label, cv=cv, n_jobs=4, scoring='roc_auc')\n",
    "print(\"ROC-AUC (LR): {}/{}\".format(score_svm_sgd.mean(), score_svm_sgd.std()))\n",
    "print score_svm_sgd.mean() , score_svm_sgd.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (LR): 0.93173131076/0.00332688209995 log l2 0.0001 100\n",
      "ROC-AUC (LR): 0.933008103489/0.00288496463752 log l2 1e-05 100\n",
      "ROC-AUC (LR): 0.917277988436/0.00428209187709 log l2 0.001 100\n",
      "ROC-AUC (LR): 0.931715460078/0.00331303769308 log l2 0.0001 200\n",
      "ROC-AUC (LR): 0.933152480475/0.00293851682033 log l2 1e-05 200\n",
      "ROC-AUC (LR): 0.917262022596/0.00428199273337 log l2 0.001 200\n",
      "ROC-AUC (LR): 0.931712082298/0.00332313049129 log l2 0.0001 300\n",
      "ROC-AUC (LR): 0.933222722717/0.00294992605696 log l2 1e-05 300\n",
      "ROC-AUC (LR): 0.917255592707/0.00428218628049 log l2 0.001 300\n",
      "ROC-AUC (LR): 0.931709342456/0.00331837682179 log l2 0.0001 400\n",
      "ROC-AUC (LR): 0.933225250152/0.00295598915346 log l2 1e-05 400\n",
      "ROC-AUC (LR): 0.917253548041/0.00428334223714 log l2 0.001 400\n"
     ]
    }
   ],
   "source": [
    "for clf__n_iter in  range(100,500,100):\n",
    "    for clf__alpha in [1e-4, 1e-5, 1e-3]:\n",
    "        for clf__penalty in [ \"l2\"]:\n",
    "            for clf_loss in ['log']:\n",
    "                svm_sgd=SGDClassifier(loss=clf_loss, penalty=clf__penalty, alpha=clf__alpha, n_iter=clf__n_iter, random_state=42, \n",
    "                      n_jobs=4, class_weight='balanced')\n",
    "                sgd_pipe=MyPipe_v4(svm_sgd)\n",
    "                score_svm_sgd=cross_val_score(sgd_pipe,np.array(df[df.duplicates==0][train_col]), df[df.duplicates==0].Label, cv=cv, n_jobs=4, scoring='roc_auc')\n",
    "                print(\"ROC-AUC (LR): {}/{}\".format(score_svm_sgd.mean(), score_svm_sgd.std())) ,clf_loss,clf__penalty,clf__alpha,clf__n_iter\n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv = StratifiedKFold(df[df.duplicates==0].Label, n_folds=5, shuffle=True)\n",
    "train_col=['Word','last_3',  'VOV_count','CONS_count','len','isalpha','isupper','istitle','len_other']\n",
    "\n",
    "svm_sgd=SGDClassifier(loss='log', penalty='l2', alpha=1e-5, n_iter=300, random_state=42, \n",
    "                      n_jobs=4, class_weight='balanced')\n",
    "\n",
    "sgd_pipe=MyPipe_v4(svm_sgd)\n",
    "\n",
    "sgd_pipe.fit(np.array(df[df.duplicates==0][train_col]), df[df.duplicates==0].Label)\n",
    "sgd_pred=sgd_pipe.predict_proba(np.array(df_test[train_col]))[:,1]\n",
    "df_test['pred1']=sgd_pred\n",
    "\n",
    "df_test.pred1[(df_test.duplicates==1) & (df_test.duplicates_ind==1) ]=1\n",
    "df_test.pred1[(df_test.duplicates==1) & (df_test.duplicates_ind==0) ]=0\n",
    "\n",
    "#score_svm_sgd=cross_val_score(sgd_pipe,np.array(df[df.duplicates==0][train_col]), df[df.duplicates==0].Label, cv=cv, n_jobs=4, scoring='roc_auc')\n",
    "#print(\"ROC-AUC (LR): {}/{}\".format(score_svm_sgd.mean(), score_svm_sgd.std()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['db']= df_test.Word.apply(lambda x: 1  if x in  df.Word.values  else 0  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_1=df_test.merge(df[['Word','Label']],on='Word', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test_1.pred1[df_test_1.Label==0]=1\n",
    "df_test_1.pred1[df_test_1.Label==1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds=pd.DataFrame({'Id':range(len(df_test)),'Prediction': df_test_1.pred1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.to_csv('hw0_v2.csv', sep=',',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faac04b5350>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAECCAYAAAAB2kexAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkH+H5jOU6bLRT1+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faac04bf790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df.duplicates==1].pivot_table('Word','duplicates_ind','Label','count').plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
