{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "## Features:\n",
    "### кол-во гласных\n",
    "### кол-во согласных \n",
    "### признак принимающий значения 0,1,2 в зависимости от того написано слово капсом, маленькими буквами или с заглавной\n",
    "### частота встречи последних 3х букв(окончение слова) в фамилии\n",
    "### частота встречи последних 3х букв(окончание слова) в нефамилии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data_train = pd.read_csv('train.csv')\n",
    "#data_test = pd.read_csv('test.csv')\n",
    "\n",
    "surnames = data_train[data_train.Label == 1].drop(['Label'], axis=1)\n",
    "words = data_train[data_train.Label == 0].drop(['Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel = 'уеёыаоэяию'\n",
    "consonant = 'йцкнгшщзхъфвпрлджчсмтьб'\n",
    "\n",
    "def count_vow(word):\n",
    "    vow = 0\n",
    "    for i in str(word).lower():\n",
    "        if i in vowel:\n",
    "            vow += 1\n",
    "    return vow\n",
    "\n",
    "def count_con(word):\n",
    "    cons = 0\n",
    "    for i in str(word).lower():\n",
    "        if i in consonant:\n",
    "            cons += 1\n",
    "    return cons\n",
    "\n",
    "def upper_lower_case(df):\n",
    "    feature = []\n",
    "    for word in df.Word:\n",
    "        if str(word).islower():\n",
    "            feature.append(0)\n",
    "        elif str(word).isupper():\n",
    "            feature.append(1)\n",
    "        else:\n",
    "            feature.append(2)\n",
    "    return feature  \n",
    "\n",
    "def word_format(df):\n",
    "    df['Letter_size'] = upper_lower_case(df)\n",
    "    return df\n",
    "\n",
    "def word_vowels_cons(df):\n",
    "    df['Vowel_count'] = df.Word.apply(lambda x: count_vow(x))\n",
    "    df['Consonant_count'] = df.Word.apply(lambda x: count_con(x))\n",
    "    return df\n",
    "\n",
    "def ending_extract(x):\n",
    "    if len(x) > 2:\n",
    "        return str((x[-3] + x[-2] + x[-1])).lower()\n",
    "    if len(x) > 1:\n",
    "        return str(x[-2] + x[-1]).lower()\n",
    "    else:\n",
    "        return str(x[-1]).lower()\n",
    "\n",
    "def ending_surname_freq_extract(x):\n",
    "    return endings_surname_freq.get(ending_extract(x), 0)\n",
    "\n",
    "def ending_word_freq_extract(x):\n",
    "    return endings_word_freq.get(ending_extract(x), 0)\n",
    "    \n",
    "def word_ending_freq(df):\n",
    "    df['Surname_ending_freq'] = df.Word.apply(lambda x: ending_surname_freq_extract(x))\n",
    "    df['Word_ending_freq'] = df.Word.apply(lambda x: ending_word_freq_extract(x))\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    return df.drop(['Word'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = word_format(df)\n",
    "    df = word_vowels_cons(df)\n",
    "    df = word_ending_freq(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "endings_sur_list = []\n",
    "[endings_sur_list.append(ending_extract(word)) for word in surnames.Word]\n",
    "endings_surname_freq = Counter(endings_sur_list)\n",
    "\n",
    "endings_word_list = []\n",
    "[endings_word_list.append(ending_extract(word)) for word in words.Word]\n",
    "endings_word_freq = Counter(endings_word_list)\n",
    "\n",
    "data_train = transform_features(data_train)\n",
    "#data_test = transform_features(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91732123211659633"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = data_train.drop(['Label'], axis=1)\n",
    "y_all = data_train['Label']\n",
    "print(X_all)\n",
    "X_all['Letter_size'] = X_all['Letter_size'].astype(str) \n",
    "X_all = pd.get_dummies(X_all, columns=['Letter_size']) \n",
    "print(X_all)\n",
    "num_test = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=55)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "predictions = knn.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucky\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.9128162685509515\n",
      "Fold 2 accuracy: 0.9248060133565259\n",
      "Fold 3 accuracy: 0.9122564841294727\n",
      "Fold 4 accuracy: 0.9187556358076213\n",
      "Fold 5 accuracy: 0.899155628493313\n",
      "Fold 6 accuracy: 0.9078610234517592\n",
      "Fold 7 accuracy: 0.8601110865636807\n",
      "Fold 8 accuracy: 0.9040434758812292\n",
      "Fold 9 accuracy: 0.9114323572357947\n",
      "Fold 10 accuracy: 0.9088748693588734\n",
      "Mean Accuracy: 0.9060112842829222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from numpy import mean\n",
    "\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(101408, n_folds=10)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict_proba(X_test)[:,1]\n",
    "        accuracy = roc_auc_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))\n",
    "    mean_outcome = mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome))\n",
    "\n",
    "run_kfold(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
