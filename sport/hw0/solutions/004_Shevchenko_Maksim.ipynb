{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение соревнования по классификации фамилий на 4 место\n",
    "\n",
    "https://www.kaggle.com/c/dmia-surnames-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101408, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалтонен</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Аар</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аарон</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ААРОН</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарона</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Label\n",
       "0  Аалтонен      1\n",
       "1       Аар      0\n",
       "2     Аарон      0\n",
       "3     ААРОН      0\n",
       "4    Аарона      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101408, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалто</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ААР</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аара</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ааре</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарон</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word\n",
       "0  Аалто\n",
       "1    ААР\n",
       "2   Аара\n",
       "3   Ааре\n",
       "4  Аарон"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как pymorphy может возвращать несколько значений к одному слову, то было принято решение кодировать признаки (часть речи, род и число) суммарными score каждого возвращаемого слова.\n",
    "\n",
    "Кроме того, на семинаре была предложена отличная идея для признака: на предобученной модели w2v оценивать близость вектора каждого слова выборки с вектором слова __\"Фамилия\"__.\n",
    "\n",
    "Функция *pymorhy_features* возвращает эти признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymorhy_features(word, py_morphy_analyzer, gensim_w2v):\n",
    "    \n",
    "    # Часть речи\n",
    "    noun = 0\n",
    "    verb = 0\n",
    "    adjf = 0\n",
    "\n",
    "    # Род\n",
    "    masc = 0\n",
    "    femn = 0\n",
    "    neut = 0\n",
    "\n",
    "    # Число\n",
    "    sing = 0\n",
    "    plur = 0\n",
    "\n",
    "    # Фамилия\n",
    "    pymorphy = 0\n",
    "    \n",
    "    pymorphy_parse = py_morphy_analyzer.parse(word)\n",
    "    \n",
    "    pymorphy_values = len(pymorphy_parse)\n",
    "    normal_form = pymorphy_parse[0].normal_form\n",
    "    \n",
    "    w2v_surname = 0\n",
    "    if pymorphy_parse[0].tag.POS is not None:\n",
    "        w2v_word = word.lower() + '_' + pymorphy_parse[0].tag.POS\n",
    "        try: w2v_surname = model.similarity('фамилия_NOUN', w2v_word)\n",
    "        except: pass\n",
    "    \n",
    "    for p in pymorphy_parse:\n",
    "\n",
    "        pos = p.tag.POS\n",
    "        if pos == 'NOUN': noun += p.score\n",
    "        elif pos in ('VERB', 'INFN', 'GRND'): verb += p.score\n",
    "        elif pos in ('ADJF', 'ADJS', 'PRTF', 'PRTS'): adjf += p.score\n",
    "\n",
    "        gender = p.tag.gender\n",
    "        if gender == 'masc': masc += p.score\n",
    "        elif gender == 'femn': femn += p.score\n",
    "        elif gender == 'neut': neut += p.score\n",
    "\n",
    "        number = p.tag.number\n",
    "        if number == 'sing': sing += p.score\n",
    "        elif number == 'plur': plur += p.score\n",
    "\n",
    "        if 'Surn' in p.tag: pymorphy = 1\n",
    "            \n",
    "    return w2v_surname, noun, verb, adjf, masc, femn, neut, sing, plur, pymorphy, pymorphy_values, normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mystem - библиотека, реализующая функционал аналогичный pymorphy, поэтому с помощью нее проверялось является ли слово фамилией или нет. Как правило, в большинстве моделей данный признак был незначимый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mystem_features(word, mystem_analyzer):\n",
    "    try: \n",
    "        return int('фам' in mystem_analyzeranalyze(word)[0]['analysis'][0]['gr'].split(','))\n",
    "    except: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная функция подготовки признаков. \n",
    "\n",
    "Идея с шипящими, свистящими звонкими и глухими была честно подсмотрена [в бейзлайне](http://nbviewer.jupyter.org/urls/kaggle2.blob.core.windows.net/forum-message-attachments/285519/8604/Baseline_SGD_ngrams%26wordfeatures.ipynb) любезно предоставленным [Nikk Reppin](https://www.kaggle.com/nikrepp)\n",
    "\n",
    "Идея с категориальным признаком \"2end\" также была подсмотрена у Mikhail Solomennik [в этом бенчмарке](https://github.com/solomennikm/notes/blob/master/Easy_catboost_starter.ipynb). На основе нее было принято решение использовать Catboost с двумя категориальными фичами, который поднял мой скор примерно на 0,02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from natasha import NamesExtractor\n",
    "import pymorphy2\n",
    "from pymystem3 import Mystem\n",
    "import pyphen\n",
    "\n",
    "def prepare_dataset(df, gensim_w2v, verbose=True):\n",
    "    \n",
    "    print('Prepare features based on word...')\n",
    "    vowels = set('аоиеёэыуюя')\n",
    "    consonant = set('бвгджзйклмнпрстфхцчшщ')\n",
    "    \n",
    "    df.loc[:, 'word'] = df['Word'].apply(lambda x: ''.join(filter(None, re.split('\\W', x))))\n",
    "    \n",
    "    df.loc[:, 'len'] = df['Word'].apply(len)\n",
    "    df.loc[:, 'len_word'] = df['word'].apply(len)\n",
    "    \n",
    "    df.loc[:, 'vowels'] = df['word'].apply(lambda word: sum(letter in vowels for letter in word.lower()))\n",
    "    df.loc[:, 'consonant'] = df['word'].apply(lambda word: sum(letter in consonant for letter in word.lower()))\n",
    "    \n",
    "    df.loc[:, 'ship'] = df['word'].apply(lambda word: sum(letter in set('жчшщ') for letter in word.lower()))\n",
    "    df.loc[:, 'swist'] = df['word'].apply(lambda word: sum(letter in set('цзс') for letter in word.lower()))\n",
    "    \n",
    "    df.loc[:, 'zvon_parn'] = df['word'].apply(lambda word: sum(letter in set('бвгджз') for letter in word.lower()))\n",
    "    df.loc[:, 'glukh_parn'] = df['word'].apply(lambda word: sum(letter in set('пфктшс') for letter in word.lower()))\n",
    "    df.loc[:, 'zvon_neparn'] = df['word'].apply(lambda word: sum(letter in set('лмнрй') for letter in word.lower()))\n",
    "    df.loc[:, 'glukh_neparn'] = df['word'].apply(lambda word: sum(letter in set('хцчщ') for letter in word.lower()))\n",
    "    \n",
    "    df.loc[:, 'capitals'] = df['Word'].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "    \n",
    "    df.loc[:, 'ratio_vowels'] = df['vowels'] / df['len_word']\n",
    "    df.loc[:, 'ratio_consonant'] = df['consonant'] / df['len_word']\n",
    "    df.loc[:, 'ratio_capitals'] = df['capitals'] / df['len_word']\n",
    "    \n",
    "    df.loc[:, 'istitle'] = df['Word'].apply(lambda x: 1 if x.istitle() else 0)\n",
    "    \n",
    "    df.loc[:, 'cyrillic'] = df['word'].apply(\n",
    "        lambda word: int(sum(letter in vowels.union(consonant) for letter in word.lower()) == len(word))\n",
    "    )\n",
    "    \n",
    "    # pymorphy2\n",
    "    print('Prepare features based on pymorphy2...')\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    df.loc[:, 'w2v_surname'], \\\n",
    "    df.loc[:, 'noun'], df.loc[:, 'verb'], df.loc[:, 'adjf'], df.loc[:, 'masc'], \\\n",
    "    df.loc[:, 'femn'], df.loc[:, 'neut'], df.loc[:, 'sing'], df.loc[:, 'plur'], \\\n",
    "    df.loc[:, 'pymorphy'], df.loc[:, 'pymorphy_values'], df.loc[:, 'normal_form'] \\\n",
    "        = zip(*df['Word'].apply(lambda x: pymorhy_features(x, morph, gensim_w2v)))\n",
    "    \n",
    "    # pymystem3\n",
    "    print('Prepare features based on pymystem3...')\n",
    "    m = Mystem()\n",
    "    \n",
    "    df.loc[:, 'mystem'] = df.loc[:, 'word'].apply(lambda word: mystem_features(word, m))\n",
    "    \n",
    "    # Natasha\n",
    "    print('Prepare features based on Natasha...')\n",
    "    extractor = NamesExtractor()\n",
    "\n",
    "    df.loc[:, 'Natasha'] = df['word'].apply(lambda x: 0 if len(list(extractor(x.capitalize()))) == 0 else 1)\n",
    "    \n",
    "    df.loc[:, '2end'] = df['Word'].str[-2:].str.lower()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим [предобученную модель W2V](http://rusvectores.org/ru/models/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load_word2vec_format('./ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим train, добавив признак \"кол-во слов с аналогичной начальной формой слова\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare features based on word...\n",
      "Prepare features based on pymorphy2...\n",
      "Prepare features based on pymystem3...\n",
      "Prepare features based on Natasha...\n",
      "CPU times: user 2min 38s, sys: 2.49 s, total: 2min 41s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = prepare_dataset(train, model)\n",
    "\n",
    "train = train.merge(\n",
    "    train.groupby('normal_form', as_index=False).count()[['normal_form', 'Word']]\\\n",
    "        .rename(columns={'Word': 'count_normal'}),\n",
    "    how='left',\n",
    "    on='normal_form')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/processed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично подготовим test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare features based on word...\n",
      "Prepare features based on pymorphy2...\n",
      "Prepare features based on pymystem3...\n",
      "Prepare features based on Natasha...\n",
      "CPU times: user 4min 55s, sys: 3.6 s, total: 4min 59s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = prepare_dataset(test, model)\n",
    "\n",
    "test = test.merge(\n",
    "    train.groupby('normal_form', as_index=False).count()[['normal_form', 'Word']]\\\n",
    "        .rename(columns={'Word': 'count_normal'}),\n",
    "    how='left',\n",
    "    on='normal_form').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./data/processed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Локальная валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train.drop(['Label', 'word', 'Word'], axis=1), train['Label'].values.flatten(), \n",
    "    test_size=0.2, stratify=train['Label'], random_state=777\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим категориальные признаки для catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['plur', 'normal_form'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = np.where(X_train.dtypes == 'object')[0].tolist()\n",
    "train.columns[cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9133941\ttotal: 95.1ms\tremaining: 3m 10s\n",
      "100:\tlearn: 0.9514141\ttotal: 10.8s\tremaining: 3m 22s\n",
      "200:\tlearn: 0.9589788\ttotal: 21.5s\tremaining: 3m 12s\n",
      "300:\tlearn: 0.9615960\ttotal: 31.6s\tremaining: 2m 58s\n",
      "400:\tlearn: 0.9632501\ttotal: 41.3s\tremaining: 2m 44s\n",
      "500:\tlearn: 0.9643556\ttotal: 51.1s\tremaining: 2m 32s\n",
      "600:\tlearn: 0.9652963\ttotal: 1m 1s\tremaining: 2m 22s\n",
      "700:\tlearn: 0.9661202\ttotal: 1m 10s\tremaining: 2m 11s\n",
      "800:\tlearn: 0.9669694\ttotal: 1m 20s\tremaining: 2m\n",
      "900:\tlearn: 0.9677741\ttotal: 1m 30s\tremaining: 1m 50s\n",
      "1000:\tlearn: 0.9685043\ttotal: 1m 40s\tremaining: 1m 40s\n",
      "1100:\tlearn: 0.9692169\ttotal: 1m 50s\tremaining: 1m 30s\n",
      "1200:\tlearn: 0.9698792\ttotal: 1m 59s\tremaining: 1m 19s\n",
      "1300:\tlearn: 0.9704543\ttotal: 2m 9s\tremaining: 1m 9s\n",
      "1400:\tlearn: 0.9710583\ttotal: 2m 19s\tremaining: 59.5s\n",
      "1500:\tlearn: 0.9716391\ttotal: 2m 29s\tremaining: 49.6s\n",
      "1600:\tlearn: 0.9721533\ttotal: 2m 38s\tremaining: 39.6s\n",
      "1700:\tlearn: 0.9725818\ttotal: 2m 48s\tremaining: 29.6s\n",
      "1800:\tlearn: 0.9731964\ttotal: 2m 58s\tremaining: 19.7s\n",
      "1900:\tlearn: 0.9737285\ttotal: 3m 7s\tremaining: 9.79s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x10fcb24e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "ctb = CatBoostClassifier(eval_metric='AUC', random_seed=777, iterations=2000, metric_period=100)\n",
    "ctb.fit(X_train, y_train, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим качество на отложенной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9726341794016273"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_val, ctb.predict_proba(X_val)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим важность признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ratio_capitals</td>\n",
       "      <td>22.846306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w2v_surname</td>\n",
       "      <td>13.039769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>count_normal</td>\n",
       "      <td>10.223563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>istitle</td>\n",
       "      <td>8.410677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>normal_form</td>\n",
       "      <td>8.271064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2end</td>\n",
       "      <td>7.239061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>capitals</td>\n",
       "      <td>6.242655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vowels</td>\n",
       "      <td>3.682739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pymorphy</td>\n",
       "      <td>3.681037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pymorphy_values</td>\n",
       "      <td>2.604975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>1.968947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noun</td>\n",
       "      <td>1.903416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>masc</td>\n",
       "      <td>1.369228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ratio_consonant</td>\n",
       "      <td>0.888720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>neut</td>\n",
       "      <td>0.872376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>len</td>\n",
       "      <td>0.809340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ratio_vowels</td>\n",
       "      <td>0.779750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>swist</td>\n",
       "      <td>0.768476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sing</td>\n",
       "      <td>0.688127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>femn</td>\n",
       "      <td>0.686240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>consonant</td>\n",
       "      <td>0.499273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>adjf</td>\n",
       "      <td>0.462888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>plur</td>\n",
       "      <td>0.424329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>glukh_parn</td>\n",
       "      <td>0.395195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>verb</td>\n",
       "      <td>0.364565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>len_word</td>\n",
       "      <td>0.288086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ship</td>\n",
       "      <td>0.248659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zvon_neparn</td>\n",
       "      <td>0.136174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>glukh_neparn</td>\n",
       "      <td>0.087489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zvon_parn</td>\n",
       "      <td>0.082415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cyrillic</td>\n",
       "      <td>0.034463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mystem</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           features     fscore\n",
       "13   ratio_capitals  22.846306\n",
       "16      w2v_surname  13.039769\n",
       "31     count_normal  10.223563\n",
       "14          istitle   8.410677\n",
       "27      normal_form   8.271064\n",
       "30             2end   7.239061\n",
       "10         capitals   6.242655\n",
       "2            vowels   3.682739\n",
       "25         pymorphy   3.681037\n",
       "26  pymorphy_values   2.604975\n",
       "29          Natasha   1.968947\n",
       "17             noun   1.903416\n",
       "20             masc   1.369228\n",
       "12  ratio_consonant   0.888720\n",
       "22             neut   0.872376\n",
       "0               len   0.809340\n",
       "11     ratio_vowels   0.779750\n",
       "5             swist   0.768476\n",
       "23             sing   0.688127\n",
       "21             femn   0.686240\n",
       "3         consonant   0.499273\n",
       "19             adjf   0.462888\n",
       "24             plur   0.424329\n",
       "7        glukh_parn   0.395195\n",
       "18             verb   0.364565\n",
       "1          len_word   0.288086\n",
       "4              ship   0.248659\n",
       "8       zvon_neparn   0.136174\n",
       "9      glukh_neparn   0.087489\n",
       "6         zvon_parn   0.082415\n",
       "15         cyrillic   0.034463\n",
       "28           mystem   0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame(\n",
    "    data={\n",
    "        'features': X_train.columns,\n",
    "        'fscore': ctb.feature_importances_\n",
    "    }\n",
    ")\n",
    "importances = importances.reindex(importances.fscore.abs().sort_values(ascending=False).index)\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9098501\ttotal: 119ms\tremaining: 3m 57s\n",
      "100:\tlearn: 0.9572516\ttotal: 11.6s\tremaining: 3m 37s\n",
      "200:\tlearn: 0.9626323\ttotal: 23.8s\tremaining: 3m 33s\n",
      "300:\tlearn: 0.9652306\ttotal: 35.9s\tremaining: 3m 22s\n",
      "400:\tlearn: 0.9664383\ttotal: 47.9s\tremaining: 3m 11s\n",
      "500:\tlearn: 0.9674953\ttotal: 1m\tremaining: 3m\n",
      "600:\tlearn: 0.9683387\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "700:\tlearn: 0.9691390\ttotal: 1m 24s\tremaining: 2m 36s\n",
      "800:\tlearn: 0.9699549\ttotal: 1m 36s\tremaining: 2m 24s\n",
      "900:\tlearn: 0.9705615\ttotal: 1m 48s\tremaining: 2m 12s\n",
      "1000:\tlearn: 0.9712139\ttotal: 2m 1s\tremaining: 2m 1s\n",
      "1100:\tlearn: 0.9718591\ttotal: 2m 13s\tremaining: 1m 48s\n",
      "1200:\tlearn: 0.9724258\ttotal: 2m 25s\tremaining: 1m 36s\n",
      "1300:\tlearn: 0.9729738\ttotal: 2m 38s\tremaining: 1m 24s\n",
      "1400:\tlearn: 0.9734288\ttotal: 2m 50s\tremaining: 1m 12s\n",
      "1500:\tlearn: 0.9738434\ttotal: 3m 2s\tremaining: 1m\n",
      "1600:\tlearn: 0.9741983\ttotal: 3m 14s\tremaining: 48.6s\n",
      "1700:\tlearn: 0.9746036\ttotal: 3m 27s\tremaining: 36.4s\n",
      "1800:\tlearn: 0.9750934\ttotal: 3m 39s\tremaining: 24.3s\n",
      "1900:\tlearn: 0.9754526\ttotal: 3m 52s\tremaining: 12.1s\n",
      "CPU times: user 11min 10s, sys: 47.3 s, total: 11min 58s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat_features = np.where(\n",
    "    train.drop(['Word', 'word', 'Label'], axis=1).dtypes == 'object'\n",
    ")[0].tolist()\n",
    "\n",
    "ctb = CatBoostClassifier(eval_metric='AUC', random_seed=777, iterations=2000, metric_period=100)\\\n",
    "    .fit(train.drop(['Word', 'word', 'Label'], axis=1), \n",
    "         train['Label'], \n",
    "         cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Word</th>\n",
       "      <th>word</th>\n",
       "      <th>len</th>\n",
       "      <th>len_word</th>\n",
       "      <th>vowels</th>\n",
       "      <th>consonant</th>\n",
       "      <th>ship</th>\n",
       "      <th>swist</th>\n",
       "      <th>zvon_parn</th>\n",
       "      <th>...</th>\n",
       "      <th>sing</th>\n",
       "      <th>plur</th>\n",
       "      <th>pymorphy</th>\n",
       "      <th>pymorphy_values</th>\n",
       "      <th>normal_form</th>\n",
       "      <th>mystem</th>\n",
       "      <th>Natasha</th>\n",
       "      <th>2end</th>\n",
       "      <th>count_normal</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Аалто</td>\n",
       "      <td>Аалто</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>аалтый</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>то</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ААР</td>\n",
       "      <td>ААР</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>аар</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ар</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Аара</td>\n",
       "      <td>Аара</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>аар</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ра</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ааре</td>\n",
       "      <td>Ааре</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>ааре</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ре</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Аарон</td>\n",
       "      <td>Аарон</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>аарон</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>он</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.760981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Word   word  len  len_word  vowels  consonant  ship  swist  zvon_parn  \\\n",
       "0   0  Аалто  Аалто    5         5       3          2     0      0          0   \n",
       "1   1    ААР    ААР    3         3       2          1     0      0          0   \n",
       "2   2   Аара   Аара    4         4       3          1     0      0          0   \n",
       "3   3   Ааре   Ааре    4         4       3          1     0      0          0   \n",
       "4   4  Аарон  Аарон    5         5       3          2     0      0          0   \n",
       "\n",
       "      ...          sing      plur  pymorphy  pymorphy_values  normal_form  \\\n",
       "0     ...      1.000000  0.000000         0                1       аалтый   \n",
       "1     ...      0.000000  0.000000         0                1          аар   \n",
       "2     ...      0.565217  0.434783         0               17          аар   \n",
       "3     ...      0.500000  0.500000         0               12         ааре   \n",
       "4     ...      1.000000  0.000000         1                7        аарон   \n",
       "\n",
       "   mystem  Natasha  2end  count_normal  Prediction  \n",
       "0       0        0    то           0.0    0.235761  \n",
       "1       0        0    ар           1.0    0.025434  \n",
       "2       0        0    ра           1.0    0.291601  \n",
       "3       0        0    ре           0.0    0.339099  \n",
       "4       0        1    он           6.0    0.760981  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Prediction'] = ctb.predict_proba(test.drop(['Word', 'word'], axis=1).values)[:, 1]\n",
    "test = test.reset_index().rename(columns={'index': 'Id'})\n",
    "test[['Id', 'Prediction']].to_csv('./submissions/sub22.csv', index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ratio_capitals</td>\n",
       "      <td>23.416657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>istitle</td>\n",
       "      <td>13.116555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w2v_surname</td>\n",
       "      <td>12.526096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>normal_form</td>\n",
       "      <td>8.209293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>count_normal</td>\n",
       "      <td>8.082563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2end</td>\n",
       "      <td>6.998043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>capitals</td>\n",
       "      <td>5.167944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vowels</td>\n",
       "      <td>4.655005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pymorphy</td>\n",
       "      <td>3.544970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pymorphy_values</td>\n",
       "      <td>2.186932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noun</td>\n",
       "      <td>2.006632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Natasha</td>\n",
       "      <td>1.732586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>masc</td>\n",
       "      <td>1.113919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>len</td>\n",
       "      <td>0.757076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>swist</td>\n",
       "      <td>0.656934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>femn</td>\n",
       "      <td>0.604785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ratio_consonant</td>\n",
       "      <td>0.587550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sing</td>\n",
       "      <td>0.567518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>neut</td>\n",
       "      <td>0.565824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>verb</td>\n",
       "      <td>0.554809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ratio_vowels</td>\n",
       "      <td>0.487824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>plur</td>\n",
       "      <td>0.470023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>consonant</td>\n",
       "      <td>0.432994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>adjf</td>\n",
       "      <td>0.393633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ship</td>\n",
       "      <td>0.306610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>glukh_parn</td>\n",
       "      <td>0.268331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>len_word</td>\n",
       "      <td>0.216886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zvon_neparn</td>\n",
       "      <td>0.190399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>glukh_neparn</td>\n",
       "      <td>0.087491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cyrillic</td>\n",
       "      <td>0.055381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zvon_parn</td>\n",
       "      <td>0.038736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mystem</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           features     fscore\n",
       "13   ratio_capitals  23.416657\n",
       "14          istitle  13.116555\n",
       "16      w2v_surname  12.526096\n",
       "27      normal_form   8.209293\n",
       "31     count_normal   8.082563\n",
       "30             2end   6.998043\n",
       "10         capitals   5.167944\n",
       "2            vowels   4.655005\n",
       "25         pymorphy   3.544970\n",
       "26  pymorphy_values   2.186932\n",
       "17             noun   2.006632\n",
       "29          Natasha   1.732586\n",
       "20             masc   1.113919\n",
       "0               len   0.757076\n",
       "5             swist   0.656934\n",
       "21             femn   0.604785\n",
       "12  ratio_consonant   0.587550\n",
       "23             sing   0.567518\n",
       "22             neut   0.565824\n",
       "18             verb   0.554809\n",
       "11     ratio_vowels   0.487824\n",
       "24             plur   0.470023\n",
       "3         consonant   0.432994\n",
       "19             adjf   0.393633\n",
       "4              ship   0.306610\n",
       "7        glukh_parn   0.268331\n",
       "1          len_word   0.216886\n",
       "8       zvon_neparn   0.190399\n",
       "9      glukh_neparn   0.087491\n",
       "15         cyrillic   0.055381\n",
       "6         zvon_parn   0.038736\n",
       "28           mystem   0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame(\n",
    "    data={\n",
    "        'features': train.drop(['Word', 'word', 'Label'], axis=1).columns,\n",
    "        'fscore': ctb.feature_importances_\n",
    "    }\n",
    ")\n",
    "importances = importances.reindex(importances.fscore.abs().sort_values(ascending=False).index)\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоги\n",
    "\n",
    "Что не получилось:\n",
    "\n",
    "* Признак флага \"Дубликат из другого класса\" не дал прироста к качеству\n",
    "* Не нашел лик, так как и не искал его - хороший урок, если добавить leak к моему решению скор на паблике был бы 0.98280: второе место)\n",
    "* Target encoding в отличии от catboost не дал заметных приростов (возможно это связано с кривой реализацией)\n",
    "* К сожалению, я не приручил catboost с CSR матрицами - очень хотелось добавить к данным признакам CountVectorizer, так как xgboost с такими фичами и count_vectorizer(analyzer='char_wb', ngram_range=(3, 5), lowercase=True) выдавал очень неплохой бейзлайн со скором на публичном лидерборде в районе 0.919."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
