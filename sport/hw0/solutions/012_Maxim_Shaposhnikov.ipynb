{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шапошников Максим<br>\n",
    "12 место на private (0.943), 12 место на public (0.94)<br>\n",
    "Подход: xgboost на выделенных фичах + результат логистической регрессии на n-grams и knn на выделенных фичах как дополнительные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## признак 1 - заглавная буква"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['First_is_upper'] = train_data.apply(lambda row: 1 if row.Word[0].isupper() and row.Word[1:].islower() else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## признак 2 - слово с маленькой буквы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['Starts_with_lower'] = train_data.apply(lambda row: 1 if row.Word.islower() else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## признак 3 - в слове все буквы заглавные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['All_upper'] = train_data.apply(lambda row: 1 if row.Word.isupper() else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## признак 4 - слово в CamelCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camel_case_detector(word):\n",
    "    res = [x for x in word if x.isupper()]\n",
    "    if len(res) >= 2 and len(res) < len(word):\n",
    "        return 1\n",
    "    return 0\n",
    "train_data['CamelCase'] = train_data.apply(lambda row: camel_case_detector(row.Word), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## признак 5 - количество гласных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "train_data['Count_Vowels'] = train_data.apply(lambda row: len(re.findall('[уеыаоэяию]', row.Word, re.IGNORECASE)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## признак 6 - наличие дополнительных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def contains_special_symbols(word):\n",
    "    for w in word:\n",
    "        if w in string.punctuation or w == '':\n",
    "            return 1\n",
    "    return 0\n",
    "train_data['Has_special_symbols'] = train_data.apply(lambda row: contains_special_symbols(row.Word), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## признак 7 - Pymorphy распознал слово как фамилию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "analyzer = pymorphy2.MorphAnalyzer()\n",
    "def is_surname_by_pymorphy(word):\n",
    "    parsed = analyzer.parse(word)\n",
    "    for variant in parsed:\n",
    "        if 'Surn' in variant.tag:\n",
    "            return 1\n",
    "    return 0\n",
    "train_data['pymorphy'] = train_data.apply(lambda row: is_surname_by_pymorphy(row.Word), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 8 - Есть ли дубликат из другого класса\n",
    "для линйной модели критично и лучше вообще выбросить дубликаты\n",
    "для деревьев может - могут сосуществовать вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 9 - Word2Vec модель на Фамилия + слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('ruscorpora_1_300_10.bin.gz', binary=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2vec_similarity(word):\n",
    "    for_vec_model = '{}_NOUN'.format(word.lower())\n",
    "    try:\n",
    "        return model.similarity('фамилия_NOUN', for_vec_model)\n",
    "    except KeyError as e:\n",
    "        return 0\n",
    "train_data['word2vecSim'] = train_data.apply(lambda row: word2vec_similarity(row.Word), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 10 - Pymystem3 для уточнения - фамилия или нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymystem3\n",
    "stemmer = pymystem3.Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def stemming(word):\n",
    "#     response = stemmer.analyze(word)\n",
    "#     try:\n",
    "#         analysis = response[0].get('analysis')[0].get('gr')\n",
    "#         if 'фам' in analysis:\n",
    "#             return 1\n",
    "#     except Exception:\n",
    "#         return 0\n",
    "#     return 0\n",
    "# train_data['pymyStem'] = train_data.apply(lambda row: stemming(row.Word), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 11 - Natasha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_from_Natasha = pd.read_csv('train_with_natasha.csv').Natasha.values\n",
    "train_data['Natasha'] = predictions_from_Natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 12 - Длина слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['Length'] = train_data['Word'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 13 - Количество согласных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['Count_Not_Vowels'] = train_data['Length'] - train_data['Count_Vowels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 14 - группа признаков из pyMorphy тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "train_data['pymorphyObj'] = train_data['Word'].apply(lambda x: morph.tag(x)[0])\n",
    "\n",
    "train_data['pymorphy_animacy'] = train_data['pymorphyObj'].apply(lambda x: x.animacy)\n",
    "train_data['pymorphy_POS'] = train_data['pymorphyObj'].apply(lambda x: x.POS)\n",
    "train_data['pymorphy_case'] = train_data['pymorphyObj'].apply(lambda x: x.case)\n",
    "train_data['pymorphy_number'] = train_data['pymorphyObj'].apply(lambda x: x.number)\n",
    "train_data['pymorphy_gender'] = train_data['pymorphyObj'].apply(lambda x: x.gender)\n",
    "\n",
    "train_data.drop('pymorphyObj' , axis=1 , inplace=True)\n",
    "\n",
    "columns_to_one_hot = ['pymorphy_animacy', 'pymorphy_POS', 'pymorphy_case','pymorphy_number', 'pymorphy_gender']\n",
    "\n",
    "for col in columns_to_one_hot:\n",
    "    train_data[col] = LabelEncoder().fit_transform(list(train_data[col].fillna('nan')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 14(2) - предсказания pyMystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_from_stem = pd.read_csv('train_with_natashaAndPymystem.csv')\n",
    "train_data['pyStemName'] = predictions_from_stem.pymystemName\n",
    "train_data['pyStemSurname'] = predictions_from_stem.pymystemSurname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 15 - Результат линейной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['linearModel'] = linear_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признак 16 - KNN модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['KnnPred'] = knnpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция для формирования результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(predictions, filename='submit.csv'):\n",
    "    submit = pd.DataFrame({'Prediction': predictions})\n",
    "    submit.index.name = 'Id'\n",
    "    submit.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "      <th>First_is_upper</th>\n",
       "      <th>Starts_with_lower</th>\n",
       "      <th>All_upper</th>\n",
       "      <th>CamelCase</th>\n",
       "      <th>Count_Vowels</th>\n",
       "      <th>Has_special_symbols</th>\n",
       "      <th>pymorphy</th>\n",
       "      <th>word2vecSim</th>\n",
       "      <th>...</th>\n",
       "      <th>Length</th>\n",
       "      <th>Count_Not_Vowels</th>\n",
       "      <th>pymorphy_animacy</th>\n",
       "      <th>pymorphy_POS</th>\n",
       "      <th>pymorphy_case</th>\n",
       "      <th>pymorphy_number</th>\n",
       "      <th>pymorphy_gender</th>\n",
       "      <th>pyStemName</th>\n",
       "      <th>pyStemSurname</th>\n",
       "      <th>linearModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалтонен</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Аар</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201280</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аарон</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ААРОН</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарона</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Label  First_is_upper  Starts_with_lower  All_upper  CamelCase  \\\n",
       "0  Аалтонен      1               1                  0          0          0   \n",
       "1       Аар      0               1                  0          0          0   \n",
       "2     Аарон      0               1                  0          0          0   \n",
       "3     ААРОН      0               0                  0          1          0   \n",
       "4    Аарона      0               1                  0          0          0   \n",
       "\n",
       "   Count_Vowels  Has_special_symbols  pymorphy  word2vecSim     ...       \\\n",
       "0             4                    0         0     0.000000     ...        \n",
       "1             2                    0         0     0.201280     ...        \n",
       "2             3                    0         1     0.168421     ...        \n",
       "3             3                    0         1     0.168421     ...        \n",
       "4             4                    0         1     0.000000     ...        \n",
       "\n",
       "   Length  Count_Not_Vowels  pymorphy_animacy  pymorphy_POS  pymorphy_case  \\\n",
       "0       8                 4                 2             1              7   \n",
       "1       3                 1                 2            17              7   \n",
       "2       5                 2                 0             8              8   \n",
       "3       5                 2                 0             8              8   \n",
       "4       6                 2                 0             8              4   \n",
       "\n",
       "   pymorphy_number  pymorphy_gender  pyStemName  pyStemSurname  linearModel  \n",
       "0                2                1           0              0     0.409957  \n",
       "1                0                2           0              0     0.200070  \n",
       "2                2                1           1              0     0.274166  \n",
       "3                2                1           1              0     0.274166  \n",
       "4                2                1           0              1     0.259846  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделение признаков в test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_from_Natasha = pd.read_csv('test_with_natashaAndPymystem.csv')\n",
    "test_data['First_is_upper'] = test_data.apply(lambda row: 1 if row.Word[0].isupper() and row.Word[1:].islower() else 0, axis=1)\n",
    "test_data['Starts_with_lower'] = test_data.apply(lambda row: 1 if row.Word.islower() else 0, axis=1)\n",
    "test_data['All_upper'] = test_data.apply(lambda row: 1 if row.Word.isupper() else 0, axis=1)\n",
    "test_data['CamelCase'] = test_data.apply(lambda row: camel_case_detector(row.Word), axis=1)\n",
    "test_data['Count_Vowels'] = test_data.apply(lambda row: len(re.findall('[уеыаоэяию]', row.Word, re.IGNORECASE)), axis=1)\n",
    "test_data['Has_special_symbols'] = test_data.apply(lambda row: contains_special_symbols(row.Word), axis=1)\n",
    "test_data['pymorphy'] = test_data.apply(lambda row: is_surname_by_pymorphy(row.Word), axis=1)\n",
    "test_data['word2vecSim'] = test_data.apply(lambda row: word2vec_similarity(row.Word), axis=1)\n",
    "test_data['Natasha'] = predictions_from_Natasha.Natasha\n",
    "test_data['Length'] = test_data['Word'].apply(lambda x: len(x))\n",
    "test_data['Count_Not_Vowels'] = test_data['Length'] - test_data['Count_Vowels']\n",
    "test_data['pymorphyObj'] = test_data['Word'].apply(lambda x: morph.tag(x)[0])\n",
    "\n",
    "test_data['pymorphy_animacy'] = test_data['pymorphyObj'].apply(lambda x: x.animacy)\n",
    "test_data['pymorphy_POS'] = test_data['pymorphyObj'].apply(lambda x: x.POS)\n",
    "test_data['pymorphy_case'] = test_data['pymorphyObj'].apply(lambda x: x.case)\n",
    "test_data['pymorphy_number'] = test_data['pymorphyObj'].apply(lambda x: x.number)\n",
    "test_data['pymorphy_gender'] = test_data['pymorphyObj'].apply(lambda x: x.gender)\n",
    "\n",
    "test_data.drop('pymorphyObj' , axis=1 , inplace=True)\n",
    "\n",
    "columns_to_one_hot = ['pymorphy_animacy', 'pymorphy_POS', 'pymorphy_case','pymorphy_number', 'pymorphy_gender']\n",
    "\n",
    "for col in columns_to_one_hot:\n",
    "    test_data[col] = LabelEncoder().fit_transform(list(test_data[col].fillna('nan')))\n",
    "test_data['pyStemName'] = predictions_from_Natasha.pymystemName\n",
    "test_data['pyStemSurname'] = predictions_from_Natasha.pymystemSurname\n",
    "test_data['linearModel'] = linear_preds\n",
    "test_data['KnnPred'] = knnpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тестовая и отложенная выборки на обучении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "drop_features = ['Word', 'Label']\n",
    "feature_names = [c for c in train_data if c not in drop_features]\n",
    "X = train_data[feature_names]\n",
    "y = train_data['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=True, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost модель - 0.915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.951898\tvalid-auc:0.949133\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 100 rounds.\n",
      "[10]\ttrain-auc:0.961695\tvalid-auc:0.95534\n",
      "[20]\ttrain-auc:0.964442\tvalid-auc:0.956187\n",
      "[30]\ttrain-auc:0.965821\tvalid-auc:0.956359\n",
      "[40]\ttrain-auc:0.966794\tvalid-auc:0.956468\n",
      "[50]\ttrain-auc:0.96724\tvalid-auc:0.956369\n",
      "[60]\ttrain-auc:0.968155\tvalid-auc:0.956318\n",
      "[70]\ttrain-auc:0.968787\tvalid-auc:0.956129\n",
      "[80]\ttrain-auc:0.969195\tvalid-auc:0.956335\n",
      "[90]\ttrain-auc:0.969578\tvalid-auc:0.956136\n",
      "[100]\ttrain-auc:0.96998\tvalid-auc:0.956037\n",
      "[110]\ttrain-auc:0.970337\tvalid-auc:0.955927\n",
      "[120]\ttrain-auc:0.970578\tvalid-auc:0.955918\n",
      "[130]\ttrain-auc:0.970857\tvalid-auc:0.955944\n",
      "Stopping. Best iteration:\n",
      "[36]\ttrain-auc:0.966603\tvalid-auc:0.956546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "XG_train = xgb.DMatrix(X_train, label=y_train)\n",
    "XG_test = xgb.DMatrix(X_test, label=y_test)\n",
    "params = {'max_depth': 10, \n",
    "          'min_child_weight': 20, \n",
    "          'lambda': 0.1,\n",
    "          'alpha': 0.1,\n",
    "          'eta': 0.3, \n",
    "          'objective': 'binary:logistic',\n",
    "          'eval_metric' : 'auc',\n",
    "          'silent': 1,\n",
    "          'seed': 17\n",
    "         }\n",
    "watchlist = [(XG_train, 'train'), (XG_test, 'valid')]\n",
    "xgbmodel = xgb.train(params, XG_train, 30000, watchlist, early_stopping_rounds=100, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_features = [c for c in test_data if c not in ['Word','Id']]\n",
    "XG_submission = xgb.DMatrix(test_data[submission_features])\n",
    "predictions = xgbmodel.predict(XG_submission)\n",
    "make_submission(predictions, 'xgboostModel7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost о валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates(subset=['Word'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "drop_features = ['Word', 'Label', 'Id']\n",
    "feature_names = [c for c in train_data if c not in drop_features]\n",
    "X = train_data[feature_names]\n",
    "y = train_data['Label']\n",
    "modelXGB = XGBClassifier(max_depth = 10 , n_estimators=670 , learning_rate=0.09 , colsample_bytree=0.9 , colsample_bylevel=0.6)\n",
    "cv = StratifiedKFold(4 ,shuffle=True, random_state=99)\n",
    "score = cross_val_score( modelXGB, X, y, scoring='roc_auc' , cv=cv)\n",
    "print (score.mean() , score.std() , '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelXGB = XGBClassifier(max_depth = 10 , n_estimators=670 , learning_rate=0.09 , colsample_bytree=0.9 , colsample_bylevel=0.6)\n",
    "X = train_data[feature_names]\n",
    "y = train_data['Label']\n",
    "modelXGB.fit(X, y)\n",
    "submission_features = [c for c in test_data if c not in ['Word','Id']]\n",
    "X_test = test_data[submission_features]\n",
    "predictions = modelXGB.predict(X_test)\n",
    "make_submission(predictions, 'xgboost_linModel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model, логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_copy = train_data.drop_duplicates(subset=['Word'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2,10), analyzer='char_wb')\n",
    "skf = StratifiedKFold(random_state=42, n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_vec = vectorizer.fit_transform(data_copy.Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from scipy.sparse import hstack\n",
    "# dropped_features = ['Word', 'Label', 'Count_Not_Vowels']\n",
    "# x_train_features = train_data[[c for c in train_data if c not in dropped_features]]\n",
    "# X_train = hstack([x_train_vec, x_train_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.1, 0.01, 0.001, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "param_grid = {\n",
    "    'C' : [0.1, 0.01, 0.001, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "estimator = LogisticRegression()\n",
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "grid.fit(x_train_vec, data_copy.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.66635, std: 0.12044, params: {'C': 0.1, 'penalty': 'l1'},\n",
       "  mean: 0.75644, std: 0.07461, params: {'C': 0.1, 'penalty': 'l2'},\n",
       "  mean: 0.66458, std: 0.05154, params: {'C': 0.01, 'penalty': 'l1'},\n",
       "  mean: 0.78484, std: 0.04029, params: {'C': 0.01, 'penalty': 'l2'},\n",
       "  mean: 0.50000, std: 0.00000, params: {'C': 0.001, 'penalty': 'l1'},\n",
       "  mean: 0.78306, std: 0.01929, params: {'C': 0.001, 'penalty': 'l2'},\n",
       "  mean: 0.65052, std: 0.13398, params: {'C': 1, 'penalty': 'l1'},\n",
       "  mean: 0.74088, std: 0.08366, params: {'C': 1, 'penalty': 'l2'},\n",
       "  mean: 0.64361, std: 0.12804, params: {'C': 10, 'penalty': 'l1'},\n",
       "  mean: 0.73435, std: 0.08533, params: {'C': 10, 'penalty': 'l2'},\n",
       "  mean: 0.63388, std: 0.13190, params: {'C': 100, 'penalty': 'l1'},\n",
       "  mean: 0.73190, std: 0.08680, params: {'C': 100, 'penalty': 'l2'}],\n",
       " 0.78484468851682987)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estim = grid.best_estimator_\n",
    "x_test_vec = vectorizer.transform(test_data.Word)\n",
    "linear_preds = [x[1] for x in estim.predict_proba(x_test_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linearModel = grid.best_estimator_\n",
    "x_test_vec = vectorizer.transform(test_data.Word)\n",
    "x_test_features = test_data[[c for c in test_data if c not in ['Word']]]\n",
    "X_test = hstack([x_test_vec, x_test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [x[1] for x in linearModel.predict_proba(X_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN расстояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'kd_tree']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "params = {\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm' : ['auto', 'kd_tree'],\n",
    "}\n",
    "grid = GridSearchCV(estimator=knn, param_grid=params, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "feature_names = [c for c in train_data if c not in ['Word', 'Label', 'Id']]\n",
    "X = train_data[feature_names]\n",
    "y = train_data['Label']\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estim = grid.best_estimator_\n",
    "feature_names = [c for c in test_data if c not in ['Word', 'Label', 'Id']]\n",
    "X = test_data[feature_names]\n",
    "knnpreds = estim.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_submission(predictions, 'logisticRegression.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
