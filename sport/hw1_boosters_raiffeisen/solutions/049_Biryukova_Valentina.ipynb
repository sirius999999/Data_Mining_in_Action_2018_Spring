{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Будут вопросы, пишите valencia13@mail.ru\n",
    "\n",
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date, timedelta\n",
    "import dateutil\n",
    "import time\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "from math import sqrt, pow as pw\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определим типы колонок для экономии памяти\n",
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "# для экономии памяти будем загружать только часть атрибутов транзакций\n",
    "usecols_train = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon']\n",
    "usecols_test = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']\n",
    "\n",
    "train = pd.read_csv('train_set.csv', dtype = dtypes, usecols = usecols_train)\n",
    "train.rename(columns = {'pos_adress_lat': 'pos_address_lat', 'pos_adress_lon': 'pos_address_lon'}, inplace = True)\n",
    "\n",
    "test = pd.read_csv('test_set.csv', dtype = dtypes, usecols = usecols_test)\n",
    "submission = pd.DataFrame(test['customer_id'].unique(), columns = ['_ID_'])\n",
    "\n",
    "# соединяем test/train в одном DataFrame\n",
    "train['is_train'] = np.int32(1)\n",
    "test['is_train'] = np.int32(0)\n",
    "data = pd.concat([train, test])\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "double_home_la = data.groupby(['customer_id'])['home_add_lat'].unique()\n",
    "double_home_lo = data.groupby(['customer_id'])['home_add_lon'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doub_h_la = []\n",
    "for i in zip(double_home_la.index, double_home_la.values):\n",
    "    if len(i[1]) >1:\n",
    "        doub_h_la.append(i[0])\n",
    "doub_h_lo = []\n",
    "for i in zip(double_home_lo.index, double_home_lo.values):\n",
    "    if len(i[1]) >1:\n",
    "        doub_h_lo.append(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "double_work_la = data.groupby(['customer_id'])['work_add_lat'].unique()\n",
    "double_work_lo = data.groupby(['customer_id'])['work_add_lon'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doub_w_la = []\n",
    "for i in zip(double_work_la.index, double_work_la.values):\n",
    "    if len(i[1]) >1:\n",
    "        doub_w_la.append(i[0])\n",
    "doub_w_lo = []\n",
    "for i in zip(double_work_lo.index, double_work_lo.values):\n",
    "    if len(i[1]) >1:\n",
    "        doub_w_lo.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doub_h_la), len(doub_h_lo), len(doub_w_la), len(doub_w_lo))\n",
    "del_us = set(doub_h_la + doub_h_lo + doub_w_la + doub_w_lo)\n",
    "len(del_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in del_us:\n",
    "    data = data[data.customer_id != i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.customer_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcc = pd.read_csv('mcc.csv', header=None)\n",
    "mcc.columns = ['mcc', 'cat', 'group']\n",
    "# mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['mcc'] = data['mcc'].apply(lambda x: int(''.join(str(x).split(','))))\n",
    "data['mcc'] = pd.to_numeric(data['mcc'])\n",
    "data = data.join(mcc.set_index('mcc'), on='mcc', rsuffix='_2')\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data[['atm_address_lat', 'pos_address_lat', 'atm_address_lon', 'pos_address_lon']] = data[['atm_address_lat', 'pos_address_lat', 'atm_address_lon', 'pos_address_lon']].fillna(0)\n",
    "\n",
    "data['ter_lat'] = data['atm_address_lat'].fillna(data['pos_address_lat'])\n",
    "data['ter_lon'] = data['atm_address_lon'].fillna(data['pos_address_lon'])\n",
    "\n",
    "data['ter_lat'] = data['ter_lat'].apply(lambda x: round(x,3))\n",
    "data['ter_lon'] = data['ter_lon'].apply(lambda x: round(x,3))\n",
    "\n",
    "data['atm_address_lat'] = data['atm_address_lat'].notnull()*1\n",
    "data['pos_address_lat'] = data['pos_address_lat'].notnull()*1\n",
    "\n",
    "data['atm_address_lon'] = data['atm_address_lon'].notnull()*1\n",
    "data['pos_address_lon'] = data['pos_address_lon'].notnull()*1#.apply(lambda x: not(x.isnull())*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data['toh'] = data.apply(lambda x: ((x.ter_lat - x.home_add_lat)**2 + (x.ter_lon - x.home_add_lon)**2)**(1/2), axis=1)\n",
    "# data['tow'] = data.apply(lambda x: ((x.ter_lat - x.work_add_lat)**2 + (x.ter_lon - x.work_add_lon)**2)**(1/2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = pd.read_csv('dates.csv', header=None)\n",
    "\n",
    "data.transaction_date = pd.to_datetime(data.transaction_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['transaction_date'].notnull())]\n",
    "datess = []\n",
    "for i in range(12):\n",
    "    datess.append(set(map(int, dates[i][0].split(','))))\n",
    "datess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['week'] = data['transaction_date'].apply(lambda x: 0 if x.day in datess[x.month-1] else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.ter_lat.isnull().sum(), data.ter_lon.isnull().sum(), data.shape)\n",
    "data = data[np.isfinite(data['ter_lat'])]\n",
    "# data = data[np.isfinite(data['work_add_lat'])]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8,4))\n",
    "# ax.plot(data['toh'], marker='.', linestyle='None')\n",
    "# fig.autofmt_xdate()\n",
    "# plt.title('toh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mimeco=data.groupby('customer_id')['amount'].agg(['count'])\n",
    "# mimeco=data.groupby('customer_id')['toh'].agg(['min', 'mean', 'median', 'count'])\n",
    "data = data.join(mimeco, on='customer_id', rsuffix='_2')\n",
    "\n",
    "# mimeco=data.groupby('customer_id')['tow'].agg(['min'])\n",
    "# # mimeco=data.groupby('customer_id')['tow'].agg(['min', 'mean', 'median', 'count'])\n",
    "\n",
    "# data = data.join(mimeco, on='customer_id', rsuffix='_w')\n",
    "mass = pd.DataFrame(data.groupby(['ter_lon'])['amount'].count())\n",
    "mass.columns = ['mass']\n",
    "data = data.join(mass, on='ter_lon', rsuffix='_2')  \n",
    "# print(mass[mass.amount > 1000].shape)\n",
    "# masss = set(mass[mass.amount > 1000]['ter_lon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['ter_lat','ter_lon']:\n",
    "    data[i+'_2'] = data[i].apply(lambda x: round(x, 2))\n",
    "    data[i+'_1'] = data[i].apply(lambda x: round(x, 1))\n",
    "    \n",
    "\n",
    "mass1 = pd.DataFrame(data.groupby(['ter_lon_1', 'ter_lat_1'])['amount'].count()).reset_index()\n",
    "mass2 = pd.DataFrame(data.groupby(['ter_lon_2', 'ter_lat_2'])['amount'].count()).reset_index()\n",
    "\n",
    "data = pd.merge(data, mass1,  how='inner', left_on=['ter_lon_1', 'ter_lat_1'], right_on = ['ter_lon_1', 'ter_lat_1'])\n",
    "data = pd.merge(data, mass2,  how='inner', left_on=['ter_lon_2', 'ter_lat_2'], right_on = ['ter_lon_2', 'ter_lat_2'])\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data[data['min']>0.02].shape\n",
    "data['weekday'] = data['transaction_date'].apply(lambda x: x.weekday())\n",
    "data['day'] = data['transaction_date'].apply(lambda x: x.weekday())\n",
    "data['weekend'] = data['weekday'].apply(lambda x: ((x==5) or (x==6))*1)\n",
    "data['month'] = data['transaction_date'].apply(lambda x: x.month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = pd.read_csv('coord_all.csv')\n",
    "data = data.join(coord.set_index('cus'), on='customer_id', rsuffix='_2')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "\n",
    "data = data[np.isfinite(data['lat1'])]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['currency'] = data['currency'].fillna(-1).astype(np.int32)\n",
    "# data['mcc'] = data['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)\n",
    "data['city'] = data['city'].factorize()[0].astype(np.int32)\n",
    "data['country'] = data['country'].factorize()[0].astype(np.int32)\n",
    "\n",
    "# удаляем транзакции без даты\n",
    "data.drop(data[data['transaction_date'].isnull()].index, axis = 0, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tsfresh import extract_features\n",
    "# from tsfresh.feature_extraction.settings import ComprehensiveFCParameters, MinimalFCParameters, EfficientFCParameters\n",
    "# from tsfresh import select_features\n",
    "# from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "# settings=MinimalFCParameters()\n",
    "# settings['number_cwt_peaks'] = ComprehensiveFCParameters()['number_cwt_peaks']\n",
    "# settings['number_peaks'] = ComprehensiveFCParameters()['number_peaks']\n",
    "# settings['cid_ce'] = ComprehensiveFCParameters()['cid_ce']\n",
    "# # settings['agg_linear_trend'] = ComprehensiveFCParameters()['agg_linear_trend']\n",
    "# settings['agg_autocorrelation'] = ComprehensiveFCParameters()['agg_autocorrelation']\n",
    "# settings['c3'] = ComprehensiveFCParameters()['c3']\n",
    "# settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_am = pd.DataFrame(data.groupby(['customer_id', 'transaction_date'])['amount'].median()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracted_features = extract_features(data, column_id=\"customer_id\",\\\n",
    "#                                       column_sort=\"transaction_date\", column_value=\"ter_lon\", default_fc_parameters=settings, n_jobs=4)\n",
    "# impute(extracted_features)\n",
    "# # features_filtered = select_features(extracted_features, target)\n",
    "# data = data.join(extracted_features, on='customer_id')\n",
    "\n",
    "# # del extracted_features; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extracted_features.to_csv('extracted_features_lon.csv')\n",
    "ext_f = pd.read_csv('extracted_features.csv')\n",
    "# ext_lat = pd.read_csv('extracted_features_lat.csv')\n",
    "# ext_lon = pd.read_csv('extracted_features_lon.csv')\n",
    "ext_f = ext_f.set_index('id')\n",
    "# ext_lat = ext_lat.set_index('id')\n",
    "# ext_lon = ext_lon.set_index('id')\n",
    "\n",
    "data = data.join(ext_f, on='customer_id')\n",
    "# data = data.join(ext_lat, on='customer_id')\n",
    "# data = data.join(ext_lon, on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(data.shape)\n",
    "\n",
    "# data['is_atm'] = (~data['atm_address_lat'].isnull()).astype(np.int32)\n",
    "# data['is_pos'] = (~data['pos_address_lat'].isnull()).astype(np.int32)\n",
    "\n",
    "# data['address_lat'] = data['atm_address_lat'].fillna(0) + data['pos_address_lat'].fillna(0)\n",
    "# data['address_lon'] = data['atm_address_lon'].fillna(0) + data['pos_address_lon'].fillna(0)\n",
    "\n",
    "# data.drop(['atm_address_lat','atm_address_lon','pos_address_lat','pos_address_lon'], axis = 1, inplace = True)\n",
    "\n",
    "# # удалим транзакции без адреса\n",
    "# data.drop(data[((data['address_lon'] == 0) & (data['address_lon'] == 0))].index, axis = 0, inplace = True)\n",
    "\n",
    "# print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = data['home_add_lat'] - data['ter_lat']\n",
    "lon = data['home_add_lon'] - data['ter_lon']\n",
    "data['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "data['has_home'] = (~data['home_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "lat = data['work_add_lat'] - data['ter_lat']\n",
    "lon = data['work_add_lon'] - data['ter_lon']\n",
    "data['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "data['has_work'] = (~data['work_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "# data.drop(['work_add_lat','work_add_lon','home_add_lat','home_add_lon'], axis = 1, inplace = True)\n",
    "\n",
    "data['address'] = data['ter_lat'].apply(lambda x: \"%.02f\" % x) + ';' + data['ter_lon'].apply(lambda x: \"%.02f\" % x)\n",
    "data['address'] = data['address'].factorize()[0].astype(np.int32)\n",
    "\n",
    "data = data.merge(data.groupby(['customer_id','address'])['amount'].count().reset_index(name = 'tx_cust_addr'), how = 'left')\n",
    "data['tx_cust_addr'] = data['tx_cust_addr'].astype(np.int32)\n",
    "\n",
    "# какая часть транзакций клиента приходится на данный адрес\n",
    "data['ratio1'] = data['tx_cust_addr'] / data['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def add_noise(series, noise_level):\n",
    "#     return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "# def target_encode(trn_series=None, \n",
    "#                   tst_series=None, \n",
    "#                   target=None, \n",
    "#                   min_samples_leaf=1, \n",
    "#                   smoothing=1,\n",
    "#                   noise_level=0):\n",
    "#     \"\"\"\n",
    "#     Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "#     https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "#     trn_series : training categorical feature as a pd.Series\n",
    "#     tst_series : test categorical feature as a pd.Series\n",
    "#     target : target data as a pd.Series\n",
    "#     min_samples_leaf (int) : minimum samples to take category average into account\n",
    "#     smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "#     \"\"\" \n",
    "#     assert len(trn_series) == len(target)\n",
    "#     assert trn_series.name == tst_series.name\n",
    "#     temp = pd.concat([trn_series, target], axis=1)\n",
    "#     # Compute target mean \n",
    "#     averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "#     # Compute smoothing\n",
    "#     smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "#     # Apply average function to all target data\n",
    "#     prior = target.mean()\n",
    "#     # The bigger the count the less full_avg is taken into account\n",
    "#     averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "#     averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "#     # Apply averages to trn and tst series\n",
    "#     ft_trn_series = pd.merge(\n",
    "#         trn_series.to_frame(trn_series.name),\n",
    "#         averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "#         on=trn_series.name,\n",
    "#         how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "#     # pd.merge does not keep the index so restore it\n",
    "#     ft_trn_series.index = trn_series.index \n",
    "#     ft_tst_series = pd.merge(\n",
    "#         tst_series.to_frame(tst_series.name),\n",
    "#         averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "#         on=tst_series.name,\n",
    "#         how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "#     # pd.merge does not keep the index so restore it\n",
    "#     ft_tst_series.index = tst_series.index\n",
    "#     return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n",
    "\n",
    "# trn, sub = target_encode(data[data.is_train==1]['mcc'], \n",
    "#                          data[data.is_train==0]['mcc'], \n",
    "#                          target=data[data.is_train==1].is_home, \n",
    "#                          min_samples_leaf=100, #65 #70 не зашло\n",
    "#                          smoothing=10,\n",
    "#                          noise_level=0.01)\n",
    "# sub.head(100)\n",
    "# # # ind = len(train)\n",
    "# # # full = pd.concat([train_full, test_full]).reset_index(drop=True)\n",
    "# # # doub = full.groupby(['norm'])['Label'].mean()\n",
    "# # # print(doub)\n",
    "\n",
    "# # # train_full = train_full.join(doub, on='norm', rsuffix='_d')\n",
    "# # # test_full = test_full.join(doub, on='norm', rsuffix='_d')\n",
    "\n",
    "# # full = pd.concat([train_full, test_full]).fillna(0).reset_index(drop=True)\n",
    "# # doub = full.groupby(['norm'])['Label'].mean()\n",
    "# # print(doub)\n",
    "\n",
    "# # train_full = train_full.join(doub, on='norm', rsuffix='_d')\n",
    "# # test_full = test_full.join(doub, on='norm', rsuffix='_d')\n",
    "\n",
    "# # train_full.rename(columns={'Label_d':'Mean'}, inplace=True)\n",
    "# # test_full.rename(columns={'Label':'Mean'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# k = 0\n",
    "# innlalol = []\n",
    "# for i in ['90ea490b1609f862033a44b615690176', 'daa79438cba5089c7fd9ce7c4b1850bd', '1730b4288ddf5c690f31c0e463a7dec7']:\n",
    "    \n",
    "#     da = data[data.customer_id == i]\n",
    "#     melat = da['ter_lat'].median()\n",
    "#     melon = da['ter_lon'].median()\n",
    "#     inner_lat = da['ter_lat'].values\n",
    "#     inner_lon = da['ter_lon'].values\n",
    "#     lat = inner_lat - melat\n",
    "#     lon = inner_lon - melon\n",
    "#     n = [sqrt(pw(la, 2) + pw(lo, 2)) for la, lo in zip(lat,lon)]\n",
    "#     innlalol.extend(n)\n",
    "\n",
    "\n",
    "# print(k, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# k = 0\n",
    "# innlalo = []\n",
    "\n",
    "# for i in data.customer_id.unique():\n",
    "#     da = data[data.customer_id == i]\n",
    "#     melat = da['ter_lat'].median()\n",
    "#     melon = da['ter_lon'].median()\n",
    "#     inner_lat = da['ter_lat'].values\n",
    "#     inner_lon = da['ter_lon'].values\n",
    "#     lat = inner_lat - melat\n",
    "#     lon = inner_lon - melon\n",
    "#     n = [sqrt(pw(la,2) + pw(lo, 2)) for la, lo in zip(lat,lon)]\n",
    "#     innlalo.extend(n)\n",
    "#     k += 1\n",
    "#     if k%100==0:\n",
    "#         print(k, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inll = pd.DataFrame(innlalo)\n",
    "# inll.columns = ['innlalo']\n",
    "# inll.to_csv('innlalo.csv', index=False)\n",
    "# inll.head()\n",
    "# cou_mcc = pd.DataFrame(data[(data.is_train==1)].groupby('mcc')[['amount']].count()).reset_index()\n",
    "# cou_mcc.sort_values(by=['amount'], ascending=False)\n",
    "# mmccc = []\n",
    "# for i in range(cou_mcc.shape[0]):\n",
    "#     if cou_mcc['amount'].iloc[i]>8000:\n",
    "#         mmccc.append(cou_mcc['mcc'].iloc[i])\n",
    "# mmccc\n",
    "inll = pd.read_csv('innlalo.csv')\n",
    "inll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "data['innlalo'] = inll['innlalo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "\n",
    "# data = data.set_index('mcc')\n",
    "# # all_mcc_coord = []\n",
    "\n",
    "# for i in mmccc:\n",
    "#     exec('inner{} = data[[\"ter_lat\", \"ter_lon\"]].loc[i]'.format(i))\n",
    "#     exec('inner{} = inner{}.drop_duplicates()'.format(i, i))\n",
    "\n",
    "# data = data.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # def get_nn_eps(df, data, eps, mode):\n",
    "# # #     from sklearn.neighbors import NearestNeighbors\n",
    "# # #     neigh = NearestNeighbors(radius=eps, n_jobs=4)\n",
    "# # #     customer_id_dct_te=df.groupby(['customer_id']).count().index\n",
    "# # #     nn_eps_te=[]\n",
    "# # # #     print(customer_id_dct_te)\n",
    "# # #     for i,item in enumerate(customer_id_dct_te):\n",
    "# # #         if mode=='train':\n",
    "# # #             b=np.vstack((data[:i],data[i+1:]))\n",
    "# # #         else:\n",
    "# # #             b=data\n",
    "# # #         neigh.fit(b)\n",
    "# # #         vv = neigh.radius_neighbors(df[df['customer_id']==item][[\"ter_lat\", \"ter_lon\"]])\n",
    "# # # #         for j in neigh.radius_neighbors(df[df['customer_id']==item][[\"ter_lat\", \"ter_lon\"]])[0]:\n",
    "# # # #             print(j.shape[0])\n",
    "# # # #             nn_eps_te.append(j.shape[0])\n",
    "# # #     return vv.shape\n",
    "# lli = [] \n",
    "# for i in mmccc:\n",
    "#     exec('lli.append(({}, inner{}.shape[0]))'.format(i, i))\n",
    "# set(lli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_coor = data[['ter_lat', 'ter_lon']]\n",
    "# print(data_coor.shape)\n",
    "# data_coor = data_coor.drop_duplicates()\n",
    "# data_coor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from io import StringIO\n",
    "\n",
    "# #remember to restore the original stdout!\n",
    "\n",
    "# for mcc in lli:\n",
    "#     data_coor[mcc[0]] = -1\n",
    "#     inn = []\n",
    "#     print((mcc[0]))\n",
    "#     buffer = StringIO()\n",
    "#     sys.stdout = buffer\n",
    "#     for coor in range(data_coor.shape[0]):\n",
    "#         n = 0\n",
    "#         for mcc_coor in range(mcc[1]):\n",
    "#             exec('print(inner{}[\"ter_lat\"].iloc[mcc_coor])'.format(mcc[0]))\n",
    "#             latt = float(buffer.getvalue()[:-1])\n",
    "#             buffer = StringIO()\n",
    "#             sys.stdout = buffer\n",
    "#             exec('print(inner{}[\"ter_lon\"].iloc[mcc_coor])'.format(mcc[0]))\n",
    "#             lonn = float(buffer.getvalue()[:-1])\n",
    "#             buffer = StringIO()\n",
    "#             sys.stdout = buffer\n",
    "#             lat = data_coor['ter_lat'].iloc[coor] - latt\n",
    "#             lon = data_coor['ter_lon'].iloc[coor] - lonn\n",
    "#             if (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02):\n",
    "#                 n+=1\n",
    "# #         data_coor[mcc[0]].iloc[coor] = n\n",
    "#         inn.append(n)\n",
    "#     data_coor[mcc[0]] = inn\n",
    "\n",
    "#     sys.stdout = sys.__stdout__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #inner5814\n",
    "# import time\n",
    "# from math import sqrt, pow as pw\n",
    "# start_time = time.time()\n",
    "\n",
    "# # data_coor['inner5814'] = -1\n",
    "# inn = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5814.shape[0]):\n",
    "#         lat = data_coor[coor][0] - inner5814[mcc_coor][0]\n",
    "#         lon = data_coor[coor][1] - inner5814[mcc_coor][1]\n",
    "#         if (math.sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn.append(n)\n",
    "#     if coor%1000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# # data_coor['inner5814'] = inn\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# #         lat = data_coor['ter_lat'].iloc[coor] - inner5814['ter_lat'].iloc[mcc_coor]\n",
    "# #         lon = data_coor['ter_lon'].iloc[coor] - inner5814['ter_lon'].iloc[mcc_coor]\n",
    "\n",
    "# # 0 0.02087688446044922\n",
    "# # 1000 21.12002658843994\n",
    "# # 2000 41.68081474304199\n",
    "\n",
    "# # 0 0.014701128005981445\n",
    "# # 1000 13.027771472930908\n",
    "# # 2000 26.112202167510986\n",
    "\n",
    "# # 0 0.015043020248413086\n",
    "# # 1000 12.524210453033447\n",
    "# # 2000 24.834967851638794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inner5814 = inner5814.as_matrix()\n",
    "# data_coor = data_coor.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # data = data.set_index('mcc')\n",
    "# # # all_mcc_coord = []\n",
    "\n",
    "# # for i in mmccc:\n",
    "# #     exec('inner{} = data[[\"ter_lat\", \"ter_lon\"]].loc[i]'.format(i))\n",
    "# #     exec('inner{} = inner{}.drop_duplicates()'.format(i, i))\n",
    "\n",
    "# # data = data.reset_index()\n",
    "\n",
    "# data_coor = data[['ter_lat', 'ter_lon']]\n",
    "# print(data_coor.shape)\n",
    "# data_coor = data_coor.drop_duplicates()\n",
    "# data_coor.shape\n",
    "\n",
    "# data_lat = data_coor['ter_lat'].values\n",
    "# data_lon = data_coor['ter_lon'].values\n",
    "# # inner5411_lat = inner5411['ter_lat'].values\n",
    "# # inner5411_lon = inner5411['ter_lon'].values\n",
    "# data_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #inner5411\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn1 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5411.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5411_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5411_lon[mcc_coor]\n",
    "#         if (math.sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn1.append(n)\n",
    "#     if coor%1000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "# # #inner5411\n",
    "\n",
    "# # start_time = time.time()\n",
    "\n",
    "# # inn1 = []\n",
    "# # for coor in range(data_coor.shape[0]):   \n",
    "# #     n = 0\n",
    "# #     for mcc_coor in range(inner5411.shape[0]):\n",
    "# #         lat = data_coor[coor][0] - inner5411[mcc_coor][0]\n",
    "# #         lon = data_coor[coor][1] - inner5411[mcc_coor][1]\n",
    "# #         if (math.sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "# #             n+=1\n",
    "# #     inn1.append(n)\n",
    "# #     if coor%1000==0:\n",
    "# #         print(coor, time.time() - start_time)\n",
    "# # print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inner6011_lat = inner6011['ter_lat'].values\n",
    "# inner6011_lon = inner6011['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn6011 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner6011.shape[0]):\n",
    "#         lat = data_lat[coor] - inner6011_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner6011_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn6011.append(n)\n",
    "#     if coor%1000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inner4111_lat = inner4111['ter_lat'].values\n",
    "# inner4111_lon = inner4111['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn4111 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner4111.shape[0]):\n",
    "#         lat = data_lat[coor] - inner4111_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner4111_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn4111.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inner5261_lat = inner5261['ter_lat'].values\n",
    "# inner5261_lon = inner5261['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5261 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5261.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5261_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5261_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5261.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inner5311_lat = inner5311['ter_lat'].values\n",
    "# inner5311_lon = inner5311['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5311 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5311.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5311_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5311_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5311.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inner5331_lat = inner5331['ter_lat'].values\n",
    "# inner5331_lon = inner5331['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5331 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5331.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5331_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5331_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5331.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inner5499_lat = inner5499['ter_lat'].values\n",
    "# inner5499_lon = inner5499['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5499 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5499.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5499_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5499_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5499.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #  (5541, 4612),\n",
    "# #  (5691, 2313),\n",
    "# #  (5812, 7728),\n",
    "# ##  (5814, 6360),\n",
    "# #  (5912, 9642),\n",
    "# #  (5921, 3894),\n",
    "# #  (5977, 2192),\n",
    "# #  (5999, 2899),\n",
    "# ##  (6011, 87623)\n",
    "\n",
    "# inner5541_lat = inner5541['ter_lat'].values\n",
    "# inner5541_lon = inner5541['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5541 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5541.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5541_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5541_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5541.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #  (5691, 2313),\n",
    "# #  (5812, 7728),\n",
    "# ##  (5814, 6360),\n",
    "# #  (5912, 9642),\n",
    "# #  (5921, 3894),\n",
    "# #  (5977, 2192),\n",
    "# #  (5999, 2899),\n",
    "# ##  (6011, 87623)\n",
    "\n",
    "# inner5691_lat = inner5691['ter_lat'].values\n",
    "# inner5691_lon = inner5691['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5691 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5691.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5691_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5691_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5691.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #  (5812, 7728),\n",
    "# ##  (5814, 6360),\n",
    "# #  (5912, 9642),\n",
    "# #  (5921, 3894),\n",
    "# #  (5977, 2192),\n",
    "# #  (5999, 2899),\n",
    "# ##  (6011, 87623)\n",
    "\n",
    "# inner5812_lat = inner5812['ter_lat'].values\n",
    "# inner5812_lon = inner5812['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5812 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5812.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5812_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5812_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5812.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #  (5912, 9642),\n",
    "# #  (5921, 3894),\n",
    "# #  (5977, 2192),\n",
    "# #  (5999, 2899),\n",
    "# ##  (6011, 87623)\n",
    "\n",
    "# inner5912_lat = inner5912['ter_lat'].values\n",
    "# inner5912_lon = inner5912['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5912 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5912.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5912_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5912_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5912.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #  (5921, 3894),\n",
    "# #  (5977, 2192),\n",
    "# #  (5999, 2899),\n",
    "# ##  (6011, 87623)\n",
    "\n",
    "# inner5921_lat = inner5921['ter_lat'].values\n",
    "# inner5921_lon = inner5921['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5921 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5921.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5921_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5921_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5921.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #  (5977, 2192),\n",
    "# #  (5999, 2899),\n",
    "# ##  (6011, 87623)\n",
    "\n",
    "# inner5977_lat = inner5977['ter_lat'].values\n",
    "# inner5977_lon = inner5977['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5977 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5977.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5977_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5977_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5977.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #  (5999, 2899),\n",
    "# ##  (6011, 87623)\n",
    "\n",
    "# inner5999_lat = inner5999['ter_lat'].values\n",
    "# inner5999_lon = inner5999['ter_lon'].values\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# inn5999 = []\n",
    "# for coor in range(data_coor.shape[0]):   \n",
    "#     n = 0\n",
    "#     for mcc_coor in range(inner5999.shape[0]):\n",
    "#         lat = data_lat[coor] - inner5999_lat[mcc_coor]\n",
    "#         lon = data_lon[coor] - inner5999_lon[mcc_coor]\n",
    "#         if (sqrt(pw(lat,2) + pw(lon, 2)) <= 0.02):\n",
    "#             n+=1\n",
    "#     inn5999.append(n)\n",
    "#     if coor%10000==0:\n",
    "#         print(coor, time.time() - start_time)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # data_coor = data[['ter_lat', 'ter_lon']]\n",
    "# # print(data_coor.shape)\n",
    "# # data_coor = data_coor.drop_duplicates()\n",
    "# # data_coor['inn'] = inn\n",
    "# # data_coor['inn1'] = inn1\n",
    "# # data_coor = data_coor.reset_index(drop = True)\n",
    "# # # data_coor = data_coor.set_index(['ter_lat', 'ter_lon'])\n",
    "# # data_coor.head()\n",
    "\n",
    "\n",
    "# data_coor = pd.read_csv('data_coor.csv')\n",
    "# data_coor['i4111'] = inn4111\n",
    "# data_coor['i5261'] = inn5261\n",
    "# data_coor['i5311'] = inn5311\n",
    "# data_coor['i5331'] = inn5331\n",
    "# data_coor['i5499'] = inn5499\n",
    "# data_coor['i5691'] = inn5691\n",
    "# data_coor['i5812'] = inn5812\n",
    "# data_coor['i5912'] = inn5912\n",
    "# data_coor['i5921'] = inn5921\n",
    "# data_coor['i5977'] = inn5977\n",
    "# data_coor['i5999'] = inn5999\n",
    "# data_coor['i6011'] = inn6011\n",
    "# data_coor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_coor.to_csv('data_coor.csv', index=False)\n",
    "\n",
    "data_coor = pd.read_csv('data_coor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(data, data_coor,  how='inner', left_on=['ter_lat', 'ter_lon'], right_on = ['ter_lat', 'ter_lon'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.drop(['wd_home', 'wd_work', 'w_home', 'w_work', 'gw_home', 'gw_work', 'gwd_home', 'gwd_work'], axis = 1, inplace = True)\n",
    "\n",
    "# data_mcc = data[(data.weekend==0)].groupby('mcc')[['is_home', 'is_work']].count()\n",
    "# data_mcc.columns = ['w_home', 'w_work']\n",
    "# data = data.join(data_mcc, on='mcc', rsuffix='_2')  \n",
    "\n",
    "# data_mcc = data[(data.weekend==1)].groupby('mcc')[['is_home', 'is_work']].count()\n",
    "# data_mcc.columns = ['wd_home', 'wd_work']\n",
    "# data = data.join(data_mcc, on='mcc', rsuffix='_2')  \n",
    "\n",
    "# data_mcc = data[(data.weekend==0)].groupby('group')[['is_home', 'is_work']].count()\n",
    "# data_mcc.columns = ['gw_home', 'gw_work']\n",
    "# data = data.join(data_mcc, on='group', rsuffix='_2')  \n",
    "\n",
    "# data_mcc = data[(data.weekend==1)].groupby('group')[['is_home', 'is_work']].count()\n",
    "# data_mcc.columns = ['gwd_home', 'gwd_work']\n",
    "# data = data.join(data_mcc, on='group', rsuffix='_2')\n",
    "# data.drop(['atm_address_lon', 'pos_address_lon'], axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lat = data['home_add_lat'] - data['lat1']\n",
    "# lon = data['home_add_lon'] - data['lon1']\n",
    "# data['is_home1'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "\n",
    "# lat = data['work_add_lat'] - data['lat1']\n",
    "# lon = data['work_add_lon'] - data['lon1']\n",
    "# data['is_work1'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "\n",
    "\n",
    "# lat = data['home_add_lat'] - data['lat2']\n",
    "# lon = data['home_add_lon'] - data['lon2']\n",
    "# data['is_home2'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "\n",
    "# lat = data['work_add_lat'] - data['lat2']\n",
    "# lon = data['work_add_lon'] - data['lon2']\n",
    "# data['is_work2'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "\n",
    "\n",
    "# lat = data['home_add_lat'] - data['lat3']\n",
    "# lon = data['home_add_lon'] - data['lon3']\n",
    "# data['is_home3'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "\n",
    "# lat = data['work_add_lat'] - data['lat3']\n",
    "# lon = data['work_add_lon'] - data['lon3']\n",
    "# data['is_work3'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # data['sssum_w'] = data['is_work1'] + data['is_work2'] + data['is_work3']\n",
    "# # data['sssum_h'] = data['is_home1'] + data['is_home2'] + data['is_home3']\n",
    "\n",
    "# lat = data['home_add_lat'] - data['ter_lat']\n",
    "# lon = data['home_add_lon'] - data['ter_lon']\n",
    "# data['is_home03'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)\n",
    "# lat = data['work_add_lat'] - data['ter_lat']\n",
    "# lon = data['work_add_lon'] - data['ter_lon']\n",
    "# data['is_work03'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)\n",
    "\n",
    "# lat = data['home_add_lat'] - data['lat1']\n",
    "# lon = data['home_add_lon'] - data['lon1']\n",
    "# data['is_home103'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)\n",
    "\n",
    "# lat = data['work_add_lat'] - data['lat1']\n",
    "# lon = data['work_add_lon'] - data['lon1']\n",
    "# data['is_work103'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)\n",
    "\n",
    "\n",
    "# lat = data['home_add_lat'] - data['lat2']\n",
    "# lon = data['home_add_lon'] - data['lon2']\n",
    "# data['is_home203'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)\n",
    "\n",
    "# lat = data['work_add_lat'] - data['lat2']\n",
    "# lon = data['work_add_lon'] - data['lon2']\n",
    "# data['is_work203'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)\n",
    "\n",
    "\n",
    "# lat = data['home_add_lat'] - data['lat3']\n",
    "# lon = data['home_add_lon'] - data['lon3']\n",
    "# data['is_home303'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)\n",
    "\n",
    "# lat = data['work_add_lat'] - data['lat3']\n",
    "# lon = data['work_add_lon'] - data['lon3']\n",
    "# data['is_work303'] = ((np.sqrt((lat ** 2) + (lon ** 2)) <= 0.03)&(np.sqrt((lat ** 2) + (lon ** 2)) > 0.02)).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ishw = data.groupby('customer_id')[['is_work', 'is_home', 'is_work1', 'is_home1', 'is_work2', 'is_home2', 'is_work3', 'is_home3',\\\n",
    "# #                 'is_work03', 'is_home03', 'is_work103', 'is_home103', 'is_work203', 'is_home203', 'is_work303', 'is_home303']].max()\n",
    "# without = pd.DataFrame(data.groupby('customer_id')['is_home'].max())\n",
    "# without.columns = ['without']\n",
    "# data = data.join(without, on='customer_id', rsuffix='_2')  \n",
    "\n",
    "# # ishw = data[(data.is_train==1)].groupby('customer_id')[['is_work', 'is_home', 'is_work1', 'is_home1', 'is_work2', 'is_home2', 'is_work3', 'is_home3']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# without = pd.DataFrame(data[data.is_train==1].groupby('customer_id')[['is_home', 'is_work']].max())\n",
    "\n",
    "# ishw.describe()\n",
    "# data.drop(['is_work', 'is_home', 'is_work1', 'is_home1', 'is_work2', 'is_home2', 'is_work3', 'is_home3', 'without', 'without_2'], axis = 1, inplace = True)\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split \n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# data_ca = data[(data.group != 'Отели и мотели')&(data.mcc != 5542)&(data.group != 'Транспорт')&(data.is_train==1)]\n",
    "\n",
    "# # (data.group != 'Развлечения')\n",
    "\n",
    "# cols = ['amount','currency', 'mcc', 'ter_lat','ter_lon', 'week', 'count', 'weekday', 'month',\\\n",
    "#        'lat1', 'lon1', 'cou1','lat2','lon2','cou2','lat3','lon3','cou3', 'is_home', 'is_work',\\\n",
    "#         'city','country', 'atm_address_lat','pos_address_lat','ratio1', 'tx_cust_addr', 'customer_id']\n",
    "# data_cat = data_ca[cols]\n",
    "# data_cat.shape, data_ca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_cat = data_cat.reset_index()\n",
    "# x_tr,  x_vl = train_test_split(data_cat.customer_id.unique(), random_state=777, test_size=0.25)\n",
    "\n",
    "# data_cat = data_cat.set_index('customer_id')\n",
    "# tr = data_cat.loc[x_tr]\n",
    "# vl = data_cat.loc[x_vl]\n",
    "# tr = tr.reset_index(drop=True)\n",
    "# vl = vl.reset_index(drop=True)\n",
    "# tr.shape, vl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "\n",
    "# # cols = [col for col in tr.columns if 'id' not in col and  'first_prch' not in col and 'date' not in col \\\n",
    "# #         and 'time' not in col and 'target' not in col and 'code' not in col]\n",
    "\n",
    "# # cols = [col for col in tr.columns if col not in ['id', 'first_prch', \\\n",
    "# #     'date', 'code', 'time', 'target', 'level_0', 'index']]\n",
    "\n",
    "# cols = ['amount','currency', 'mcc', 'ter_lat','ter_lon', 'week', 'count', 'weekday', 'month',\\\n",
    "#        'lat1', 'lon1', 'cou1','lat2','lon2','cou2','lat3','lon3','cou3', \\\n",
    "#         'city','country', 'atm_address_lat','pos_address_lat','ratio1', 'tx_cust_addr']\n",
    "\n",
    "# # data_cat_tr = \n",
    "# # data_cat_vl = \n",
    "\n",
    "# # # print(data_cat_tr.shape)\n",
    "\n",
    "# lgb_train = lgb.Dataset(tr[cols] , tr['is_home'])\n",
    "# lgb_eval = lgb.Dataset(vl[cols] , vl['is_home'])\n",
    "\n",
    "# # specify your configurations as a dict\n",
    "# # params = {\n",
    "# #     'task': 'train',\n",
    "# #     'boosting_type': 'gbdt',\n",
    "# #     'objective':'binary',\n",
    "# #     'metric': {'auc'},\n",
    "# #     'verbose': 0\n",
    "# # }\n",
    "\n",
    "# # print(data_cat_tr.shape, tr['target'].shape)\n",
    "# # train\n",
    "# # gbm = lgb.train(params,\n",
    "# #                 lgb_train,\n",
    "# #                 num_boost_round=20,\n",
    "# #                 valid_sets=lgb_eval,\n",
    "# #                 early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params = {'max_depth': 7, \n",
    "#           'min_child_weight': 50, \n",
    "#           'bagging_fraction': 0.1, #0.3\n",
    "#           'feature_fraction': 0.5,   #0.7\n",
    "#           'boosting': 'dart',\n",
    "#           'learning_rate': 0.1,\n",
    "#           'lambda_l2': 3,\n",
    "#           'objective': 'binary',\n",
    "#           'metric': 'auc',\n",
    "#           'data_random_seed': 777\n",
    "#          }\n",
    "\n",
    "# gbm = lgb.train(params,\n",
    "#                 lgb_train,\n",
    "#                 num_boost_round=100,\n",
    "#                 valid_sets=lgb_eval,\n",
    "#                 verbose_eval=10,\n",
    "#                 early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgb_train = lgb.Dataset(tr[cols] , tr['is_work'])\n",
    "# lgb_eval = lgb.Dataset(vl[cols] , vl['is_work'])\n",
    "\n",
    "# params = {'max_depth': 7, \n",
    "#           'min_child_weight': 50, \n",
    "#           'bagging_fraction': 0.1, #0.3\n",
    "#           'feature_fraction': 0.5,   #0.7\n",
    "#           'boosting': 'dart',\n",
    "#           'learning_rate': 0.1,\n",
    "#           'lambda_l2': 3,\n",
    "#           'objective': 'binary',\n",
    "#           'metric': 'auc',\n",
    "#           'data_random_seed': 777\n",
    "#          }\n",
    "\n",
    "# gbm = lgb.train(params,\n",
    "#                 lgb_train,\n",
    "#                 num_boost_round=100,\n",
    "#                 valid_sets=lgb_eval,\n",
    "#                 verbose_eval=10,\n",
    "#                 early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ['lat1','lon1','lat2','lon2','lat3','lon3']:\n",
    "#     data[i] = data[i].apply(lambda x: round(x, 2))\n",
    "# data.head()\n",
    "mccc = pd.DataFrame(data.groupby(['customer_id', 'mcc'])['amount'].count())\n",
    "mccc.columns = ['mcc_cuc_am']\n",
    "mccc = mccc.reset_index()\n",
    "mccc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(data, mccc,  how='inner', left_on=['customer_id', 'mcc'], right_on = ['customer_id', 'mcc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [col for col in data.columns if col.startswith('i') and col not in ['is_train', 'is_home', 'is_work']]\n",
    "for col in cols:\n",
    "    data['mcc_cuc_amii'+col] = data[col] - data['mcc_cuc_am']\n",
    "#     data['ref'+col] = data['mcc_cuc_am']/data[col]\n",
    "data['wonder'] = data['inn']+data['inn1']+data['i4111']+data['i5261']+data['i5311']+data['i5331']+data['i5499']+\\\n",
    "   data['i5691']+data['i5812']+data['i5912']+data['i5921']+data['i5977']+data['i5999']+data['i6011'] - 13*data['mcc_cuc_am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "customers = data.groupby('customer_id')[['ter_lat', 'ter_lon']].agg(['mean', 'median'])\n",
    "customers.columns = ['latme', 'latmed', 'lonme', 'lonmed']\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(customers, on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            if col == 'is_work':\n",
    "                cols = [pred,'ter_lat','ter_lon', 'work_add_lat','work_add_lon']\n",
    "\n",
    "            elif col == 'is_home':\n",
    "                cols = [pred,'ter_lat','ter_lon','home_add_lat','home_add_lon']\n",
    "\n",
    "\n",
    "\n",
    "#             if col in x:\n",
    "#                 cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'ter_lat':'%s:add_lat' % col,\n",
    "                'ter_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret\n",
    "\n",
    "def predict_proba(dt, ys = ['is_home', 'is_work']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict(dt[xs])\n",
    "    somefr = dt.groupby('customer_id').apply(_best).reset_index()\n",
    "    if col == 'is_work':\n",
    "        lat = somefr['work_add_lat'] - somefr['is_work:add_lat']\n",
    "        lon = somefr['work_add_lon'] - somefr['is_work:add_lon']\n",
    "        somefr['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "    elif col == 'is_home':\n",
    "        lat = somefr['home_add_lat'] - somefr['is_home:add_lat']\n",
    "        lon = somefr['home_add_lon'] - somefr['is_home:add_lon']\n",
    "        somefr['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "    return somefr\n",
    "\n",
    "\n",
    "def score(dt, ys = ['is_home', 'is_work']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean\n",
    "\n",
    "params = {'max_depth': 7, \n",
    "          'min_child_weight': 50, #50\n",
    "          'bagging_fraction': 0.3, #0.7\n",
    "          'feature_fraction': 0.7,   #0.7\n",
    "          'boosting': 'dart',\n",
    "          'learning_rate': 0.05,\n",
    "          'lambda_l2': 3,\n",
    "          'objective': 'binary',\n",
    "#           'metric': 'auc',\n",
    "          'data_random_seed': 777\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xs = ['amount','currency', 'mcc', 'ter_lat','ter_lon', 'week', 'count', 'weekday', 'month',\\\n",
    "#        'lat1', 'lon1', 'cou1','lat2','lon2','cou2','lat3','lon3','cou3', 'mass',\\\n",
    "#         'city','country', 'atm_address_lat','pos_address_lat','ratio1', 'tx_cust_addr']\n",
    "xs = [col for col in data.columns if col not in ['address', 'atm_address_lon', 'cat', 'customer_id', 'group',\\\n",
    "    'has_home', 'has_work', 'is_home', 'is_train', 'is_work', 'pos_address_lon', 'transaction_date',\\\n",
    "        'home_add_lat', 'home_add_lon', 'work_add_lat', 'work_add_lon', 'day', 'weekend',\\\n",
    "        'ter_lat_2', 'ter_lat_1', 'ter_lon_2', 'ter_lon_1'] and not col.startswith('mcc_cuc_amiii')]\n",
    "\n",
    "ys = ['is_home', 'is_work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(data.columns)\n",
    "for i in (data[xs].columns):\n",
    "    print(i)\n",
    "# model0 = {\n",
    "#     'is_home': gbm,\n",
    "#     'is_work': gbm,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "data_ca = data[(data.group != 'Отели и мотели')&(data.mcc != 5542)&(data.group != 'Транспорт')]\n",
    "# последовательно обучаем два классификатора\n",
    "for col in ['is_home', 'is_work']:\n",
    "    \n",
    "    #выберем для обучение транзакции только тех клиентов из train, у которых хоть в одной транзакции указано место работы/жительства\n",
    "    cust_train = data_ca[data_ca['is_train'] == 1].groupby('customer_id')[col.replace('is_','has_')].max()\n",
    "    cust_train = cust_train[cust_train > 0].index\n",
    "    \n",
    "    #разобъем train на train/valid для валидации\n",
    "    cust_train, cust_valid = train_test_split(cust_train, test_size = 0.1, shuffle = True, random_state = 2)\n",
    "    print(cust_train.shape, cust_valid.shape)\n",
    "    train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(data_ca, how = 'left')\n",
    "    valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(data_ca, how = 'left')\n",
    "    lgb_train = lgb.Dataset(train[xs] , train[col])\n",
    "    lgb_eval = lgb.Dataset(valid[xs] , valid[col])\n",
    "    print (\"Training:\", col)\n",
    "    model[col] = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=lgb_eval,\n",
    "                verbose_eval=40,\n",
    "                early_stopping_rounds=50)\n",
    "    print (\"Train accuracy:\", score(train, ys = [col]))\n",
    "    print (\"Test accuracy:\", score(valid, ys = [col]))\n",
    "    print ()\n",
    "\n",
    "    \n",
    "# Train accuracy: 0.44998844998845\n",
    "# Test accuracy: 0.44282744282744285\n",
    "\n",
    "# Train accuracy: 0.35339894712748915\n",
    "# Test accuracy: 0.3662551440329218\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(0.441403+0.333333)/2, 0.373875, (0.4276642+0.316872)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cust_test = data_ca[data_ca['is_train'] == 0]['customer_id'].unique()\n",
    "test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(data_ca, how = 'left')\n",
    "test = predict_proba(test)\n",
    "test.rename(columns = {\n",
    "        'customer_id':'_ID_',\n",
    "        'is_home:add_lat': '_HOME_LAT_',\n",
    "        'is_home:add_lon': '_HOME_LON_',\n",
    "        'is_work:add_lat': '_WORK_LAT_',\n",
    "        'is_work:add_lon': '_WORK_LON_'}, inplace = True)\n",
    "test = test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = pd.read_csv('test_set.csv', dtype = dtypes, usecols = usecols_test)\n",
    "submission = pd.DataFrame(test3['customer_id'].unique(), columns = ['_ID_'])\n",
    "\n",
    "\n",
    "# Заполняем пропуски\n",
    "submission = submission.merge(test, how = 'left').fillna(0)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Пишем файл submission\n",
    "submission.to_csv('baseline-very-simple9.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(data_ca, how = 'left')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2 = predict_proba(test)\n",
    "\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "di = {}\n",
    "\n",
    "for i in range(len(xs)):\n",
    "    di[xs[i]] = model['is_home'].feature_importance()[i]\n",
    "def my_plot_importance(booster, figsize, **kwargs): \n",
    "    from matplotlib import pyplot as plt\n",
    "    from xgboost import plot_importance\n",
    "    fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax, **kwargs)\n",
    "%matplotlib inline\n",
    "my_plot_importance(di, (10,20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
