{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Boosters] Raiffeisen Data Cup. Baseline\n",
    "Общий подход:\n",
    "- Добавляем к каждой транзакции столбец: is_work (если транзакция находится в пределах 0.02 от дома клиента)\n",
    "- Добавляем к каждой транзакции столбец: is_home (если транзакция находится в пределах 0.02 от работы клиента)\n",
    "- Обучаем классификатор предсказывающий вероятность (is_home == 1) для транзакции\n",
    "- Обучаем классификатор предсказывающий вероятность (is_work == 1) для транзакции\n",
    "\n",
    "Точность определения местоположения:\n",
    "- для классификатора is_home: ~3x%\n",
    "- для классификатора is_work: ~2x%\n",
    "- общая оценка на Public Leaderboard: ???\n",
    "\n",
    "Примечание\n",
    "* Требуется Python версии 3.5\n",
    "* Требуется библиотека xgboost (для обучения использовалась xgboost версии 0.7.post3)\n",
    "* Требуются файлы: test_set.csv, train_set.csv в одном каталоге с данным скриптом\n",
    "* Требования к памяти: должно работать с 2Гб свободного RAM\n",
    "* Время работы: ~3 минуты (тестировалось на процессоре Intel Core i7-4770)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определим типы колонок для экономии памяти\n",
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "# для экономии памяти будем загружать только часть атрибутов транзакций\n",
    "usecols_train = ['customer_id', 'terminal_id', 'transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon']\n",
    "usecols_test = ['customer_id', 'terminal_id', 'transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем train_set, test_set, соединяем в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set.csv', dtype = dtypes, usecols = usecols_train)\n",
    "train.rename(columns = {'pos_adress_lat': 'pos_address_lat', 'pos_adress_lon': 'pos_address_lon'}, inplace = True)\n",
    "\n",
    "\n",
    "test = pd.read_csv('test_set.csv', dtype = dtypes, usecols = usecols_test)\n",
    "submission = pd.DataFrame(test['customer_id'].unique(), columns = ['_ID_'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['mcc'] = train['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)\n",
    "test['mcc'] = test['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcc_grouped = train.groupby('mcc')['customer_id'].count().sort_values(ascending=False).to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "\n",
    "with open('mcc.csv', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        lst.append(line.strip().split(';'))\n",
    "\n",
    "mcc_codes = pd.DataFrame(lst, columns=['mcc', 'description', 'group'])\n",
    "mcc_codes['mcc'] = mcc_codes.mcc.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mcc_group_codes = mcc_grouped.merge(mcc_codes, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_trans = mcc_group_codes.customer_id.sum()\n",
    "# mcc_group_codes['part'] = mcc_group_codes.customer_id.apply(lambda x: x / all_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['address_lat'] = train['atm_address_lat'].fillna(0) + train['pos_address_lat'].fillna(0)\n",
    "# train['address_lon'] = train['atm_address_lon'].fillna(0) + train['pos_address_lon'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for idx in mcc_group_codes.index:\n",
    "#     current_mcc = mcc_group_codes.get_value(idx, 'mcc')\n",
    "#     all_trans = mcc_group_codes.get_value(idx, 'customer_id')\n",
    "    \n",
    "#     df = train[train.mcc == current_mcc][['address_lat','address_lon', 'home_add_lat', 'home_add_lon']].dropna()\n",
    "#     df['dist'] = ((df.address_lat - df.home_add_lat) ** 2 + (df.address_lon - df.home_add_lon) ** 2) ** 0.5\n",
    "    \n",
    "#     distances = df.dist.values\n",
    "#     mcc_group_codes.set_value(idx, 'percent_near_home', len(distances[distances <= 0.02]) / all_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train.drop(['address_lat','address_lon'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcc</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5411</td>\n",
       "      <td>391635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6011</td>\n",
       "      <td>281885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5814</td>\n",
       "      <td>128771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5812</td>\n",
       "      <td>62407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5499</td>\n",
       "      <td>44703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mcc  customer_id\n",
       "0  5411       391635\n",
       "1  6011       281885\n",
       "2  5814       128771\n",
       "3  5812        62407\n",
       "4  5499        44703"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = train.merge(mcc_group_codes[['mcc', 'part', 'percent_near_home']], how='left')\n",
    "# test = test.merge(mcc_group_codes[['mcc', 'part', 'percent_near_home']], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# соединяем test/train в одном DataFrame\n",
    "train['is_train'] = np.int32(1)\n",
    "test['is_train'] = np.int32(0)\n",
    "dt = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dt['part'] = dt['part'].fillna(-1).astype(np.float64)\n",
    "# dt['percent_near_home'] = dt['percent_near_home'].fillna(-1).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = dt.merge(mcc_codes[['mcc', 'group']], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customer_cars = {x: 0 for x in dt[dt.group == 'Автомобили и транспортные средства']['customer_id'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['has_car'] = dt.group.apply(lambda x: 1 if x in customer_cars else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt.drop(dt[dt.mcc == 5542].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt['group'] = dt['group'].fillna(-1).factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_group = pd.DataFrame(enc.fit_transform(dt[['group']]))\n",
    "del dt['group']\n",
    "dt = pd.concat([dt, encoded_group], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрабатываем дату транзакции и категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['currency'] = dt['currency'].fillna(-1).astype(np.int32)\n",
    "# dt['mcc'] = dt['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)\n",
    "\n",
    "dt_abroad = dt[~dt.country.isin(['RUS', 'RU '])]\n",
    "dt_abroad_dict = {x: 0 for x in dt_abroad.customer_id.unique()}\n",
    "\n",
    "del dt_abroad\n",
    "\n",
    "dt['was_abroad'] = dt.customer_id.apply(lambda x: 1 if x in dt_abroad_dict else 0)\n",
    "\n",
    "dt['country'] = dt['country'].apply(lambda x: 'RUS' if x == 'RU ' else x)\n",
    "dt['country'] = dt['country'].factorize()[0].astype(np.int32)\n",
    "\n",
    "# удаляем транзакции без даты\n",
    "dt.drop(dt[dt['transaction_date'].isnull()].index, axis = 0, inplace = True)\n",
    "dt['transaction_date'] = dt['transaction_date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Города"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('cities.txt', 'w') as f:\n",
    "#     for city in dt['city'].unique():\n",
    "#         if type(city) == float:\n",
    "#             continue\n",
    "#         f.write(city + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def convert_city(city):\n",
    "#     if type(city) == float:\n",
    "#         return city\n",
    "#     elif 'PETER' in city.upper():\n",
    "#         return 'ST PETERBURG'\n",
    "#     elif 'MOSC' in city.upper() or 'MOSK' in city.upper():\n",
    "#         return 'MOSCOW'\n",
    "#     else:\n",
    "#         return city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dt['city'] = dt['city'].apply(lambda x: convert_city(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import reverse_geocoder as rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coords_dict = {}\n",
    "\n",
    "# for coords in dt[['pos_address_lat', 'pos_address_lon']].dropna().values:\n",
    "#     coords = tuple(coords)\n",
    "\n",
    "#     if coords not in coords_dict:\n",
    "#         coords_dict[coords] = rg.search(coords)[0]['admin1'] \n",
    "\n",
    "        \n",
    "# for coords in dt[['atm_address_lat', 'atm_address_lon']].dropna().values:\n",
    "#     coords = tuple(coords)\n",
    "\n",
    "#     if coords not in coords_dict:\n",
    "#         coords_dict[coords] = rg.search(coords)[0]['admin1']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('coords_trans.csv', 'w') as f:\n",
    "#     for coords, place in coords_dict.items():\n",
    "#         f.write(\"{}, {}, {}\\n\".format(coords[0], coords[1], place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_coords = pd.read_csv('coords_trans.csv', names=['lat', 'lon', 'city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coords['city'] = df_coords['city'].apply(lambda x: 'St.-Petersburg' if x == 'Leningrad' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coords_dict = {}\n",
    "\n",
    "for val in df_coords.values:\n",
    "    coords_dict[(val[0], val[1])] = val[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['cities_new'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in dt.index:\n",
    "\n",
    "    pos = dt.get_value(idx, 'pos_address_lat'), dt.get_value(idx, 'pos_address_lon')\n",
    "    if pos in coords_dict:\n",
    "        dt.set_value(idx, 'cities_new', coords_dict[pos])\n",
    "        continue\n",
    "    \n",
    "    atm = tuple((dt.get_value(idx, 'atm_address_lat'), dt.get_value(idx, 'atm_address_lon')))\n",
    "    if atm in coords_dict:\n",
    "        dt.set_value(idx, 'cities_new', coords_dict[atm])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coords_dict_cutted = {}\n",
    "\n",
    "for key, value in coords_dict.items():\n",
    "    coords_dict_cutted[(np.float32(round(key[0], 6)), np.float32(round(key[1], 6)))] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in dt[dt['cities_new'] == ''].index:\n",
    "\n",
    "    pos = dt.get_value(idx, 'pos_address_lat'), dt.get_value(idx, 'pos_address_lon')\n",
    "    if pos in coords_dict_cutted:\n",
    "        dt.set_value(idx, 'cities_new', coords_dict_cutted[pos])\n",
    "        continue\n",
    "    \n",
    "    atm = tuple((dt.get_value(idx, 'atm_address_lat'), dt.get_value(idx, 'atm_address_lon')))\n",
    "    if atm in coords_dict_cutted:\n",
    "        dt.set_value(idx, 'cities_new', coords_dict_cutted[atm])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dt['cities_new'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('left_cities.txt', 'w') as f:\n",
    "#     for c in dt[dt['cities_new'] == '']['city'].dropna().unique():\n",
    "#         f.write(c + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add_dict = {}\n",
    "# counter = 0\n",
    "\n",
    "# for coords in dt[dt['cities_new'] == ''][['pos_address_lat', 'pos_address_lon']].dropna().drop_duplicates().values:\n",
    "#     coords = tuple(coords)\n",
    "#     counter += 1\n",
    "#     if counter % 100 == 0:\n",
    "#         print(counter)\n",
    "    \n",
    "#     if coords not in add_dict:\n",
    "#         add_dict[coords] = rg.search(coords)[0]['admin1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('coords_trans.csv', 'a') as f:\n",
    "#     for coords, place in add_dict_dict.items():\n",
    "#         f.write(\"{}, {}, {}\\n\".format(coords[0], coords[1], place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lst = {}\n",
    "\n",
    "# for coords in dt[['pos_address_lat', 'pos_address_lon']].values:\n",
    "#     try:\n",
    "#         lst.append(rg.search(tuple(coords))['admin1'])\n",
    "#     except:\n",
    "#         lst.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['cities_new'] = dt['cities_new'].apply(lambda x: x[1:].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt['city'] = dt['city'].apply(lambda x: x.upper() if type(x) != float else x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_old_new_cities = {\n",
    "    'MOSKVA': 'MOSCOW',\n",
    "    'MOSCOW': 'MOSCOW',\n",
    "    'MOSKVA G': 'MOSCOW',\n",
    "    'SANKT-PETERBU': 'ST.-PETERSBURG',\n",
    "    'ST PETERSBURG': 'ST.-PETERSBURG',\n",
    "    'ST-PETERSBURG': 'ST.-PETERSBURG',\n",
    "    'SAINT PETERSB': 'ST.-PETERSBURG',\n",
    "    'ST.PETERSBURG': 'ST.-PETERSBURG',\n",
    "    'ST-PETERBURG': 'ST.-PETERSBURG',\n",
    "    'ST PETERBURG': 'ST.-PETERSBURG',\n",
    "    'EKATERINBURG': 'SVERDLOVSK',\n",
    "    'KRASNODAR': 'KRASNODARSKIY',\n",
    "    'NVSIBR': 'NOVOSIBIRSK',\n",
    "    'NOVOSIBIRSK': 'NOVOSIBIRSK',\n",
    "    'OMSK': 'OMSK',\n",
    "    'KAZAN':'TATARSTAN',\n",
    "    'VORONEZH': 'VORONEZJ',\n",
    "    'MO': 'MOSKOVSKAYA',\n",
    "    'PODOLSK': 'MOSKOVSKAYA',\n",
    "    'KRASNOGORSK': 'MOSKOVSKAYA',\n",
    "    'HIMKI': 'MOSKOVSKAYA',\n",
    "    'KOROLEV': 'MOSKOVSKAYA',\n",
    "    'UFA': 'BASHKORTOSTAN',\n",
    "    'ROSTOV-NA-DON': 'ROSTOV',\n",
    "    'CHEREPOVETS': 'VOLOGDA',\n",
    "    'CHEREPOVEC': 'VOLOGDA',\n",
    "    'SEVASTOPOL': \"MISTO SEVASTOPOL'\",\n",
    "    'N NOVGOROD': 'NOVGOROD',\n",
    "    'NIZHNIY NOVGO': 'NOVGOROD',\n",
    "    'N.NOVGOROD': 'NOVGOROD',\n",
    "    'OREL': 'ORJOL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sorted(dt['cities_new'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in dt[dt['cities_new'] == ''].index:\n",
    "\n",
    "    city = dt.get_value(idx, 'city')\n",
    "    if city in map_old_new_cities:\n",
    "        dt.set_value(idx, 'cities_new', map_old_new_cities[city])\n",
    "    else:\n",
    "        dt.set_value(idx, 'cities_new', city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt['city'] = dt['cities_new']\n",
    "del dt['cities_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['city'] = dt['city'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи денег"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pays = dt[['transaction_date', 'amount', 'customer_id']].groupby(['customer_id', 'transaction_date'])['amount'].count().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_pays.rename(columns={'amount': 'num_of_pays'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = dt.merge(df_pays, on=['customer_id', 'transaction_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pays = dt[['transaction_date', 'amount', 'customer_id']].groupby(['customer_id', 'transaction_date'])['amount'].sum().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pays.rename(columns={'amount': 'sum_of_pays'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = dt.merge(df_pays, on=['customer_id', 'transaction_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_pays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи для даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['weekday'] = dt['transaction_date'].dt.weekday.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt['month'] = dt['transaction_date'].dt.month.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt['is_holiday'] = dt['weekday'].apply(lambda x: 1 if x == 5 or x == 6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vacances = [\n",
    "    np.datetime64('2017-02-23'), \n",
    "    np.datetime64('2017-02-24'), \n",
    "    np.datetime64('2017-03-08'),\n",
    "    np.datetime64('2017-05-01'), \n",
    "    np.datetime64('2017-05-08'),\n",
    "    np.datetime64('2017-05-09'),\n",
    "    np.datetime64('2017-06-12'),\n",
    "    np.datetime64('2017-11-06')\n",
    "]\n",
    "\n",
    "dt['is_vacance'] = dt['transaction_date'].apply(lambda x: 1 if x in vacances else 0)\n",
    "dt['is_holiday'] = dt['is_holiday'] + dt['is_vacance']\n",
    "\n",
    "del dt['is_vacance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_length_holiday(day):\n",
    "    \n",
    "    if day in (\n",
    "        np.datetime64('2017-11-06'), \n",
    "        np.datetime64('2017-11-05'),\n",
    "        np.datetime64('2017-11-04'),\n",
    "        np.datetime64('2017-06-12'),\n",
    "        np.datetime64('2017-06-11'),\n",
    "        np.datetime64('2017-06-10'),\n",
    "        np.datetime64('2017-05-01'),\n",
    "        np.datetime64('2017-04-29'),\n",
    "        np.datetime64('2017-04-30'),\n",
    "    ):\n",
    "        return 3\n",
    "    \n",
    "    elif day in (\n",
    "        np.datetime64('2017-05-06'),\n",
    "        np.datetime64('2017-05-07'),\n",
    "        np.datetime64('2017-05-08'),\n",
    "        np.datetime64('2017-05-09'),\n",
    "    ):\n",
    "        return 4\n",
    "    elif day == np.datetime64('2017-03-08'):\n",
    "        return 1\n",
    "    \n",
    "    return 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt['holidays_length'] = dt['transaction_date'].apply(lambda x: set_length_holiday(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приводим адрес транзакции для pos и atm-транзакций к единообразному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atm_df = dt[~dt.atm_address_lon.isnull()].groupby('terminal_id')[['atm_address_lat', 'atm_address_lon']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atm_coords = {}\n",
    "\n",
    "for idx in atm_df.index:\n",
    "    atm_coords[idx] = (atm_df.get_value(idx, 'atm_address_lat'), atm_df.get_value(idx, 'atm_address_lon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del atm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in dt[~dt.atm_address_lon.isnull()].index:\n",
    "    term_id = dt.get_value(idx, 'terminal_id')\n",
    "    dt.set_value(idx, 'atm_address_lat', atm_coords[term_id][0])\n",
    "    dt.set_value(idx, 'atm_address_lon', atm_coords[term_id][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['is_atm'] = (~dt['atm_address_lat'].isnull()).astype(np.int32)\n",
    "dt['is_pos'] = (~dt['pos_address_lat'].isnull()).astype(np.int32)\n",
    "\n",
    "dt['address_lat'] = dt['atm_address_lat'].fillna(0) + dt['pos_address_lat'].fillna(0)\n",
    "dt['address_lon'] = dt['atm_address_lon'].fillna(0) + dt['pos_address_lon'].fillna(0)\n",
    "\n",
    "dt.drop(['atm_address_lat','atm_address_lon','pos_address_lat','pos_address_lon'], axis = 1, inplace = True)\n",
    "\n",
    "# удалим транзакции без адреса\n",
    "dt.drop(dt[((dt['address_lon'] == 0) & (dt['address_lon'] == 0))].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dt['terminal_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем признаки is_home, is_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = dt['home_add_lat'] - dt['address_lat']\n",
    "lon = dt['home_add_lon'] - dt['address_lon']\n",
    "dt['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "dt['has_home'] = (~dt['home_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "lat = dt['work_add_lat'] - dt['address_lat']\n",
    "lon = dt['work_add_lon'] - dt['address_lon']\n",
    "dt['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "dt['has_work'] = (~dt['work_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "dt.drop(['work_add_lat','work_add_lon','home_add_lat','home_add_lon'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем категориальный признак для адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['address'] = dt['address_lat'].apply(lambda x: \"%.02f\" % x) + ';' + dt['address_lon'].apply(lambda x: \"%.02f\" % x)\n",
    "dt['address'] = dt['address'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем несколько абонентских фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# количество транзакций каждого клиента\n",
    "dt = dt.merge(dt.groupby('customer_id')['amount'].count().reset_index(name = 'tx'), how = 'left')\n",
    "dt['tx'] = dt['tx'].astype(np.int32)\n",
    "\n",
    "dt = dt.merge(dt.groupby(['customer_id','address'])['amount'].count().reset_index(name = 'tx_cust_addr'), how = 'left')\n",
    "dt['tx_cust_addr'] = dt['tx_cust_addr'].astype(np.int32)\n",
    "\n",
    "# какая часть транзакций клиента приходится на данный адрес\n",
    "dt['ratio1'] = dt['tx_cust_addr'] / dt['tx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции для оценки точности классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            cols = [pred,'address_lat','address_lon']\n",
    "            if col in x:\n",
    "                cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'address_lat':'%s:add_lat' % col,\n",
    "                'address_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba(dt, ys = ['is_home', 'is_work']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict_proba(dt[xs])[:,1]\n",
    "    return dt.groupby('customer_id').apply(_best).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(dt, ys = ['is_home', 'is_work']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, на которых будем обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([          'amount',             'city',          'country',\n",
       "               'currency',      'customer_id',         'is_train',\n",
       "                    'mcc', 'transaction_date',          'has_car',\n",
       "                        0,                  1,                  2,\n",
       "                        3,                  4,                  5,\n",
       "                        6,                  7,                  8,\n",
       "                        9,                 10,                 11,\n",
       "                       12,                 13,                 14,\n",
       "                       15,                 16,                 17,\n",
       "                       18,                 19,                 20,\n",
       "             'was_abroad',      'num_of_pays',      'sum_of_pays',\n",
       "                'weekday',            'month',       'is_holiday',\n",
       "        'holidays_length',           'is_atm',           'is_pos',\n",
       "            'address_lat',      'address_lon',          'is_home',\n",
       "               'has_home',          'is_work',         'has_work',\n",
       "                'address',               'tx',     'tx_cust_addr',\n",
       "                 'ratio1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = list(set(dt.columns) - set(['is_atm', 'is_pos', 'address_lat', 'address_lon', 'is_home', 'has_home',\n",
    "       'is_work', 'has_work', 'address', 'tx', 'tx_cust_addr', 'transaction_date',\n",
    "                                'customer_id']))\n",
    "\n",
    "# ['amount','currency','city', 'country', 'mcc','is_atm',\n",
    "#       'is_pos','ratio1', 'weekday', 'is_holiday', 'was_abroad',\n",
    "#      'is_vacance'\n",
    "#      'num_of_pays', 'sum_of_pays',\n",
    "#       'holidays_length', 'month',\n",
    "#       'group'\n",
    "#       'part', 'percent_near_home'\n",
    "#      ]\n",
    "ys = ['is_home', 'is_work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 'has_car',\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 'ratio1',\n",
       " 'sum_of_pays',\n",
       " 'is_holiday',\n",
       " 'weekday',\n",
       " 'was_abroad',\n",
       " 'city',\n",
       " 'amount',\n",
       " 'mcc',\n",
       " 'num_of_pays',\n",
       " 'country',\n",
       " 'currency',\n",
       " 'is_train',\n",
       " 'month',\n",
       " 'holidays_length']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем классификаторы\n",
    "**Hint**: можно поигратьcя с гиперпараметрами для лучшего результата :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0 = {\n",
    "    'is_home': xgb.XGBClassifier(n_estimators = 300, n_jobs = 3),\n",
    "    'is_work': xgb.XGBClassifier(n_estimators = 300, n_jobs = 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: is_home\n",
      "[0]\tvalidation_0-logloss:0.660289\tvalidation_1-logloss:0.658774\n",
      "[10]\tvalidation_0-logloss:0.523509\tvalidation_1-logloss:0.516517\n",
      "[20]\tvalidation_0-logloss:0.495826\tvalidation_1-logloss:0.488683\n",
      "[30]\tvalidation_0-logloss:0.486924\tvalidation_1-logloss:0.479656\n",
      "[40]\tvalidation_0-logloss:0.482567\tvalidation_1-logloss:0.475493\n",
      "[50]\tvalidation_0-logloss:0.479972\tvalidation_1-logloss:0.472878\n",
      "[60]\tvalidation_0-logloss:0.477583\tvalidation_1-logloss:0.470726\n",
      "[70]\tvalidation_0-logloss:0.475585\tvalidation_1-logloss:0.469196\n",
      "[80]\tvalidation_0-logloss:0.474339\tvalidation_1-logloss:0.46875\n",
      "[90]\tvalidation_0-logloss:0.472966\tvalidation_1-logloss:0.467723\n",
      "[100]\tvalidation_0-logloss:0.471905\tvalidation_1-logloss:0.46703\n",
      "[110]\tvalidation_0-logloss:0.471126\tvalidation_1-logloss:0.466606\n",
      "[120]\tvalidation_0-logloss:0.470241\tvalidation_1-logloss:0.465815\n",
      "[130]\tvalidation_0-logloss:0.469324\tvalidation_1-logloss:0.465695\n",
      "[140]\tvalidation_0-logloss:0.46838\tvalidation_1-logloss:0.465333\n",
      "[150]\tvalidation_0-logloss:0.467439\tvalidation_1-logloss:0.464579\n",
      "[160]\tvalidation_0-logloss:0.466399\tvalidation_1-logloss:0.463987\n",
      "[170]\tvalidation_0-logloss:0.465845\tvalidation_1-logloss:0.464029\n",
      "[180]\tvalidation_0-logloss:0.465171\tvalidation_1-logloss:0.46405\n",
      "[190]\tvalidation_0-logloss:0.464488\tvalidation_1-logloss:0.463796\n",
      "[200]\tvalidation_0-logloss:0.463577\tvalidation_1-logloss:0.463523\n",
      "[210]\tvalidation_0-logloss:0.463092\tvalidation_1-logloss:0.463456\n",
      "[220]\tvalidation_0-logloss:0.462532\tvalidation_1-logloss:0.463228\n",
      "[230]\tvalidation_0-logloss:0.461929\tvalidation_1-logloss:0.463197\n",
      "[240]\tvalidation_0-logloss:0.461504\tvalidation_1-logloss:0.4631\n",
      "[250]\tvalidation_0-logloss:0.46076\tvalidation_1-logloss:0.463186\n",
      "[260]\tvalidation_0-logloss:0.46031\tvalidation_1-logloss:0.463337\n",
      "[270]\tvalidation_0-logloss:0.459848\tvalidation_1-logloss:0.463603\n",
      "[280]\tvalidation_0-logloss:0.459398\tvalidation_1-logloss:0.4634\n",
      "[290]\tvalidation_0-logloss:0.458867\tvalidation_1-logloss:0.463443\n",
      "[299]\tvalidation_0-logloss:0.45833\tvalidation_1-logloss:0.46343\n",
      "Train accuracy: 0.398\n",
      "Test accuracy: 0.388\n",
      "\n",
      "Training: is_work\n",
      "[0]\tvalidation_0-logloss:0.648076\tvalidation_1-logloss:0.648516\n",
      "[10]\tvalidation_0-logloss:0.458305\tvalidation_1-logloss:0.459095\n",
      "[20]\tvalidation_0-logloss:0.417648\tvalidation_1-logloss:0.419965\n",
      "[30]\tvalidation_0-logloss:0.405415\tvalidation_1-logloss:0.409471\n",
      "[40]\tvalidation_0-logloss:0.399974\tvalidation_1-logloss:0.405998\n",
      "[50]\tvalidation_0-logloss:0.396932\tvalidation_1-logloss:0.405108\n",
      "[60]\tvalidation_0-logloss:0.394169\tvalidation_1-logloss:0.405236\n",
      "[70]\tvalidation_0-logloss:0.392197\tvalidation_1-logloss:0.40501\n",
      "[80]\tvalidation_0-logloss:0.390419\tvalidation_1-logloss:0.404683\n",
      "[90]\tvalidation_0-logloss:0.388658\tvalidation_1-logloss:0.404649\n",
      "[100]\tvalidation_0-logloss:0.387263\tvalidation_1-logloss:0.404562\n",
      "[110]\tvalidation_0-logloss:0.386231\tvalidation_1-logloss:0.40427\n",
      "[120]\tvalidation_0-logloss:0.384722\tvalidation_1-logloss:0.404771\n",
      "[130]\tvalidation_0-logloss:0.38384\tvalidation_1-logloss:0.405043\n",
      "[140]\tvalidation_0-logloss:0.382599\tvalidation_1-logloss:0.405879\n",
      "[150]\tvalidation_0-logloss:0.381503\tvalidation_1-logloss:0.405864\n",
      "[160]\tvalidation_0-logloss:0.380528\tvalidation_1-logloss:0.406317\n",
      "[170]\tvalidation_0-logloss:0.379688\tvalidation_1-logloss:0.406051\n",
      "[180]\tvalidation_0-logloss:0.378439\tvalidation_1-logloss:0.406697\n",
      "[190]\tvalidation_0-logloss:0.377566\tvalidation_1-logloss:0.406538\n",
      "[200]\tvalidation_0-logloss:0.376589\tvalidation_1-logloss:0.40667\n",
      "[210]\tvalidation_0-logloss:0.375235\tvalidation_1-logloss:0.407242\n",
      "[220]\tvalidation_0-logloss:0.374261\tvalidation_1-logloss:0.407525\n",
      "[230]\tvalidation_0-logloss:0.373172\tvalidation_1-logloss:0.407963\n",
      "[240]\tvalidation_0-logloss:0.371832\tvalidation_1-logloss:0.409515\n",
      "[250]\tvalidation_0-logloss:0.371071\tvalidation_1-logloss:0.409958\n",
      "[260]\tvalidation_0-logloss:0.369787\tvalidation_1-logloss:0.410354\n",
      "[270]\tvalidation_0-logloss:0.369232\tvalidation_1-logloss:0.410797\n",
      "[280]\tvalidation_0-logloss:0.36863\tvalidation_1-logloss:0.410432\n",
      "[290]\tvalidation_0-logloss:0.368159\tvalidation_1-logloss:0.410272\n",
      "[299]\tvalidation_0-logloss:0.366751\tvalidation_1-logloss:0.411002\n",
      "Train accuracy: 0.279405428695\n",
      "Test accuracy: 0.257751937984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "\n",
    "# последовательно обучаем два классификатора\n",
    "for col in ['is_home', 'is_work']:\n",
    "    \n",
    "    #выберем для обучение транзакции только тех клиентов из train, у которых хоть в одной транзакции указано место работы/жительства\n",
    "    cust_train = dt[dt['is_train'] == 1].groupby('customer_id')[col.replace('is_','has_')].max()\n",
    "    cust_train = cust_train[cust_train > 0].index\n",
    "    \n",
    "    #разобъем train на train/valid для валидации\n",
    "    cust_train, cust_valid = train_test_split(cust_train, test_size = 0.1, shuffle = True, random_state = 2)\n",
    "    \n",
    "    train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "    valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "\n",
    "    print (\"Training:\", col)\n",
    "    clf = sklearn.base.clone(model0[col])\n",
    "    clf.fit(train[xs], train[col], eval_metric = 'logloss', eval_set = [(train[xs], train[col]), (valid[xs], valid[col])], verbose=10)\n",
    "    model[col] = clf\n",
    "    print (\"Train accuracy:\", score(train, ys = [col]))\n",
    "    print (\"Test accuracy:\", score(valid, ys = [col]))\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cust_test = dt[dt['is_train'] == 0]['customer_id'].unique()\n",
    "test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "test = predict_proba(test)\n",
    "test.rename(columns = {\n",
    "        'customer_id':'_ID_',\n",
    "        'is_home:add_lat': '_HOME_LAT_',\n",
    "        'is_home:add_lon': '_HOME_LON_',\n",
    "        'is_work:add_lat': '_WORK_LAT_',\n",
    "        'is_work:add_lon': '_WORK_LON_'}, inplace = True)\n",
    "test = test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем submission-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Заполняем пропуски\n",
    "submission = submission.merge(test, how = 'left').fillna(0)\n",
    "\n",
    "# Пишем файл submission\n",
    "submission.to_csv('baseline-very-simple.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_'], dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_ID_</th>\n",
       "      <th>_WORK_LAT_</th>\n",
       "      <th>_WORK_LON_</th>\n",
       "      <th>_HOME_LAT_</th>\n",
       "      <th>_HOME_LON_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_ID_, _WORK_LAT_, _WORK_LON_, _HOME_LAT_, _HOME_LON_]\n",
       "Index: []"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission._WORK_LAT_ == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_submit(path_to_csv):\n",
    "    \"\"\"\n",
    "    Dummy checking of submission\n",
    "    \n",
    "    :param path_to_csv: path to your submission file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path_to_csv)\n",
    "    assert df.shape == (9997, 5), u'Мало или много строк'\n",
    "    # несмотря на то, что названия не имеют особого значения, правильный порядк колонок позволит не запутаться в широте-долготе\n",
    "    assert list(df.columns) == ['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_'], u'Неверные названия столбцов'\n",
    "    assert np.any(df['_ID_'].duplicated()) == False, u'Одному клиенту соответствует больше одной записи'\n",
    "    for col_name in df.columns:\n",
    "        if col_name != '_ID_':\n",
    "            assert df[col_name].dtype in (np.float, np.int), u'В колонке {col_name} есть NULL'.format(col_name=col_name)\n",
    "        assert df[col_name].isnull().sum() == 0, u'В колонке {col_name} есть NULL'.format(col_name=col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_submit('baseline-very-simple.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
