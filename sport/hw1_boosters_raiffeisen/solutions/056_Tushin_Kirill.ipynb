{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:40:52.646960Z",
     "start_time": "2018-03-24T15:40:47.415545Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas(desc='apply')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:40:52.756145Z",
     "start_time": "2018-03-24T15:40:52.648080Z"
    },
    "code_folding": [
     0,
     7,
     15,
     26,
     45
    ]
   },
   "outputs": [],
   "source": [
    "def dist(data , lat1 , lat2 , lon1 , lon2):\n",
    "    return np.sqrt((data[lat1] - data[lat2]) ** 2 + (data[lon1] - data[lon2]) ** 2)\n",
    "\n",
    "def dist_from_series(lat1 , lat2 , lon1 , lon2):\n",
    "    return np.sqrt((lat1 - lat2) ** 2 + (lon1 - lon2) ** 2)\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    'n_estimators':100, \n",
    "    'subsample':0.7,\n",
    "    'random_state':42,\n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "def get_columns(data):\n",
    "    to_drop = ['target_home', 'target_work', 'customer_id', 'transaction_date',\n",
    "               'home_add_lat','home_add_lon','work_add_lat','work_add_lon', \n",
    "               'address_lat' , 'address_lon' , 'address']\n",
    "    columns = list(set(data.columns) - set(to_drop) - set(data.dtypes[data.dtypes == object].keys()))\n",
    "    return columns\n",
    "\n",
    "def predict(model , data , columns , target):\n",
    "    data = data.copy()\n",
    "    data['predict_' + target] = model.predict_proba(data[columns])[:,1]\n",
    "    tmp = data.groupby(['customer_id' , 'address_lat' , 'address_lon'])[['predict_' + target]].max()\n",
    "    tmp = tmp.groupby(['customer_id']).idxmax()['predict_' + target].values\n",
    "    predict = pd.DataFrame(tmp.tolist() , columns=['customer_id' , target + '_predict_lat' ,  target + '_predict_lon'])\n",
    "    return predict\n",
    "\n",
    "def get_good_data_for_valid(data):\n",
    "    data = data.copy()\n",
    "    columns = get_columns(data)\n",
    "    \n",
    "    data = data[data['home' + '_add_lat'].notnull() & data['work' + '_add_lat'].notnull()]\n",
    "    data = data[data['address_lat'].notnull()]\n",
    "    return data , columns\n",
    "\n",
    "def validate_for_target(data , columns , cv):\n",
    "    res = []\n",
    "    \n",
    "    for train_index , valid_index in tqdm_notebook(cv.split(X = data , groups=data['customer_id']) , total = cv.n_splits):\n",
    "        x_tr , x_vl = data.iloc[train_index] , data.iloc[valid_index]\n",
    "        \n",
    "        res_for_fold = 0\n",
    "        for target in ['home' , 'work']:\n",
    "            lgbm = LGBMClassifier(**model_params)\n",
    "            lgbm.fit(x_tr[columns] , x_tr['target_' + target])\n",
    "            predict_data = predict(lgbm , x_vl , columns , target)\n",
    "\n",
    "            real_answer = x_vl.groupby(['customer_id'] , as_index=False)[target + '_add_lat',target + '_add_lon'].mean()\n",
    "            in_radius = dist_from_series(real_answer[target + '_add_lat'] , predict_data[target + '_predict_lat'] ,\n",
    "                                         real_answer[target + '_add_lon'] , predict_data[target + '_predict_lon']) < 0.02\n",
    "            res_for_fold += in_radius.mean()\n",
    "        res.append(res_for_fold/2)\n",
    "    return np.array(res)\n",
    "\n",
    "def valid(data , n_splits = 5):\n",
    "    data , columns = get_good_data_for_valid(data)\n",
    "    k_fold = GroupKFold(n_splits = n_splits)\n",
    "    res = validate_for_target(data  , columns,  k_fold)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:00.108039Z",
     "start_time": "2018-03-24T15:40:52.757328Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_set.csv').rename(columns={\"pos_adress_lat\": \"pos_address_lat\",\"pos_adress_lon\": \"pos_address_lon\"})\n",
    "test = pd.read_csv('data/test_set.csv')\n",
    "sample = pd.read_csv('data/sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:03.215406Z",
     "start_time": "2018-03-24T15:41:00.109265Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train = train[train.work_add_lat.notnull() | train.home_add_lat.notnull()]\n",
    "train['is_train'] = 1\n",
    "test['mcc'] = test['mcc'].apply(lambda x: str(x).replace(',', '')).astype(np.int32)\n",
    "\n",
    "all_data = pd.concat([train , test])\n",
    "\n",
    "all_data['is_atm'] = all_data['atm_address_lat'].notnull().astype('int8')\n",
    "all_data['is_pos'] = all_data['pos_address_lat'].notnull().astype('int8')\n",
    "\n",
    "all_data['address_lat'] = all_data['atm_address_lat'].fillna(0) + all_data['pos_address_lat'].fillna(0)\n",
    "all_data['address_lon'] = all_data['atm_address_lon'].fillna(0) + all_data['pos_address_lon'].fillna(0)\n",
    "all_data['address'] = all_data['atm_address'].fillna('') + all_data['pos_address'].fillna('')\n",
    "\n",
    "all_data.drop(['atm_address_lat', 'atm_address_lon', 'atm_address',\n",
    "                  'pos_address_lat', 'pos_address_lon', 'pos_address'] , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:06.896754Z",
     "start_time": "2018-03-24T15:41:03.216899Z"
    }
   },
   "outputs": [],
   "source": [
    "good_terminal = all_data.groupby('terminal_id' , as_index=False)['address_lat','address_lon']\n",
    "all_data = pd.merge(all_data , good_terminal.mean() , on='terminal_id' , how='left' , suffixes=('_old',''))\n",
    "all_data = pd.merge(all_data , good_terminal.count()[['terminal_id', 'address_lat']] , on='terminal_id' , how='left' , suffixes=('','_count'))\n",
    "\n",
    "all_data.drop(['address_lat_old' , 'address_lon_old'] , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:07.437351Z",
     "start_time": "2018-03-24T15:41:06.898250Z"
    }
   },
   "outputs": [],
   "source": [
    "train = all_data[all_data['is_train'].notnull()]\n",
    "test = all_data[all_data['is_train'].isnull()]\n",
    "train['target_home'] = (dist(train , 'home_add_lat' , 'address_lat' , 'home_add_lon' , 'address_lon') < 0.02).astype('int8')\n",
    "train['target_work'] = (dist(train , 'work_add_lat' , 'address_lat' , 'work_add_lon' , 'address_lon') < 0.02).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:11.389836Z",
     "start_time": "2018-03-24T15:41:11.364577Z"
    }
   },
   "outputs": [],
   "source": [
    "russian_word = 'АБВГДЕЁЖЗИКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯабвгдеёжзиклмнопрстуфхцчшщъыьэюя'\n",
    "number = '0123456789'\n",
    "street = ['ul' , 'ул' , 'st' , 'pr-']\n",
    "build = ['d' , 'д' , 'bld']\n",
    "\n",
    "def count_number(row):\n",
    "    res = 0\n",
    "    for x in number:\n",
    "        res += row.count(x)\n",
    "    return res\n",
    "\n",
    "def count_russian_letter(row):\n",
    "    res = 0\n",
    "    for x in russian_word:\n",
    "        res += row.count(x)\n",
    "    return res\n",
    "\n",
    "def count_street_letter(row):\n",
    "    res = 0\n",
    "    for x in street:\n",
    "        res += row.count(x)\n",
    "    return res\n",
    "\n",
    "def count_build_letter(row):\n",
    "    res = 0\n",
    "    for x in build:\n",
    "        res += row.count(x)\n",
    "    return res\n",
    "\n",
    "def count_isupper(row):\n",
    "    res = 0\n",
    "    for x in row:\n",
    "        res += x.isupper()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:54.670677Z",
     "start_time": "2018-03-24T15:41:11.803618Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train , test])\n",
    "all_data.drop('is_train' , axis=1 , inplace=True)\n",
    "all_data['address'] = all_data['address'].astype(str)\n",
    "all_data['len_address'] = all_data['address'].apply(len)\n",
    "all_data['gap_count_address'] = all_data['address'].apply(lambda x: x.count(' '))\n",
    "all_data['._count_address'] = all_data['address'].apply(lambda x: x.count('.'))\n",
    "all_data[',_count_address'] = all_data['address'].apply(lambda x: x.count(','))\n",
    "all_data['/_count_address'] = all_data['address'].apply(lambda x: x.count('/'))\n",
    "all_data['\\_count_address'] = all_data['address'].apply(lambda x: x.count('\\''))\n",
    "all_data['count_number_address'] = all_data['address'].apply(count_number)\n",
    "all_data['count_russian_word_address'] = all_data['address'].apply(count_russian_letter)\n",
    "all_data['count_isupper_address'] = all_data['address'].apply(count_isupper)\n",
    "all_data['count_ul_in_address'] = all_data['address'].apply(count_street_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:56.013013Z",
     "start_time": "2018-03-24T15:41:54.671849Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data['transaction_date'] = pd.to_datetime(all_data['transaction_date'])\n",
    "all_data['transaction_date'] = all_data[['transaction_date']].fillna(all_data['transaction_date'].min())\n",
    "\n",
    "all_data['month'] = all_data['transaction_date'].dt.month.astype('int8')\n",
    "all_data['week'] = all_data['transaction_date'].dt.week.astype('int8')\n",
    "all_data['day'] = all_data['transaction_date'].dt.day.astype('int8')\n",
    "all_data['day_of_week'] = all_data['transaction_date'].dt.dayofweek.astype('int8')\n",
    "all_data['day_of_year'] = all_data['transaction_date'].dt.dayofyear.astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:57.863808Z",
     "start_time": "2018-03-24T15:41:56.014101Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = all_data.groupby(['customer_id'])['address_lat' , 'address_lon'].median().reset_index()\n",
    "all_data = pd.merge(all_data , tmp , on=['customer_id'] , how='left' , suffixes=('' , '_median'))\n",
    "all_data['dist_to_median'] = dist(all_data , 'address_lat' , 'address_lat_median',\n",
    "                                             'address_lon' , 'address_lon_median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:41:58.737119Z",
     "start_time": "2018-03-24T15:41:57.865026Z"
    }
   },
   "outputs": [],
   "source": [
    "count , diff = np.histogram(all_data.amount , 5)\n",
    "all_data['amount_cat'] = 0\n",
    "for i in range(len(diff) - 1):\n",
    "    all_data.loc[(all_data['amount'] > diff[i]) & (all_data['amount'] < diff[i+1]) , 'amount_cat'] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance to median group by categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:42:53.479939Z",
     "start_time": "2018-03-24T15:42:21.975155Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106d476a8342492da49bb0e2d6d7847b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm_notebook(['month' , 'week' , 'day' , 'day_of_week' , 'mcc' , 'len_address' ,  'address_lat_count' , \n",
    "                         'amount_cat']):\n",
    "    tmp = all_data.groupby(['customer_id' , col])['address_lat' , 'address_lon'].median().reset_index()\n",
    "    all_data = pd.merge(all_data , tmp , on=['customer_id' , col] , how='left' , suffixes=('' , '_median_' + col))\n",
    "    all_data['dist_to_' + col] = dist(all_data , 'address_lat' , 'address_lat_median_' + col,\n",
    "                                                           'address_lon' , 'address_lon_median_' + col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:42:53.686425Z",
     "start_time": "2018-03-24T15:42:53.481198Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data['city_enc'] = all_data['city'].factorize()[0]\n",
    "all_data['country'] = all_data['country'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:44:37.812350Z",
     "start_time": "2018-03-24T15:42:53.687552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e09a2fb5854ed1a9f5055f4aac213c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.37853677471259173 0.01056588179690113\n"
     ]
    }
   ],
   "source": [
    "train = all_data[all_data['target_home'].notnull()]\n",
    "score = valid(train)\n",
    "print (score.mean() , score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:44:38.241864Z",
     "start_time": "2018-03-24T15:44:37.814574Z"
    }
   },
   "outputs": [],
   "source": [
    "test = all_data[all_data['target_home'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:45:19.121289Z",
     "start_time": "2018-03-24T15:44:38.243428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 34s, sys: 2.05 s, total: 4min 36s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "columns = get_columns(train)\n",
    "    \n",
    "model_home = LGBMClassifier(**model_params).fit(train[columns] , train['target_home'])\n",
    "model_work = LGBMClassifier(**model_params).fit(train[columns] , train['target_work'])\n",
    "\n",
    "model = {'home':model_home , 'work':model_work}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-24T15:45:35.783434Z",
     "start_time": "2018-03-24T15:45:19.122775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.9 s, sys: 2.36 s, total: 39.2 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict_test = pd.merge(predict(model['work'] , test , columns , 'work') , predict(model['home'] , test , columns , 'home') , on='customer_id' , how='left')\n",
    "predict_test.columns = sample.columns\n",
    "predict_test.replace({0 : np.nan} , inplace=True)\n",
    "predict_test.fillna(predict_test.median() , inplace=True)\n",
    "predict_test.to_csv('predict_good.csv' , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
