{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Boosters] Raiffeisen Data Cup. Baseline\n",
    "Общий подход:\n",
    "- Добавляем к каждой транзакции столбец: is_work (если транзакция находится в пределах 0.02 от дома клиента)\n",
    "- Добавляем к каждой транзакции столбец: is_home (если транзакция находится в пределах 0.02 от работы клиента)\n",
    "- Обучаем классификатор предсказывающий вероятность (is_home == 1) для транзакции\n",
    "- Обучаем классификатор предсказывающий вероятность (is_work == 1) для транзакции\n",
    "\n",
    "Примечание\n",
    "* Требуется Python версии 3.5\n",
    "* Требуется библиотека xgboost (для обучения использовалась xgboost версии 0.7.post3)\n",
    "* Требуются файлы: test_set.csv, train_set.csv в одном каталоге с данным скриптом\n",
    "* Требования к памяти: должно работать с 2Гб свободного RAM\n",
    "* Время работы: ~3 минуты (тестировалось на процессоре Intel Core i7-4770)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pycountry\n",
    "\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим типы колонок для экономии памяти\n",
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "}\n",
    "\n",
    "# для экономии памяти будем загружать только часть атрибутов транзакций\n",
    "usecols_train = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon']\n",
    "usecols_test = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем train_set, test_set, соединяем в один датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set.csv', dtype = dtypes, usecols = usecols_train)\n",
    "train.rename(columns = {'pos_adress_lat': 'pos_address_lat', 'pos_adress_lon': 'pos_address_lon'}, inplace = True)\n",
    "\n",
    "test = pd.read_csv('test_set.csv', dtype = dtypes, usecols = usecols_test)\n",
    "submission = pd.DataFrame(test['customer_id'].unique(), columns = ['_ID_'])\n",
    "\n",
    "# соединяем test/train в одном DataFrame\n",
    "train['is_train'] = np.int32(1)\n",
    "test['is_train'] = np.int32(0)\n",
    "dt = pd.concat([train, test])\n",
    "\n",
    "del train, test\n",
    "\n",
    "# дропнем транзакции без даты\n",
    "\n",
    "dt.drop(dt[dt['transaction_date'].isnull()].index, axis = 0, inplace = True)\n",
    "\n",
    "dt['transaction_date'] = dt['transaction_date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "# код страны\n",
    "dt.loc[dt['country'] == 'ROM', 'country'] = 'ROU'\n",
    "dt['country'] = dt['country'].str.strip();\n",
    "dt.loc[dt['country'].str.len()==3, 'country'] = [pycountry.countries.get(alpha_3=alpha_3).alpha_2 for alpha_3 in dt[dt['country'].str.len()==3]['country']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['currency'] = dt['currency'].fillna(-1).astype(np.int32)\n",
    "dt['mcc'] = dt['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)\n",
    "dt['city'] = dt['city'].factorize()[0].astype(np.int32)\n",
    "dt['country'] = dt['country'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи для даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['weekday'] = dt['transaction_date'].dt.weekday.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приводим адрес транзакции для pos и atm-транзакций к единообразному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['is_atm'] = (~dt['atm_address_lat'].isnull()).astype(np.int32)\n",
    "dt['is_pos'] = (~dt['pos_address_lat'].isnull()).astype(np.int32)\n",
    "\n",
    "dt['address_lat'] = dt['atm_address_lat'].fillna(0) + dt['pos_address_lat'].fillna(0)\n",
    "dt['address_lon'] = dt['atm_address_lon'].fillna(0) + dt['pos_address_lon'].fillna(0)\n",
    "\n",
    "dt.drop(['atm_address_lat','atm_address_lon','pos_address_lat','pos_address_lon'], axis = 1, inplace = True)\n",
    "\n",
    "# удалим транзакции без адреса\n",
    "dt.drop(dt[((dt['address_lon'] == 0) & (dt['address_lon'] == 0))].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем признаки is_home, is_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = dt['home_add_lat'] - dt['address_lat']\n",
    "lon = dt['home_add_lon'] - dt['address_lon']\n",
    "dt['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "dt['has_home'] = (~dt['home_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "lat = dt['work_add_lat'] - dt['address_lat']\n",
    "lon = dt['work_add_lon'] - dt['address_lon']\n",
    "dt['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.02).astype(np.int32)\n",
    "dt['has_work'] = (~dt['work_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "dt.drop(['work_add_lat','work_add_lon','home_add_lat','home_add_lon'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем категориальный признак для адреса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['address'] = dt['address_lat'].apply(lambda x: \"%.02f\" % x) + ';' + dt['address_lon'].apply(lambda x: \"%.02f\" % x)\n",
    "dt['address'] = dt['address'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем несколько абонентских фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество транзакций каждого клиента\n",
    "dt = dt.merge(dt.groupby('customer_id')['amount'].count().reset_index(name = 'tx'), how = 'left')\n",
    "dt['tx'] = dt['tx'].astype(np.int32)\n",
    "\n",
    "dt = dt.merge(dt.groupby(['customer_id','address'])['amount'].count().reset_index(name = 'tx_cust_addr'), how = 'left')\n",
    "dt['tx_cust_addr'] = dt['tx_cust_addr'].astype(np.int32)\n",
    "\n",
    "# какая часть транзакций клиента приходится на данный адрес\n",
    "dt['ratio1'] = dt['tx_cust_addr'] / dt['tx']\n",
    "\n",
    "week = ['2017-01-02', '2017-01-03', '2017-01-04', '2017-01-05', '2017-01-06', '2017-02-23', '2017-02-24', '2017-03-08', '2017-05-01', '2017-05-08', '2017-05-09', '2017-06-12', '2017-11-06']\n",
    "dt['is_weekend'] = ((dt[\"weekday\"] >= 5) | dt['transaction_date'].isin(week)).astype(np.int32)\n",
    "dt = dt.merge(dt.groupby(['customer_id','address', 'is_weekend'])['amount'].count().reset_index(name = 'tx_cust_addr1'), how = 'left')\n",
    "\n",
    "dt['ratio2'] = dt['tx_cust_addr1'] / dt['tx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции для оценки точности классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            cols = [pred,'address_lat','address_lon']\n",
    "            if col in x:\n",
    "                cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'address_lat':'%s:add_lat' % col,\n",
    "                'address_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(dt, ys = ['is_home', 'is_work']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict_proba(dt[xs])[:,1]\n",
    "    return dt.groupby('customer_id').apply(_best).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(dt, ys = ['is_home', 'is_work']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, на которых будем обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = ['amount','currency','city','country','mcc','is_atm','is_pos','ratio1', 'ratio2', 'weekday']\n",
    "ys = ['is_home', 'is_work']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем классификаторы\n",
    "**Hint**: можно поигратьcя с гиперпараметрами для лучшего результата :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = {\n",
    "    'is_home': xgb.XGBClassifier(n_estimators = 100, n_jobs = 3),\n",
    "    'is_work': xgb.XGBClassifier(n_estimators = 100, n_jobs = 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: is_home\n",
      "[0]\tvalidation_0-logloss:0.659862\tvalidation_1-logloss:0.658395\n",
      "[10]\tvalidation_0-logloss:0.521808\tvalidation_1-logloss:0.513466\n",
      "[20]\tvalidation_0-logloss:0.49477\tvalidation_1-logloss:0.485612\n",
      "[30]\tvalidation_0-logloss:0.485602\tvalidation_1-logloss:0.476353\n",
      "[40]\tvalidation_0-logloss:0.48148\tvalidation_1-logloss:0.472359\n",
      "[50]\tvalidation_0-logloss:0.478444\tvalidation_1-logloss:0.469833\n",
      "[60]\tvalidation_0-logloss:0.476448\tvalidation_1-logloss:0.4684\n",
      "[70]\tvalidation_0-logloss:0.475031\tvalidation_1-logloss:0.467808\n",
      "[80]\tvalidation_0-logloss:0.474002\tvalidation_1-logloss:0.467321\n",
      "[90]\tvalidation_0-logloss:0.472874\tvalidation_1-logloss:0.466792\n",
      "[99]\tvalidation_0-logloss:0.472208\tvalidation_1-logloss:0.466377\n",
      "Train accuracy: 0.37755555555555553\n",
      "Test accuracy: 0.376\n",
      "\n",
      "Training: is_work\n",
      "[0]\tvalidation_0-logloss:0.64737\tvalidation_1-logloss:0.647619\n",
      "[10]\tvalidation_0-logloss:0.455334\tvalidation_1-logloss:0.45538\n",
      "[20]\tvalidation_0-logloss:0.415618\tvalidation_1-logloss:0.414451\n",
      "[30]\tvalidation_0-logloss:0.404776\tvalidation_1-logloss:0.403319\n",
      "[40]\tvalidation_0-logloss:0.400413\tvalidation_1-logloss:0.399613\n",
      "[50]\tvalidation_0-logloss:0.397248\tvalidation_1-logloss:0.398416\n",
      "[60]\tvalidation_0-logloss:0.395589\tvalidation_1-logloss:0.398004\n",
      "[70]\tvalidation_0-logloss:0.393569\tvalidation_1-logloss:0.398379\n",
      "[80]\tvalidation_0-logloss:0.392189\tvalidation_1-logloss:0.399221\n",
      "[90]\tvalidation_0-logloss:0.390645\tvalidation_1-logloss:0.399632\n",
      "[99]\tvalidation_0-logloss:0.389425\tvalidation_1-logloss:0.400194\n",
      "Train accuracy: 0.26066350710900477\n",
      "Test accuracy: 0.24806201550387597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "\n",
    "# последовательно обучаем два классификатора\n",
    "for col in ['is_home', 'is_work']:\n",
    "    \n",
    "    #выберем для обучение транзакции только тех клиентов из train, у которых хоть в одной транзакции указано место работы/жительства\n",
    "    cust_train = dt[dt['is_train'] == 1].groupby('customer_id')[col.replace('is_','has_')].max()\n",
    "    cust_train = cust_train[cust_train > 0].index\n",
    "    \n",
    "    #разобъем train на train/valid для валидации\n",
    "    cust_train, cust_valid = train_test_split(cust_train, test_size = 0.1, shuffle = True, random_state = 2)\n",
    "    \n",
    "    train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "    valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "\n",
    "    print (\"Training:\", col)\n",
    "    clf = sklearn.base.clone(model0[col])\n",
    "    clf.fit(train[xs], train[col], eval_metric = 'logloss', eval_set = [(train[xs], train[col]), (valid[xs], valid[col])], verbose=10)\n",
    "    model[col] = clf\n",
    "    print (\"Train accuracy:\", score(train, ys = [col]))\n",
    "    print (\"Test accuracy:\", score(valid, ys = [col]))\n",
    "    print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_test = dt[dt['is_train'] == 0]['customer_id'].unique()\n",
    "test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "test = predict_proba(test)\n",
    "test.rename(columns = {\n",
    "        'customer_id':'_ID_',\n",
    "        'is_home:add_lat': '_HOME_LAT_',\n",
    "        'is_home:add_lon': '_HOME_LON_',\n",
    "        'is_work:add_lat': '_WORK_LAT_',\n",
    "        'is_work:add_lon': '_WORK_LON_'}, inplace = True)\n",
    "test = test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формируем submission-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропуски\n",
    "submission = submission.merge(test, how = 'left').fillna(0)\n",
    "\n",
    "# Пишем файл submission\n",
    "submission.to_csv('baseline-very-simple.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
