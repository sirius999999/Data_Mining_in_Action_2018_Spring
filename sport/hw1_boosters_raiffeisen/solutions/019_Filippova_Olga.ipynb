{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import reverse_geocoder as rg\n",
    "import gmplot\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import GroupKFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 9,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('train_set.csv')\n",
    "test=pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prnt(u_id, how='all', tbl=train_agg, mcc=None, field=None ):\n",
    "    if mcc : cond=(train['mcc']==mcc)\n",
    "    elif field: cond=(train[field]==1)\n",
    "    else: cond=True\n",
    "    tmp=tbl[(tbl.customer_id==u_id)&(cond)][['b_lat' ,'b_lon']].dropna().drop_duplicates()\n",
    "    gmap = gmplot.GoogleMapPlotter(55.874, 37.445, 2)\n",
    "    gmap.scatter(tmp.b_lat, tmp.b_lon, 'cornflowerblue', marker=True)\n",
    "    if 'work_add_lat' in tbl.columns:\n",
    "        if tbl[tbl.customer_id==u_id]['work_add_lat'].any()&tbl[tbl.customer_id==u_id]['work_add_lon'].any():\n",
    "            gmap.scatter([tbl[tbl.customer_id==u_id]['work_add_lat'].iloc[0]], [ tbl[tbl.customer_id==u_id]['work_add_lon'].iloc[0] ], 'y', marker=True)\n",
    "        if tbl[tbl.customer_id==u_id]['home_add_lat'].any()&tbl[tbl.customer_id==u_id]['home_add_lon'].any():\n",
    "            gmap.scatter([tbl[tbl.customer_id==u_id]['home_add_lat'].iloc[0]], [tbl[tbl.customer_id==u_id]['home_add_lon'].iloc[0]], 'k', marker=True)\n",
    "\n",
    "    gmap.draw(\"mymap.html\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чистим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Перед тем как удалить заграничные транзакии, посчитаем сколько их было. \n",
    "train.loc[train[train.country=='RU '].index,'country']='RUS'\n",
    "test.loc[test[test.country=='RU '].index,'country']='RUS'\n",
    "train['country_nm']=train.groupby('customer_id')['country'].transform(lambda x: len(x.unique()))\n",
    "test['country_nm']=test.groupby('customer_id')['country'].transform(lambda x: len(x.unique()))\n",
    "train['country_am']=train.groupby('customer_id')['country'].transform(lambda x: x[x!='RUS'].count())\n",
    "test['country_am']=test.groupby('customer_id')['country'].transform(lambda x: x[x!='RUS'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(train[ train.country!='RUS'].index, axis=0, inplace=True)\n",
    "test.drop(test[ test.country!='RUS'].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#обработаем даты\n",
    "train['transaction_date']=pd.to_datetime(train['transaction_date'], format='%Y-%m-%d')\n",
    "test['transaction_date']=pd.to_datetime(test['transaction_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#добавим признак день недели\n",
    "train['day_of_week']=train['transaction_date'].apply(lambda x: x.dayofweek)\n",
    "test['day_of_week']=test['transaction_date'].apply(lambda x: x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#выходной\n",
    "train['day_off']=train['day_of_week'].apply(lambda x: 1 if x in[5,6] else 0)\n",
    "test['day_off']=test['day_of_week'].apply(lambda x: 1 if x in[5,6] else 0)\n",
    "clb=['2017-02-23','2017-02-24','2017-03-08',\n",
    "                                   '2017-05-01','2017-05-08','2017-05-09',\n",
    "                                  '2017-06-12','2017-11-06']\n",
    "train.loc[train[train.transaction_date.isin(clb)].index,'day_off']=1\n",
    "test.loc[test[test.transaction_date.isin(clb)].index,'day_off']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Организационное "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LabelEncoder на 'customer_id' и 'terminal_id'\n",
    "le_c=LabelEncoder()\n",
    "le_c.fit(train.customer_id.append(test.customer_id))\n",
    "train['customer_id']=le_c.transform(train.customer_id)\n",
    "test['customer_id']=le_c.transform(test.customer_id)\n",
    "\n",
    "le_t=LabelEncoder()\n",
    "le_t.fit(train.terminal_id.astype(str).append(test.terminal_id.astype(str)))\n",
    "train['terminal_id']=le_t.transform(train.terminal_id.astype(str))\n",
    "test['terminal_id']=le_t.transform(test.terminal_id.astype(str))\n",
    "\n",
    "with open('le_c1.pkl', 'wb') as pkl:\n",
    "    pickle.dump(le_c, pkl, protocol=2)\n",
    "with open('le_t1.pkl', 'wb') as pkl:\n",
    "    pickle.dump(le_c, pkl, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#сделаем данные чуть удобней, схлопнем поля для адресов и координат банкоматов.\n",
    "\n",
    "train['is_atm']=(~train[['atm_address_lat', 'atm_address_lon']].isnull().any(axis=1)).astype(int)\n",
    "temp=train.loc[:,['atm_address','pos_address','atm_address_lat', 'atm_address_lon', 'pos_adress_lat', 'pos_adress_lon']]\n",
    "temp.fillna(value=pd.Series(data=['', '', 0,0,0,0], index=temp.columns.values), inplace=True)\n",
    "temp['b_lat']=temp['atm_address_lat'].values+temp['pos_adress_lat'].values\n",
    "temp['b_lon']=temp['atm_address_lon']+temp['pos_adress_lon']\n",
    "temp['b_adr']=temp['atm_address']+temp['pos_address']\n",
    "train[['b_lat', 'b_lon']]=temp[['b_lat', 'b_lon']]\n",
    "train['b_adr']=temp['b_adr']\n",
    "\n",
    "train.drop(['atm_address' ,'atm_address_lat' ,'atm_address_lon', \n",
    "            'pos_address' ,'pos_adress_lat','pos_adress_lon'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "test['is_atm']=(~test[['atm_address_lat', 'atm_address_lon']].isnull().any(axis=1)).astype(int)\n",
    "temp=test.loc[:,['atm_address','pos_address','atm_address_lat', 'atm_address_lon', 'pos_address_lat', 'pos_address_lon']]\n",
    "temp.fillna(value=pd.Series(data=['', '', 0,0,0,0], index=temp.columns.values), inplace=True)\n",
    "temp['b_lat']=temp['atm_address_lat'].values+temp['pos_address_lat'].values\n",
    "temp['b_lon']=temp['atm_address_lon']+temp['pos_address_lon']\n",
    "temp['b_adr']=temp['atm_address']+temp['pos_address']\n",
    "test[['b_lat', 'b_lon']]=temp[['b_lat', 'b_lon']]\n",
    "test['b_adr']=temp['b_adr']\n",
    "\n",
    "test.drop(['atm_address' ,'atm_address_lat' ,'atm_address_lon', \n",
    "            'pos_address' ,'pos_address_lat','pos_address_lon'], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Усредним координаты банкоматов\n",
    "atm_j=train[train.is_atm==1][['terminal_id','b_lat','b_lon']].append(\n",
    "    test[test.is_atm==1][['terminal_id','b_lat','b_lon']], ignore_index=True)\n",
    "mp_lat=atm_j.groupby('terminal_id')['b_lat'].mean()\n",
    "mp_lon=atm_j.groupby('terminal_id')['b_lon'].mean()\n",
    "train.loc[train[train.is_atm==1].index, 'b_lat']=train.terminal_id.map(mp_lat)\n",
    "train.loc[train[train.is_atm==1].index, 'b_lon']=train.terminal_id.map(mp_lon)\n",
    "test.loc[test[test.is_atm==1].index, 'b_lat']=test.terminal_id.map(mp_lat)\n",
    "test.loc[test[test.is_atm==1].index, 'b_lon']=test.terminal_id.map(mp_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Добавим \"целевую переменную\"\n",
    "\n",
    "def is_clth(x,r=0.02):\n",
    "    if ((x[0]-x[2])**2+(x[1]-x[3])**2)**0.5<=r: ans=1\n",
    "    else: ans=0\n",
    "    return ans\n",
    "\n",
    "train['is_home']=train[['home_add_lat' ,'home_add_lon', 'b_lat','b_lon']].apply(lambda x: is_clth(x), axis=1).astype(np.int16)\n",
    "train['is_work']=train[['work_add_lat' ,'work_add_lon', 'b_lat','b_lon']].apply(lambda x: is_clth(x), axis=1).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Удалим записи, с координатами банкоматов ==0\n",
    "\n",
    "train.drop(train[(train.b_lat==0)|(train.b_lon==0)].index, axis=0,inplace=True)\n",
    "test.drop(test[(test.b_lat==0)|(test.b_lon==0)].index, axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test mcc\n",
    "test['mcc']=test.mcc.astype(str).apply(lambda x: x.replace(',', '')).fillna(0).astype(np.int16)\n",
    "test.loc[157168,'mcc']=3400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#добавим избранные mcc которые кажутся важными\n",
    "\n",
    "train['mcc5912']=train.mcc.apply(lambda x: 1 if x==5912 else 0) #аптеки\n",
    "test['mcc5912']=test.mcc.apply(lambda x: 1 if x==5912 else 0) \n",
    "\n",
    "shops=[5921, 5311, 5331,5411,5412,5422,5451, 5499,5411,5462] # Категория продуктовые магазины\n",
    "eat=[5812, 5813, 5814] #категория рестораны\n",
    "fl=[5193, 5992] #цветы\n",
    "train['shops']=train.mcc.apply(lambda x: 1 if x in shops else 0) .astype(np.int16)\n",
    "test['shops']=test.mcc.apply(lambda x: 1 if x in shops else 0) .astype(np.int16)\n",
    "train['eat']=train.mcc.apply(lambda x: 1 if x in eat else 0) .astype(np.int16)\n",
    "test['eat']=test.mcc.apply(lambda x: 1 if x in eat else 0) .astype(np.int16)\n",
    "train['fl']=train.mcc.apply(lambda x: 1 if x in fl else 0) .astype(np.int16)\n",
    "test['fl']=test.mcc.apply(lambda x: 1 if x in fl else 0) .astype(np.int16)\n",
    "train['outh']=((train['mcc5912']+train['shops']+train['eat']+train['fl'])==0).astype(np.int16) # все остальные\n",
    "test['outh']=((test['mcc5912']+test['shops']+test['eat']+test['fl'])==0).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Группировка внутри юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сколько раз юзер был в этой точке, сколько всего для него было разных точек\n",
    "\n",
    "\n",
    "def dist(x1,x2):\n",
    "    d=((x1[0]-x2[0])**2+(x1[1]-x2[1])**2)**0.5\n",
    "    return d\n",
    "\n",
    "\n",
    "for user, sub_df in train.groupby('customer_id'): \n",
    "    #частота\n",
    "    train.loc[sub_df.index,'fr']=sub_df.groupby(['b_lat','b_lon'])['city'].transform('count')\n",
    "    \n",
    "train['n_pnts']=train.groupby('customer_id')['city'].transform('count')\n",
    "train['fr_ratio']=train.fr/train.n_pnts\n",
    "\n",
    "#test\n",
    "\n",
    "\n",
    "for user, sub_df in test.groupby('customer_id'): \n",
    "    #частота\n",
    "    test.loc[sub_df.index,'fr']=sub_df.groupby(['b_lat','b_lon'])['city'].transform('count').astype(np.int16)\n",
    "    \n",
    "test['n_pnts']=test.groupby('customer_id')['city'].transform('count').astype(np.int16)\n",
    "test['fr_ratio']=(test.fr/test.n_pnts).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#аггрегация по выходным. доля сколько в этой точке пользователь был в выходные и в будни\n",
    "train['fr_w']=(train.groupby(['customer_id','b_lat', 'b_lon'])['day_off'].transform('sum')/train['fr']).astype(np.float16)\n",
    "train['fr_b']=(train.groupby(['customer_id','b_lat', 'b_lon'])['day_off'].transform(lambda x: \n",
    "                                                                                np.sum(x==0))/train['fr']).astype(np.float16)\n",
    "#аггрегация по выходным. доля сколько в этой точке пользователь был в выходные и в будни\n",
    "test['fr_w']=(test.groupby(['customer_id','b_lat', 'b_lon'])['day_off'].transform('sum')/test['fr']).astype(np.float16)\n",
    "test['fr_b']=(test.groupby(['customer_id','b_lat', 'b_lon'])['day_off'].transform(lambda x: \n",
    "                                                                                np.sum(x==0))/test['fr']).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: amount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-3dcc397be136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Перейдем к почти уникальным точкам (оставим деление на выходные):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b_lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b_lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m train=train[['amount_mean','day_off','city','customer_id', 'home_add_lat',\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column not found: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: amount'"
     ]
    }
   ],
   "source": [
    "#Перейдем к почти уникальным точкам (оставим деление на выходные):\n",
    "train['amount_mean']=train.groupby(['customer_id','b_lat', 'b_lon'])['amount'].transform('mean').astype(np.float16)\n",
    "test['amount_mean']=test.groupby(['customer_id','b_lat', 'b_lon'])['amount'].transform('mean').astype(np.float16)\n",
    "\n",
    "train=train[['amount_mean','day_off','city','customer_id', 'home_add_lat',\n",
    "       'home_add_lon','work_add_lat', 'work_add_lon', 'mcc', 'terminal_id', 'is_atm', 'b_lat', 'b_lon','is_home', \n",
    "             'is_work', 'mcc5912', 'shops', 'eat', 'fl', 'outh', 'fr',\n",
    "       'dist_cm', 'dist_cm_med', 'n_pnts', 'fr_ratio', 'fr_w', 'fr_b']].drop_duplicates()\n",
    "\n",
    "test=test[['amount_mean','day_off','city','customer_id',  'mcc', 'terminal_id', 'is_atm', 'b_lat', 'b_lon', \n",
    "           'mcc5912', 'shops', 'eat', 'fl', 'outh', 'fr',\n",
    "       'dist_cm', 'dist_cm_med', 'n_pnts', 'fr_ratio', 'fr_w', 'fr_b']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассчеты внутри юзера с использованием NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#функция с одним условием\n",
    "def un_smth_1(X, cond, name):\n",
    "    for user, sub_df in X.groupby('customer_id'): \n",
    "        neibh = NearestNeighbors(radius=0.02)\n",
    "        tmp=sub_df[sub_df[cond]==1][['b_lat', 'b_lon']].drop_duplicates()\n",
    "        if tmp.shape[0]==0: \n",
    "            X.loc[sub_df.index,name]=0\n",
    "            continue\n",
    "        neibh.fit(tmp[['b_lat', 'b_lon']].values)\n",
    "        idx=neibh.radius_neighbors(sub_df[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "        X.loc[sub_df.index,name]=[len(x) for x in idx]\n",
    "    X[name]=X[name].astype(np.int16)\n",
    "    pass\n",
    "\n",
    "#Функция с двумя условиями \n",
    "def un_smth_2(X, cond1, cond2, val2, name):\n",
    "    for user, sub_df in X.groupby('customer_id'): \n",
    "        neibh = NearestNeighbors(radius=0.02)\n",
    "        tmp=sub_df[(sub_df[cond1]==1)&(sub_df[cond2]==val2)][['b_lat', 'b_lon']].drop_duplicates()\n",
    "        if tmp.shape[0]==0: \n",
    "            X.loc[sub_df.index,name]=0\n",
    "            continue\n",
    "        neibh.fit(tmp[['b_lat', 'b_lon']].values)\n",
    "        idx=neibh.radius_neighbors(sub_df[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "        X.loc[sub_df.index,name]=[len(x) for x in idx]\n",
    "    X[name]=X[name].astype(np.int16)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 43s, sys: 192 ms, total: 3min 43s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#уникальные соседи\n",
    "for user, sub_df in train.groupby('customer_id'): \n",
    "    neibh = NearestNeighbors(radius=0.02)\n",
    "    tmp=sub_df[['b_lat', 'b_lon']].drop_duplicates()\n",
    "    neibh.fit(tmp[['b_lat', 'b_lon']].values)\n",
    "    idx=neibh.radius_neighbors(sub_df[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "    train.loc[sub_df.index,'un_nb']=[len(x) for x in idx]\n",
    "\n",
    "for user, sub_df in test.groupby('customer_id'): \n",
    "    neibh = NearestNeighbors(radius=0.02)\n",
    "    tmp=sub_df[['b_lat', 'b_lon']].drop_duplicates()\n",
    "    neibh.fit(tmp[['b_lat', 'b_lon']].values)\n",
    "    idx=neibh.radius_neighbors(sub_df[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "    test.loc[sub_df.index,'un_nb']=[len(x) for x in idx]\n",
    "train['un_nb']=train['un_nb'].astype(np.int16)\n",
    "test['un_nb']=test['un_nb'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for user, sub_df in test.groupby('customer_id'): \n",
    "    neibh = NearestNeighbors(radius=0.02)\n",
    "    tmp=sub_df[['b_lat', 'b_lon']].drop_duplicates()\n",
    "    neibh.fit(tmp[['b_lat', 'b_lon']].values)\n",
    "    idx=neibh.radius_neighbors(sub_df[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "    test.loc[sub_df.index,'un_nb']=[len(x) for x in idx]\n",
    "train['un_nb']=train['un_nb'].astype(np.int16)\n",
    "test['un_nb']=test['un_nb'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "CPU times: user 22min 42s, sys: 896 ms, total: 22min 43s\n",
      "Wall time: 22min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for (i,j) in [('shops','un_nb_shops'), ('is_atm', 'un_nb_atm'), ('mcc5912','un_nb_5912' ), \n",
    "          ('eat','un_nb_eat') , ('fl','un_nb_fl'),('outh','un_nb_outh')]:\n",
    "    un_smth_1(train, i, j)\n",
    "    un_smth_1(test, i, j)\n",
    "    print (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "CPU times: user 48min, sys: 2.13 s, total: 48min 2s\n",
      "Wall time: 48min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for (i,j) in [('shops','un_nb_shops'), ('is_atm', 'un_nb_atm'), ('mcc5912','un_nb_5912' ), \n",
    "          ('eat','un_nb_eat') , ('fl','un_nb_fl'),('outh','un_nb_outh')]:\n",
    "    for (k,m) in [(1,'_w'), (0,'_b')]:\n",
    "        un_smth_2(train, i,'day_off',k, j+m)\n",
    "        un_smth_2(test, i,'day_off',k, j+m)\n",
    "        print (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#где-то относительные значения лучше абсолютных\n",
    "train['un_nb_shops_ratio']=(train.un_nb_shops/train.un_nb).fillna(0).astype(np.float16)\n",
    "train['un_nb_5912_ratio']=(train.un_nb_5912/train.un_nb).fillna(0).astype(np.float16)\n",
    "train['un_nb_eat_ratio']=(train.un_nb_eat/train.un_nb).fillna(0).astype(np.float16)\n",
    "train['un_nb_atm_ratio']=(train.un_nb_atm/train.un_nb).fillna(0).astype(np.float16)\n",
    "train['un_nb_fl_ratio']=(train.un_nb_fl/train.un_nb).fillna(0).astype(np.float16)\n",
    "train['un_nb_atm_w_ratio']=(train.un_nb_atm_w/train.un_nb_atm).fillna(0).astype(np.float16)\n",
    "train['un_nb_atm_b_ratio']=(train.un_nb_atm_b/train.un_nb_atm).fillna(0).astype(np.float16)\n",
    "train['un_nb_shops_w_ratio']=(train.un_nb_shops_w/train.un_nb_shops).fillna(0).astype(np.float16)\n",
    "train['un_nb_shops_b_ratio']=(train.un_nb_shops_b/train.un_nb_shops).fillna(0).astype(np.float16)\n",
    "train['un_nb_5912_w_ratio']=(train.un_nb_5912_w/train.un_nb_5912).fillna(0).astype(np.float16)\n",
    "train['un_nb_5912_b_ratio']=(train.un_nb_5912_b/train.un_nb_5912).fillna(0).astype(np.float16)\n",
    "train['un_nb_eat_w_ratio']=(train.un_nb_eat_w/train.un_nb_eat).fillna(0).astype(np.float16)\n",
    "train['un_nb_eat_b_ratio']=(train.un_nb_eat_b/train.un_nb_eat).fillna(0).astype(np.float16)\n",
    "train['un_nb_fl_w_ratio']=(train.un_nb_fl_w/train.un_nb_fl).fillna(0).astype(np.float16)\n",
    "train['un_nb_fl_b_ratio']=(train.un_nb_fl_b/train.un_nb_fl).fillna(0).astype(np.float16)\n",
    "train['un_nb_outh_w_ratio']=(train.un_nb_outh_w/train.un_nb_outh).fillna(0).astype(np.float16)\n",
    "train['un_nb_outh_b_ratio']=(train.un_nb_outh_b/train.un_nb_outh).fillna(0).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['un_nb_shops_ratio']=(test.un_nb_shops/test.un_nb).fillna(0).astype(np.float16)\n",
    "test['un_nb_5912_ratio']=(test.un_nb_5912/test.un_nb).fillna(0).astype(np.float16)\n",
    "test['un_nb_eat_ratio']=(test.un_nb_eat/test.un_nb).fillna(0).astype(np.float16)\n",
    "test['un_nb_atm_ratio']=(test.un_nb_atm/test.un_nb).fillna(0).astype(np.float16)\n",
    "test['un_nb_fl_ratio']=(test.un_nb_fl/test.un_nb).fillna(0).astype(np.float16)\n",
    "test['un_nb_atm_w_ratio']=(test.un_nb_atm_w/test.un_nb_atm).fillna(0).astype(np.float16)\n",
    "test['un_nb_atm_b_ratio']=(test.un_nb_atm_b/test.un_nb_atm).fillna(0).astype(np.float16)\n",
    "test['un_nb_shops_w_ratio']=(test.un_nb_shops_w/test.un_nb_shops).fillna(0).astype(np.float16)\n",
    "test['un_nb_shops_b_ratio']=(test.un_nb_shops_b/test.un_nb_shops).fillna(0).astype(np.float16)\n",
    "test['un_nb_5912_w_ratio']=(test.un_nb_5912_w/test.un_nb_5912).fillna(0).astype(np.float16)\n",
    "test['un_nb_5912_b_ratio']=(test.un_nb_5912_b/test.un_nb_5912).fillna(0).astype(np.float16)\n",
    "test['un_nb_eat_w_ratio']=(test.un_nb_eat_w/test.un_nb_eat).fillna(0).astype(np.float16)\n",
    "test['un_nb_eat_b_ratio']=(test.un_nb_eat_b/test.un_nb_eat).fillna(0).astype(np.float16)\n",
    "test['un_nb_fl_w_ratio']=(test.un_nb_fl_w/test.un_nb_fl).fillna(0).astype(np.float16)\n",
    "test['un_nb_fl_b_ratio']=(test.un_nb_fl_b/test.un_nb_fl).fillna(0).astype(np.float16)\n",
    "test['un_nb_outh_w_ratio']=(test.un_nb_outh_w/test.un_nb_outh).fillna(0).astype(np.float16)\n",
    "test['un_nb_outh_b_ratio']=(test.un_nb_outh_b/test.un_nb_outh).fillna(0).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(train[train.fr==0].index, axis=0,inplace=True)\n",
    "test.drop(test[test.fr==0].index, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Признаки про соседей, которые считаются отдельно для трейна и теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#признаки которые надо считать отдельно. количество соседей мест работы из train\n",
    "knn_work=train[['customer_id', 'work_add_lat' ,'work_add_lon']].dropna().drop_duplicates()[['work_add_lat' ,'work_add_lon']].values.tolist()\n",
    "neibh = NearestNeighbors(radius=0.02)\n",
    "neibh.fit(knn_work)\n",
    "idx=neibh.radius_neighbors(train[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "train['nb_work']=[len(x) for x in idx]-train.is_work.values\n",
    "\n",
    "idx_val=neibh.radius_neighbors(test[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "test['nb_work']=[len(x) for x in idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#признаки которые надо считать отдельно. количество соседей домашних адресов из train\n",
    "\n",
    "knn_home=train[['customer_id', 'home_add_lat' ,'home_add_lon']].dropna().drop_duplicates()[['home_add_lat' ,'home_add_lon']].values.tolist()\n",
    "neibh = NearestNeighbors(radius=0.02)\n",
    "neibh.fit(knn_home)\n",
    "idx=neibh.radius_neighbors(train[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "train['nb_home']=[len(x) for x in idx]-train.is_home.values\n",
    "\n",
    "idx_val=neibh.radius_neighbors(test[['b_lat', 'b_lon']].values,radius=0.02,return_distance=False)\n",
    "test['nb_home']=[len(x) for x in idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['nb_work1']=train['nb_work']\n",
    "test['nb_work1']=test['nb_work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Признаки про терминалы, которые связаны с тц и работой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs=pd.read_csv('bs.csv')\n",
    "r=0.005\n",
    "bs_c=bs[['lat','lon']].values.tolist()\n",
    "neibh = NearestNeighbors(radius=r)\n",
    "neibh.fit(bs_c)\n",
    "idx= neibh.radius_neighbors(train[train.is_atm==1][['b_lat', 'b_lon']].values,radius=r,return_distance=False)\n",
    "train.loc[train.is_atm==1,'bs_c']=[len(x) for x in idx]\n",
    "train['bs_c']=train['bs_c'].fillna(0).astype(np.int16)\n",
    "\n",
    "idx= neibh.radius_neighbors(test[test.is_atm==1][['b_lat', 'b_lon']].values,radius=r,return_distance=False)\n",
    "test.loc[test.is_atm==1,'bs_c']=[len(x) for x in idx]\n",
    "test['bs_c']=test['bs_c'].fillna(0).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Перейдем к уникальным точкам:\n",
    "\n",
    "train=train[['amount_mean', 'city', 'customer_id', 'home_add_lat',\n",
    "       'home_add_lon', 'work_add_lat', 'work_add_lon', 'mcc', 'terminal_id',\n",
    "       'is_atm', 'b_lat', 'b_lon', 'is_home', 'is_work', 'mcc5912', 'shops',\n",
    "       'eat', 'fl', 'outh', 'fr', 'dist_cm', 'dist_cm_med', 'n_pnts',\n",
    "       'fr_ratio', 'fr_w', 'fr_b', 'un_nb', 'un_nb_shops', 'un_nb_atm',\n",
    "       'un_nb_5912', 'un_nb_eat', 'un_nb_fl', 'un_nb_outh', 'un_nb_shops_w',\n",
    "       'un_nb_shops_b', 'un_nb_atm_w', 'un_nb_atm_b', 'un_nb_5912_w',\n",
    "       'un_nb_5912_b', 'un_nb_eat_w', 'un_nb_eat_b', 'un_nb_fl_w',\n",
    "       'un_nb_fl_b', 'un_nb_outh_w', 'un_nb_outh_b', 'un_nb_shops_ratio',\n",
    "       'un_nb_5912_ratio', 'un_nb_eat_ratio', 'un_nb_atm_ratio',\n",
    "       'un_nb_fl_ratio', 'un_nb_atm_w_ratio', 'un_nb_atm_b_ratio',\n",
    "       'un_nb_shops_w_ratio', 'un_nb_shops_b_ratio', 'un_nb_5912_w_ratio',\n",
    "       'un_nb_5912_b_ratio', 'un_nb_eat_w_ratio', 'un_nb_eat_b_ratio',\n",
    "       'un_nb_fl_w_ratio', 'un_nb_fl_b_ratio', 'un_nb_outh_w_ratio',\n",
    "       'un_nb_outh_b_ratio','nb_work', 'nb_home', 'nb_work1', 'bs_c']].drop_duplicates()\n",
    "\n",
    "test=test[['amount_mean', 'day_off', 'city', 'customer_id', 'mcc', 'terminal_id',\n",
    "       'is_atm', 'b_lat', 'b_lon', 'mcc5912', 'shops', 'eat', 'fl', 'outh',\n",
    "       'fr', 'dist_cm', 'dist_cm_med', 'n_pnts', 'fr_ratio', 'fr_w', 'fr_b',\n",
    "       'un_nb', 'un_nb_shops', 'un_nb_atm', 'un_nb_5912', 'un_nb_eat',\n",
    "       'un_nb_fl', 'un_nb_outh', 'un_nb_shops_w', 'un_nb_shops_b',\n",
    "       'un_nb_atm_w', 'un_nb_atm_b', 'un_nb_5912_w', 'un_nb_5912_b',\n",
    "       'un_nb_eat_w', 'un_nb_eat_b', 'un_nb_fl_w', 'un_nb_fl_b',\n",
    "       'un_nb_outh_w', 'un_nb_outh_b', 'un_nb_shops_ratio', 'un_nb_5912_ratio',\n",
    "       'un_nb_eat_ratio', 'un_nb_atm_ratio', 'un_nb_fl_ratio',\n",
    "       'un_nb_atm_w_ratio', 'un_nb_atm_b_ratio', 'un_nb_shops_w_ratio',\n",
    "       'un_nb_shops_b_ratio', 'un_nb_5912_w_ratio', 'un_nb_5912_b_ratio',\n",
    "       'un_nb_eat_w_ratio', 'un_nb_eat_b_ratio', 'un_nb_fl_w_ratio',\n",
    "       'un_nb_fl_b_ratio', 'un_nb_outh_w_ratio', 'un_nb_outh_b_ratio','nb_work',\n",
    "           'nb_home', 'nb_work1', 'bs_c']].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# признак для валидации: 0 если известна целевая переменная для дома и работы, 1 если нет координат места работы\n",
    "# 2 если нет координат дома\n",
    "train['for_val']=train.groupby('customer_id')['work_add_lat'].transform(lambda x: x.isnull()).to_frame().merge(\n",
    "    train.groupby('customer_id')['home_add_lat'].transform(lambda x: x.isnull()).to_frame(),\n",
    "    left_index=True, right_index=True, how='inner').apply(lambda x: x[0]+x[1]*2, axis=1)\n",
    "#Добавим признак возможно ли определить точку\n",
    "train['ph'] =train.groupby('customer_id')['is_home'].transform(lambda x: 1 if np.sum(x)>0 else 0)\n",
    "train['pw'] =train.groupby('customer_id')['is_work'].transform(lambda x: 1 if np.sum(x)>0 else 0)\n",
    "with open('tr_val.pkl', 'wb') as pkl:\n",
    "    pickle.dump(train, pkl, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colsw=['amount_mean','terminal_id', 'is_atm', 'mcc5912', 'shops', 'eat', 'fl', 'outh','fr'\n",
    "      ,'fr_w', 'fr_b','bs_c','nb_work', 'nb_work1','un_nb_eat_b_ratio','un_nb_fl']\n",
    "\n",
    "colsh=['amount_mean','terminal_id','is_atm', 'mcc5912', 'shops', 'eat', 'fl', 'outh','fr'\n",
    "      ,'fr_w', 'fr_b','nb_work', 'nb_home',  'un_nb_eat',\n",
    "       'un_nb_fl', 'un_nb_outh','un_nb_shops','un_nb_shops_w','un_nb_atm','un_nb_5912', 'un_nb_fl_w']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5154894671623296, 0.5254027261462205, 0.4795539033457249, 0.5452292441140025]\n",
      "0.516418835192\n"
     ]
    }
   ],
   "source": [
    "#work\n",
    "cv_work=[]\n",
    "val_work=train[(train.for_val!=1)&(train.pw==1)]\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "for tr_idx, tst_idx in gkf.split(val_work, val_work['is_work'], groups=val_work['customer_id']):\n",
    "    tr=val_work.iloc[tr_idx,:]\n",
    "    ts=val_work.iloc[tst_idx,:]\n",
    "    xgb1=XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=300,n_jobs=-1,min_child_weight=1,subsample=0.9)\n",
    "    xgb1.fit(tr[colsw], tr['is_work'])\n",
    "    y1=xgb1.predict_proba(ts[colsw])[:,1]\n",
    "    ts['y1']=y1\n",
    "    a=ts.groupby('customer_id').apply(lambda x: x.is_work[np.argmax(x.y1)])\n",
    "    cv_work.append(np.sum(a)/len(a))\n",
    "\n",
    "print (cv_work)\n",
    "print (np.mean(cv_work))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6114072494669509, 0.6098081023454158, 0.6316631130063965, 0.619072988811934]\n",
      "0.617987863408\n"
     ]
    }
   ],
   "source": [
    "#home\n",
    "cv_home=[]\n",
    "val_home=train[(train.for_val!=2)&(train.ph==1)]\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "for tr_idx, tst_idx in gkf.split(val_home, val_home['is_home'], groups=val_home['customer_id']):\n",
    "    tr=val_home.iloc[tr_idx,:]\n",
    "    ts=val_home.iloc[tst_idx,:]\n",
    "    xgb2=XGBClassifier()\n",
    "    xgb2.fit(tr[colsh], tr['is_home'])\n",
    "    y2=xgb2.predict_proba(ts[colsh])[:,1]\n",
    "    ts['y2']=y2\n",
    "    a=ts.groupby('customer_id').apply(lambda x: x.is_home[np.argmax(x.y2)])\n",
    "    cv_home.append(np.sum(a)/len(a))\n",
    "print (cv_home)\n",
    "print (np.mean(cv_home))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Считаем результат\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 256 ms, total: 2min 34s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('le_c1.pkl', 'rb') as f: le_c = pickle.load(f)\n",
    "\n",
    "tr=train[train.pw==1]\n",
    "vl=test\n",
    "xgb1=XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=300,n_jobs=-1,min_child_weight=1,subsample=0.9)\n",
    "xgb1.fit(tr[colsw], tr['is_work'])\n",
    "y1=xgb1.predict_proba(vl[colsw])[:,1]\n",
    "\n",
    "tr=train[train.ph==1]\n",
    "vl=test\n",
    "xgb2=XGBClassifier()\n",
    "xgb2.fit(tr[colsh], tr['is_home'])\n",
    "y2=xgb2.predict_proba(vl[colsh])[:,1]\n",
    "\n",
    "\n",
    "ans=test[['customer_id','b_lat','b_lon']]\n",
    "ans['y_w']=y1\n",
    "ans['y_h']=y2\n",
    "h=ans.groupby('customer_id').apply(lambda x: x[['b_lat','b_lon']].loc[np.argmax(x.y_h),:])\n",
    "w=ans.groupby('customer_id').apply(lambda x: x[['b_lat','b_lon']].loc[np.argmax(x.y_w),:])\n",
    "df=pd.DataFrame(w.join(h, lsuffix='_w', rsuffix='_h').values, index= le_c.inverse_transform(h.index.astype(int)),\n",
    "             columns=['_WORK_LAT_','_WORK_LON_','_HOME_LAT_','_HOME_LON_'])\n",
    "df.to_csv('subm_1.csv', index_label='_ID_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "git remote add upstream https://github.com/applied-data-science/Data_Mining_in_Action_2018_Spring\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
