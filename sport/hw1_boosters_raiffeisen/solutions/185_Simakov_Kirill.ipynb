{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import lightgbm as xgb\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определим типы колонок для экономии памяти\n",
    "dtypes = {\n",
    "    'transaction_date': str,\n",
    "    'atm_address': str,\n",
    "    'country': str,\n",
    "    'city': str,\n",
    "    'amount': np.float32,\n",
    "    'currency': np.float32,\n",
    "    'mcc': str,\n",
    "    'customer_id': str,\n",
    "    'pos_address': str,\n",
    "    'atm_address': str,\n",
    "    'pos_adress_lat': np.float32,\n",
    "    'pos_adress_lon': np.float32,\n",
    "    'pos_address_lat': np.float32,\n",
    "    'pos_address_lon': np.float32,\n",
    "    'atm_address_lat': np.float32,\n",
    "    'atm_address_lon': np.float32,\n",
    "    'home_add_lat': np.float32,\n",
    "    'home_add_lon': np.float32,\n",
    "    'work_add_lat': np.float32,\n",
    "    'work_add_lon': np.float32,\n",
    "    'mcckmeans_lat': np.float32,\n",
    "    'mcckmeans_lon': np.float32,\n",
    "    'kmeans_lat': np.float32,\n",
    "    'kmeans_lon': np.float32,\n",
    "}\n",
    "                             \n",
    "# для экономии памяти будем загружать только часть атрибутов транзакций\n",
    "usecols_train = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', \n",
    "                 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat',\n",
    "                 'home_add_lon','work_add_lat','work_add_lon']\n",
    "usecols_test = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', \n",
    "                'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']\n",
    "usecols_dump = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', \n",
    "                'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat',\n",
    "                'home_add_lon','work_add_lat','work_add_lon','mcckmeans_lat','mcckmeans_lon','kmeans_lat','kmeans_lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set.csv', dtype = dtypes, usecols = usecols_train)\n",
    "train.rename(columns = {'pos_adress_lat': 'pos_address_lat', 'pos_adress_lon': 'pos_address_lon'}, inplace = True)\n",
    "\n",
    "test = pd.read_csv('test_set.csv', dtype = dtypes, usecols = usecols_test)\n",
    "submission = pd.DataFrame(test['customer_id'].unique(), columns = ['_ID_'])\n",
    "\n",
    "train['is_train'] = np.int32(1)\n",
    "test['is_train'] = np.int32(0)\n",
    "dt = pd.concat([train, test])\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['currency'] = dt['currency'].fillna(-1).astype(np.int32)\n",
    "dt['mcc'] = dt['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)\n",
    "dt['city'] = dt['city'].factorize()[0].astype(np.int32)\n",
    "dt['country'] = dt['country'].factorize()[0].astype(np.int32)\n",
    "\n",
    "dt.drop(dt[dt['transaction_date'].isnull()].index, axis = 0, inplace = True)\n",
    "dt['transaction_date'] = dt['transaction_date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "dt['weekday'] = dt['transaction_date'].dt.weekday.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['is_atm'] = (~dt['atm_address_lat'].isnull()).astype(np.int32)\n",
    "dt['is_pos'] = (~dt['pos_address_lat'].isnull()).astype(np.int32)\n",
    "\n",
    "dt['address_lat'] = dt['atm_address_lat'].fillna(0) + dt['pos_address_lat'].fillna(0)\n",
    "dt['address_lon'] = dt['atm_address_lon'].fillna(0) + dt['pos_address_lon'].fillna(0)\n",
    "\n",
    "dt.drop(['atm_address_lat','atm_address_lon','pos_address_lat','pos_address_lon'], axis = 1, inplace = True)\n",
    "\n",
    "dt.drop(dt[((dt['address_lat'] == 0) & (dt['address_lon'] == 0))].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeanscentrs = set(('mcckmeans_lat', 'mcckmeans_lon','kmeans_lat', 'kmeans_lon'))\n",
    "kmeanscentrs = sorted(list(kmeanscentrs))\n",
    "dt['mcckmeans_lat']=dt['address_lat']\n",
    "dt['mcckmeans_lon']=dt['address_lon']\n",
    "dt['kmeans_lat']=dt['address_lat']\n",
    "dt['kmeans_lon']=dt['address_lon']\n",
    "\n",
    "customers = dt[\"customer_id\"].value_counts().keys().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = dt['address_lat'] - dt['mcckmeans_lat']\n",
    "lon = dt['address_lon'] - dt['mcckmeans_lon']\n",
    "dt['dist_1'] = np.sqrt((lat ** 2) + (lon ** 2)).astype(np.float32)\n",
    "\n",
    "lat = dt['address_lat'] - dt['kmeans_lat']\n",
    "lon = dt['address_lon'] - dt['kmeans_lon']\n",
    "dt['dist_2'] = np.sqrt((lat ** 2) + (lon ** 2)).astype(np.float32)\n",
    "\n",
    "lat = dt['mcckmeans_lat'] - dt['kmeans_lat']\n",
    "lon = dt['mcckmeans_lon'] - dt['kmeans_lon']\n",
    "dt['dist_3'] = np.sqrt((lat ** 2) + (lon ** 2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = dt['home_add_lat'] - dt['address_lat']\n",
    "lon = dt['home_add_lon'] - dt['address_lon']\n",
    "dt['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.017).astype(np.int32)\n",
    "dt['has_home'] = (~dt['home_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "lat = dt['work_add_lat'] - dt['address_lat']\n",
    "lon = dt['work_add_lon'] - dt['address_lon']\n",
    "dt['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.017).astype(np.int32)\n",
    "dt['has_work'] = (~dt['work_add_lon'].isnull()).astype(np.int32)\n",
    "\n",
    "dt.drop(['work_add_lat','work_add_lon','home_add_lat','home_add_lon'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt['address'] = dt['address_lat'].apply(lambda x: \"%.02f\" % x) + ';' + dt['address_lon'].apply(lambda x: \"%.02f\" % x)\n",
    "dt['address'] = dt['address'].factorize()[0].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = dt.merge(dt.groupby('customer_id')['amount'].count().reset_index(name = 'tx'), how = 'left')\n",
    "dt['tx'] = dt['tx'].astype(np.int32)\n",
    "\n",
    "dt = dt.merge(dt.groupby(['customer_id','address'])['amount'].count().reset_index(name = 'tx_cust_addr'), how = 'left')\n",
    "dt['tx_cust_addr'] = dt['tx_cust_addr'].astype(np.int32)\n",
    "\n",
    "dt['ratio1'] = dt['tx_cust_addr'] / dt['tx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _best(x):\n",
    "    ret = None\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        if pred in x:\n",
    "            i = (x[pred].idxmax())\n",
    "            cols = [pred,'address_lat','address_lon']\n",
    "            if col in x:\n",
    "                cols.append(col)\n",
    "            tmp = x.loc[i,cols]\n",
    "            tmp.rename({\n",
    "                'address_lat':'%s:add_lat' % col,\n",
    "                'address_lon':'%s:add_lon' % col,\n",
    "            }, inplace = True)\n",
    "            if ret is None:\n",
    "                ret = tmp\n",
    "            else:\n",
    "                ret = pd.concat([ret, tmp])\n",
    "    return ret\n",
    "    \n",
    "def predict_proba(dt, ys = ['is_home', 'is_work']):\n",
    "    for col in ys:\n",
    "        pred = ('pred:%s' % col)\n",
    "        dt[pred] = model[col].predict_proba(dt[xs])[:,1]\n",
    "    return dt.groupby('customer_id').apply(_best).reset_index()\n",
    "\n",
    "def score(dt, ys = ['is_home', 'is_work']):\n",
    "    dt_ret = predict_proba(dt, ys)\n",
    "    mean = 0.0\n",
    "    for col in ys:\n",
    "        col_mean = dt_ret[col].mean()\n",
    "        mean += col_mean\n",
    "    if len(ys) == 2:\n",
    "        mean = mean / len(ys)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0070492579bd4dc18ce58d8640048187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: is_home\n",
      "[10]\tvalid_0's binary_logloss: 0.496329\tvalid_1's binary_logloss: 0.491254\n",
      "[20]\tvalid_0's binary_logloss: 0.456101\tvalid_1's binary_logloss: 0.451867\n",
      "[30]\tvalid_0's binary_logloss: 0.445082\tvalid_1's binary_logloss: 0.442113\n",
      "[40]\tvalid_0's binary_logloss: 0.440008\tvalid_1's binary_logloss: 0.438959\n",
      "[50]\tvalid_0's binary_logloss: 0.436569\tvalid_1's binary_logloss: 0.438134\n",
      "[60]\tvalid_0's binary_logloss: 0.433866\tvalid_1's binary_logloss: 0.438818\n",
      "[70]\tvalid_0's binary_logloss: 0.431187\tvalid_1's binary_logloss: 0.439429\n",
      "Train accuracy: 0.3638888888888889\n",
      "Test accuracy: 0.356\n",
      "\n",
      "Training: is_work\n",
      "[10]\tvalid_0's binary_logloss: 0.43444\tvalid_1's binary_logloss: 0.44627\n",
      "Train accuracy: 0.23675140025850927\n",
      "Test accuracy: 0.23449612403100775\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xs = ['amount','city','country','currency','mcc','is_atm','is_pos','ratio1','dist_1',\\\n",
    "      'dist_2','dist_3']\n",
    "ys = ['is_home', 'is_work']\n",
    "\n",
    "model0 = {\n",
    "    'is_home': xgb.LGBMClassifier(n_estimators = 77, n_jobs = 3),\n",
    "    'is_work': xgb.LGBMClassifier(n_estimators = 15, n_jobs = 3),\n",
    "}\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas(desc=\"apply\")\n",
    "\n",
    "model = {}\n",
    "\n",
    "for col in  tqdm_notebook(['is_home', 'is_work']):\n",
    "    \n",
    "    cust_train = dt[dt['is_train'] == 1].groupby('customer_id')[col.replace('is_','has_')].max()\n",
    "    cust_train = cust_train[cust_train > 0].index\n",
    "    \n",
    "    cust_train, cust_valid = train_test_split(cust_train, test_size = 0.1, shuffle = True, random_state = 2)\n",
    "    \n",
    "    train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "    valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "\n",
    "    print (\"Training:\", col)\n",
    "    clf = sklearn.base.clone(model0[col])\n",
    "    clf.fit(train[xs], train[col], eval_metric = 'logloss', eval_set = [(train[xs], train[col]), (valid[xs], valid[col])], verbose=10)\n",
    "\n",
    "    model[col] = clf\n",
    "    print (\"Train accuracy:\", score(train, ys = [col]))\n",
    "    print (\"Test accuracy:\", score(valid, ys = [col]))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cust_test = dt[dt['is_train'] == 0]['customer_id'].unique()\n",
    "test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(dt, how = 'left')\n",
    "test = predict_proba(test)\n",
    "test.rename(columns = {\n",
    "        'customer_id':'_ID_',\n",
    "        'is_home:add_lat': '_HOME_LAT_',\n",
    "        'is_home:add_lon': '_HOME_LON_',\n",
    "        'is_work:add_lat': '_WORK_LAT_',\n",
    "        'is_work:add_lon': '_WORK_LON_'}, inplace = True)\n",
    "test = test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = submission.merge(test, how = 'left').fillna(0)\n",
    "\n",
    "submission.to_csv('submit13.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
