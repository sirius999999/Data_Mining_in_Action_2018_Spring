import pandas as pd
import numpy as np
import datetime

#import xgboost as xgb
import lightgbm as xgb
import sklearn
import math

from sklearn.model_selection import train_test_split
#-----------------------------------------------------
# Определим типы колонок для экономии памяти
dtypes = {
    'transaction_date': str,
    'atm_address': str,
    'country': str,
    'city': str,
    'amount': np.float32,
    'currency': np.float32,
    'mcc': str,
    'customer_id': str,
    'pos_address': str,
    'atm_address': str,
    'pos_adress_lat': np.float32,
    'pos_adress_lon': np.float32,
    'pos_address_lat': np.float32,
    'pos_address_lon': np.float32,
    'atm_address_lat': np.float32,
    'atm_address_lon': np.float32,
    'home_add_lat': np.float32,
    'home_add_lon': np.float32,
    'work_add_lat': np.float32,
    'work_add_lon': np.float32,
    'mcckmeans_lat': np.float32,
    'mcckmeans_lon': np.float32,
    'kmeans_lat': np.float32,
    'kmeans_lon': np.float32,
}
                             
# для экономии памяти будем загружать только часть атрибутов транзакций
usecols_train = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_adress_lat', 'pos_adress_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon']
usecols_test = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon']
usecols_dump = ['customer_id','transaction_date','amount','country', 'city', 'currency', 'mcc', 'pos_address_lat', 'pos_address_lon', 'atm_address_lat', 'atm_address_lon','home_add_lat','home_add_lon','work_add_lat','work_add_lon','mcckmeans_lat','mcckmeans_lon','kmeans_lat','kmeans_lon']
#--------------------------------------------------

train = pd.read_csv('train_set.csv', dtype = dtypes, usecols = usecols_train)
train.rename(columns = {'pos_adress_lat': 'pos_address_lat', 'pos_adress_lon': 'pos_address_lon'}, inplace = True)

test = pd.read_csv('test_set.csv', dtype = dtypes, usecols = usecols_test)
submission = pd.DataFrame(test['customer_id'].unique(), columns = ['_ID_'])

# соединяем test/train в одном DataFrame
train['is_train'] = np.int32(1)
test['is_train'] = np.int32(0)
dt = pd.concat([train, test])

del train, test

#------------------------------------------------------

dt['currency'] = dt['currency'].fillna(-1).astype(np.int32)
dt['mcc'] = dt['mcc'].apply(lambda x: int(x.replace(',', ''))).astype(np.int32)
dt['city'] = dt['city'].factorize()[0].astype(np.int32)
dt['country'] = dt['country'].factorize()[0].astype(np.int32)

# удаляем транзакции без даты
dt.drop(dt[dt['transaction_date'].isnull()].index, axis = 0, inplace = True)
dt['transaction_date'] = dt['transaction_date'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))
#-----------------------------------------------------------------

dt['weekday'] = dt['transaction_date'].dt.weekday.astype(np.int32)
#------------------------------------------------------------

dt['is_atm'] = (~dt['atm_address_lat'].isnull()).astype(np.int32)
dt['is_pos'] = (~dt['pos_address_lat'].isnull()).astype(np.int32)

dt['address_lat'] = dt['atm_address_lat'].fillna(0) + dt['pos_address_lat'].fillna(0)
dt['address_lon'] = dt['atm_address_lon'].fillna(0) + dt['pos_address_lon'].fillna(0)

dt.drop(['atm_address_lat','atm_address_lon','pos_address_lat','pos_address_lon'], axis = 1, inplace = True)

# удалим транзакции без адреса
dt.drop(dt[((dt['address_lat'] == 0) & (dt['address_lon'] == 0))].index, axis = 0, inplace = True)
#-------------------------------------------------------

kmeanscentrs = set(('mcckmeans_lat', 'mcckmeans_lon','kmeans_lat', 'kmeans_lon'))
kmeanscentrs = sorted(list(kmeanscentrs))
dt['mcckmeans_lat']=dt['address_lat']
dt['mcckmeans_lon']=dt['address_lon']
dt['kmeans_lat']=dt['address_lat']
dt['kmeans_lon']=dt['address_lon']

customers = dt["customer_id"].value_counts().keys().tolist()

from sklearn.cluster import KMeans
from tqdm._tqdm_notebook import tqdm_notebook
tqdm_notebook.pandas(desc="apply")
kmns = KMeans(n_clusters=1)
kmnsmcc = KMeans(n_clusters=1)

for i in tqdm_notebook(range(len(customers))):
    custdata = dt.loc[dt["customer_id"] == customers[i],pointcol]
    kmns = KMeans(n_clusters=1)
    kmeans = kmns.fit(custdata.loc[:,pointer_col])
    centroids = kmeans.cluster_centers_
    
    mccs = custdata["mcc"].value_counts().keys().tolist()
    for j in range(len(mccs)):
        kmnsmcc = KMeans(n_clusters=1)
        kmeansmcc = kmnsmcc.fit(custdata.loc[custdata['mcc'] == mccs[j],pointer_col])
        centroidsmcc = kmeansmcc.cluster_centers_
        
        dt.loc[(dt['customer_id']==customers[i]) & (dt['mcc']==mccs[j]),kmeanscentrs] = centroidsmcc[0,0], \
                    centroidsmcc[0,1], centroids[0,0], centroids[0,1] 
#------------------------------------------------------

lat = dt['address_lat'] - dt['mcckmeans_lat']
lon = dt['address_lon'] - dt['mcckmeans_lon']
dt['dist_1'] = np.sqrt((lat ** 2) + (lon ** 2)).astype(np.float32)

lat = dt['address_lat'] - dt['kmeans_lat']
lon = dt['address_lon'] - dt['kmeans_lon']
dt['dist_2'] = np.sqrt((lat ** 2) + (lon ** 2)).astype(np.float32)

lat = dt['mcckmeans_lat'] - dt['kmeans_lat']
lon = dt['mcckmeans_lon'] - dt['kmeans_lon']
dt['dist_3'] = np.sqrt((lat ** 2) + (lon ** 2)).astype(np.float32)

#-------------------------------------

def calculate(alat, alon, km2lat, km2lon, km1lat, km1lon):
    
        lat = alat - km1lat
        lon = alon - km1lon
        latt = alat - km2lat
        lonn = alon - km2lon
        #dist = np.sqrt((lat ** 2) + (lon ** 2)).astype(np.float32)
        rlat, rlon, r2lat, r2lon, rlatt, rlonn, r2latt, r2lonn = 0, 0, 0, 0,0, 0, 0, 0
        ugol = 0.79 #ugol = math.atan((alat-km2lat)/(alon-km2lon))
    #print(ugol)
        if alat != km1lat:
            ralat = 0 + (alat - 0) * math.cos(ugol) - (alon - 0) * math.sin(ugol)
            ralon = 0 + (alon - 0) * math.cos(ugol) - (alat - 0) * math.sin(ugol)
            rkm1lat = 0 + (km1lat - 0) * math.cos(ugol) - (km1lon - 0) * math.sin(ugol)
            rkm1lon = 0 + (km1lon - 0) * math.cos(ugol) - (km1lat - 0) * math.sin(ugol)
            rkm2lat = 0 + (km2lat - 0) * math.cos(ugol) - (km2lon - 0) * math.sin(ugol)
            rkm2lon = 0 + (km2lon - 0) * math.cos(ugol) - (km2lat - 0) * math.sin(ugol)
            rlat = ralat - rkm1lat
            rlon = ralon - rkm1lon
            rlatt = ralat - rkm2lat
            rlonn = ralon - rkm2lon
            ugol = 0.39 

            ralat = 0 + (alat - 0) * math.cos(ugol) - (alon - 0) * math.sin(ugol)
            ralon = 0 + (alon - 0) * math.cos(ugol) - (alat - 0) * math.sin(ugol)
            rkm1lat = 0 + (km1lat - 0) * math.cos(ugol) - (km1lon - 0) * math.sin(ugol)
            rkm1lon = 0 + (km1lon - 0) * math.cos(ugol) - (km1lat - 0) * math.sin(ugol)
            rkm2lat = 0 + (km2lat - 0) * math.cos(ugol) - (km2lon - 0) * math.sin(ugol)
            rkm2lon = 0 + (km2lon - 0) * math.cos(ugol) - (km2lat - 0) * math.sin(ugol)

            r2lat = ralat - rkm1lat
            r2lon = ralon - rkm1lon
            r2latt = ralat - rkm2lat
            r2lonn = ralon - rkm2lon


        return  pd.Series({'mcc_lat_c':lat,'mcc_lon_c':lon,'mcc_lat_r':rlat,'mcc_lon_r':rlon,\
                           'mcc_lat_rr':r2lat,'mcc_lon_rr':r2lon, 'mcc_latt_c':latt,'mcc_lonn_c':lonn,\
                           'mcc_latt_r':rlatt,'mcc_lonn_r':rlonn,'mcc_latt_rr':r2latt,'mcc_lonn_rr':r2lonn})
                           
import multiprocessing

def _apply_df(args):
    df, func, kwargs = args
    return df.apply(lambda row: func(row['address_lat'], row['address_lon'],row['kmeans_lat'], \
                         row['kmeans_lon'], row['mcckmeans_lat'], row['mcckmeans_lon']), **kwargs)

def apply_by_multiprocessing(df, func, **kwargs):
    workers = kwargs.pop('workers')
    pool = multiprocessing.Pool(processes=workers)
    result = pool.map(_apply_df, [(d, func, kwargs)
            for d in np.array_split(df, workers)])
    pool.close()
    #pool.join()
    return pd.concat(result)
    
if __name__ == '__main__':
    resuts = apply_by_multiprocessing(dt, calculate, axis=1, workers=7)   

#--------------------------------------------------------------

dt = pd.concat([dt, resuts], axis=1)

#------------------------------------------------------------------------

lat = dt['home_add_lat'] - dt['address_lat']
lon = dt['home_add_lon'] - dt['address_lon']
dt['is_home'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.017).astype(np.int32)
dt['has_home'] = (~dt['home_add_lon'].isnull()).astype(np.int32)

lat = dt['work_add_lat'] - dt['address_lat']
lon = dt['work_add_lon'] - dt['address_lon']
dt['is_work'] = (np.sqrt((lat ** 2) + (lon ** 2)) <= 0.017).astype(np.int32)
dt['has_work'] = (~dt['work_add_lon'].isnull()).astype(np.int32)

dt.drop(['work_add_lat','work_add_lon','home_add_lat','home_add_lon'], axis = 1, inplace = True)

#--------------------------------------

dt['address'] = dt['address_lat'].apply(lambda x: "%.02f" % x) + ';' + dt['address_lon'].apply(lambda x: "%.02f" % x)
dt['address'] = dt['address'].factorize()[0].astype(np.int32)

#-------------------------------------------------

# количество транзакций каждого клиента
dt = dt.merge(dt.groupby('customer_id')['amount'].count().reset_index(name = 'tx'), how = 'left')
dt['tx'] = dt['tx'].astype(np.int32)

dt = dt.merge(dt.groupby(['customer_id','address'])['amount'].count().reset_index(name = 'tx_cust_addr'), how = 'left')
dt['tx_cust_addr'] = dt['tx_cust_addr'].astype(np.int32)

# какая часть транзакций клиента приходится на данный адрес
dt['ratio1'] = dt['tx_cust_addr'] / dt['tx']
#--------------------------------------------------------

def _best(x):
    ret = None
    for col in ys:
        pred = ('pred:%s' % col)
        if pred in x:
            i = (x[pred].idxmax())
            cols = [pred,'address_lat','address_lon']
            if col in x:
                cols.append(col)
            tmp = x.loc[i,cols]
            tmp.rename({
                'address_lat':'%s:add_lat' % col,
                'address_lon':'%s:add_lon' % col,
            }, inplace = True)
            if ret is None:
                ret = tmp
            else:
                ret = pd.concat([ret, tmp])
    return ret
    
def predict_proba(dt, ys = ['is_home', 'is_work']):
    for col in ys:
        pred = ('pred:%s' % col)
        dt[pred] = model[col].predict_proba(dt[xs])[:,1]
    return dt.groupby('customer_id').apply(_best).reset_index()

def score(dt, ys = ['is_home', 'is_work']):
    dt_ret = predict_proba(dt, ys)
    mean = 0.0
    for col in ys:
        col_mean = dt_ret[col].mean()
        mean += col_mean
    if len(ys) == 2:
        mean = mean / len(ys)
    return mean
#--------------------------------------------------------

xs = ['amount','city','country','currency','mcc','is_atm','is_pos','ratio1','dist_1',\
      'dist_2','dist_3','mcc_lat_c','mcc_lon_c', 'mcc_lat_r', 'mcc_lon_r','mcc_lat_rr', 'mcc_lon_rr',\
      'mcc_latt_c','mcc_lonn_c', 'mcc_latt_r', 'mcc_lonn_r','mcc_latt_rr', 'mcc_lonn_rr'] #,'city','country','currency']
ys = ['is_home', 'is_work']

model0 = {
    'is_home': xgb.LGBMClassifier(n_estimators = 77, n_jobs = 3),
    'is_work': xgb.LGBMClassifier(n_estimators = 15, n_jobs = 3),
}

from tqdm._tqdm_notebook import tqdm_notebook
tqdm_notebook.pandas(desc="apply")

model = {}

# последовательно обучаем два классификатора
for col in  tqdm_notebook(['is_home', 'is_work']):
    
    #выберем для обучение транзакции только тех клиентов из train, у которых хоть в одной транзакции указано место работы/жительства
    cust_train = dt[dt['is_train'] == 1].groupby('customer_id')[col.replace('is_','has_')].max()
    cust_train = cust_train[cust_train > 0].index
    
    #разобъем train на train/valid для валидации
    cust_train, cust_valid = train_test_split(cust_train, test_size = 0.1, shuffle = True, random_state = 2)
    
    train = pd.DataFrame(cust_train, columns = ['customer_id']).merge(dt, how = 'left')
    valid = pd.DataFrame(cust_valid, columns = ['customer_id']).merge(dt, how = 'left')

    print ("Training:", col)
    clf = sklearn.base.clone(model0[col])
    clf.fit(train[xs], train[col], eval_metric = 'logloss', eval_set = [(train[xs], train[col]), (valid[xs], valid[col])], verbose=10)
    #clf.fit(X_train_scaled, train[col], eval_metric = 'logloss', eval_set = [(X_train_scaled, train[col]), (X_test_scaled, valid[col])], verbose=10)
    
    model[col] = clf
    print ("Train accuracy:", score(train, ys = [col]))
    print ("Test accuracy:", score(valid, ys = [col]))
    print ()
#---------------------------------------------------

cust_test = dt[dt['is_train'] == 0]['customer_id'].unique()
test = pd.DataFrame(cust_test, columns = ['customer_id']).merge(dt, how = 'left')
test = predict_proba(test)
test.rename(columns = {
        'customer_id':'_ID_',
        'is_home:add_lat': '_HOME_LAT_',
        'is_home:add_lon': '_HOME_LON_',
        'is_work:add_lat': '_WORK_LAT_',
        'is_work:add_lon': '_WORK_LON_'}, inplace = True)
test = test[['_ID_', '_WORK_LAT_', '_WORK_LON_', '_HOME_LAT_', '_HOME_LON_']]

#-------------------------------------------------
# Заполняем пропуски
submission = submission.merge(test, how = 'left').fillna(0)

# Пишем файл submission
submission.to_csv('submit13.csv', index = False)
